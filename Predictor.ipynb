{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "###### Start of import packages ######\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from statistics import mean, stdev\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import cm as cm\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "###### To ignore warnings ######\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "###### End of import packages ######\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "dataset = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='SalePrice', data=dataset, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['SalePrice'].skew())\n",
    "print(dataset['SalePrice'].kurtosis())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "pd.set_option('display.max_rows', 100)\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect Correlation\n",
    "# # corr = dataset.corrwith(dataset['GarageArea']).to_frame()\n",
    "# corr = dataset.corr()\n",
    "# plt.figure(figsize=(50, 50))\n",
    "# sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Category description graphs\n",
    "\n",
    "# dataset_Category = dataset.select_dtypes(include = object)\n",
    "# dataset_Category\n",
    "\n",
    "# def chunks(l, n):\n",
    "#     return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "\n",
    "# cols = dataset_Category.columns\n",
    "# for x in chunks(cols, 5):\n",
    "#     sns.pairplot(dataset_Category, y_vars=x, x_vars=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numerical description graphs\n",
    "# dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "# dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Remove Nulls\n",
    "# dataset.dropna(axis=1,inplace=True)\n",
    "dataset.drop(['LotFrontage', 'Alley', 'FireplaceQu', 'PoolQC',\n",
    "                 'Fence', 'MiscFeature','GarageType','GarageFinish'], axis=1, inplace=True)\n",
    "# for x in range(0, dataset.shape[1]):\n",
    "#     col = dataset.columns[x]\n",
    "#     if (dataset[col].dtype == object):\n",
    "#         dataset[col] = dataset[col].fillna(dataset[col].mode()[0])\n",
    "#     else:\n",
    "#         dataset[col] = dataset[col].fillna(dataset[col].mean())\n",
    "\n",
    "\n",
    "\n",
    "for i, column in enumerate(dataset):\n",
    "    if (dataset[column].dtype == object):\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].mode()[0])\n",
    "    else:\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Data Encoding\n",
    "# Categorical features\n",
    "cat_features = np.array([i for i in dataset.columns.tolist() if dataset[i].dtype == 'object'])\n",
    "enc_list = {}\n",
    "\n",
    "for i in cat_features:\n",
    "    enc_list[i] = preprocessing.LabelEncoder()\n",
    "    dataset[i] = enc_list[i].fit_transform(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = dataset.corrwith(dataset['Exterior2nd']).to_frame()\n",
    "# corr = dataset['GarageArea'].corr(dataset)\n",
    "# corr\n",
    "plt.figure(figsize=(2, 15))\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Drop Highly Correlated\n",
    "dataset.drop(['GarageCars', 'TotRmsAbvGrd', '1stFlrSF', 'Exterior2nd',\n",
    "                 'GarageYrBlt', 'MSSubClass'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Low Correlated\n",
    "drops = [\"Street\", \"LandContour\", \"Utilities\", \"LotConfig\", \"LandSlope\",\n",
    "             \"Condition2\", \"MasVnrType\", \"BsmtCond\", \"BsmtFinType2\", \"BsmtFinSF2\",\n",
    "             \"BsmtHalfBath\", \"LowQualFinSF\", \"3SsnPorch\", \"MiscVal\", \"MoSold\",\n",
    "             \"YrSold\"]\n",
    "dataset = dataset.drop(drops, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Numerical description graphs\n",
    "# dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "# dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['LotArea'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['LotArea'].hist(figsize=(8, 8),  xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset[(dataset['LotArea'] < 50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['LotArea'].hist(figsize=(8, 8),  xlabelsize=8, ylabelsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['LotArea'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "dataset = dataset[(dataset['LotArea'] < 50000)]\n",
    "dataset = dataset[(dataset['MasVnrArea'] < 500)]\n",
    "dataset = dataset[(dataset['BsmtFinSF1'] < 2300)]\n",
    "dataset = dataset[(dataset['TotalBsmtSF'] < 5000)]\n",
    "dataset = dataset[(dataset['GrLivArea'] < 4000)]\n",
    "dataset = dataset[(dataset['OpenPorchSF'] < 200)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Numerical description graphs\n",
    "dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Not Important\n",
    "drops = [\"RoofMatl\", \"Heating\", \"Electrical\", \"Functional\",\n",
    "             \"GarageQual\", \"GarageCond\", \"PavedDrive\",\n",
    "             \"PoolArea\"]\n",
    "dataset = dataset.drop(drops, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop One-Category\n",
    "drops = [\n",
    "'Condition1'  ,\n",
    "'BldgType'    ,\n",
    "'ExterCond'    ,\n",
    "'BsmtQual'     ,\n",
    "'CentralAir'   ,\n",
    "'SaleType'     ,\n",
    "'SaleCondition']\n",
    "dataset = dataset.drop(drops, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numerical decription graphs\n",
    "# dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "# dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect Correlation after removal\n",
    "# corr = dataset.corr()\n",
    "# plt.figure(figsize=(50, 50))\n",
    "# sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = dataset.corrwith(dataset['SalePrice']).to_frame()\n",
    "# # corr = dataset['GarageArea'].corr(dataset)\n",
    "# # corr\n",
    "# plt.figure(figsize=(2, 15))\n",
    "# sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"SaleType_WD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='WD' else 0)\n",
    "# dataset[\"SaleType_CWD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='CWD' else 0)\n",
    "# dataset[\"SaleType_VWD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='VWD' else 0)\n",
    "# dataset[\"SaleType\"] = dataset['SaleType'].apply(lambda x: 1 if x==\"New\" else 0)\n",
    "# dataset[\"SaleType_COD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='COD' else 0)\n",
    "# dataset[\"SaleType_Con\"] = dataset['SaleType'].apply(lambda x: 1 if x=='Con' else 0)\n",
    "# dataset[\"SaleType_ConLw\"] = dataset['SaleType'].apply(lambda x: 1 if x=='ConLw' else 0)\n",
    "# dataset[\"SaleType_ConLI\"] = dataset['SaleType'].apply(lambda x: 1 if x=='ConLI' else 0)\n",
    "# dataset[\"SaleType_ConLD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='ConLD' else 0)\n",
    "# dataset[\"SaleType_Oth\"] = dataset['SaleType'].apply(lambda x: 1 if x=='Oth' else 0)\n",
    "dataset['EnclosedPorch'] = dataset['EnclosedPorch'].apply(lambda x: 1 if x>0 else 0)\n",
    "dataset['ScreenPorch'] = dataset['ScreenPorch'].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = dataset.corrwith(dataset['SalePrice']).to_frame()\n",
    "# # corr = dataset['GarageArea'].corr(dataset)\n",
    "# # corr\n",
    "# plt.figure(figsize=(2, 15))\n",
    "# sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect Correlation after removal\n",
    "# corr = dataset.corr()\n",
    "# plt.figure(figsize=(50, 50))\n",
    "# sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "cat_features = np.array([i for i in dataset.columns.tolist() if dataset[i].dtype == 'object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Plotting\n",
    "# i=1\n",
    "# for col in cat_features:\n",
    "#     plt.figure(i,figsize=(10,10))\n",
    "#     plt.subplot(224)\n",
    "#     sns.histplot(data=dataset,x=dataset[col])\n",
    "#     i+=1\n",
    "# plt.show    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform to Object\n",
    "# for x in range(0, dataset.shape[1]):\n",
    "#     if (dataset[dataset.columns[x]].dtype == object):\n",
    "#         le = preprocessing.LabelEncoder()\n",
    "#         le.fit(dataset[dataset.columns[x]])\n",
    "#         dataset[dataset.columns[x]] = le.transform(dataset[dataset.columns[x]])\n",
    "\n",
    "# Categorical Data Encoding\n",
    "# enc_list = {}\n",
    "\n",
    "# for i in cat_features:\n",
    "#     enc_list[i] = preprocessing.LabelEncoder()\n",
    "#     dataset[i] = enc_list[i].fit_transform(dataset[i])\n",
    "\n",
    "\n",
    "# dataset = pd.get_dummies(dataset,drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import KNNImputer\n",
    "# imputer = KNNImputer(n_neighbors=10)\n",
    "# dataset = imputer.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # plot_features_to_SalePrice\n",
    "# def chunks(l, n):\n",
    "#     return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "# cols = dataset.columns\n",
    "# for x in chunks(cols, 5):\n",
    "#     sns.pairplot(dataset, y_vars=['SalePrice'], x_vars=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correlation after transformation\n",
    "# corr = dataset.corr()\n",
    "# plt.figure(figsize=(50, 50))\n",
    "# sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numerical decription graphs\n",
    "dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['GarageArea'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale Data\n",
    "dataset.LotArea = np.log1p(dataset.LotArea)\n",
    "dataset.MasVnrArea = np.log1p(dataset.MasVnrArea)\n",
    "dataset.BsmtFinSF1 = np.log1p(dataset.BsmtFinSF1)\n",
    "dataset.BsmtUnfSF = np.log1p(dataset.BsmtUnfSF)\n",
    "dataset.TotalBsmtSF = np.log1p(dataset.TotalBsmtSF)\n",
    "dataset['2ndFlrSF'] = np.log1p(dataset['2ndFlrSF'])\n",
    "dataset.GrLivArea = np.log1p(dataset.GrLivArea)\n",
    "dataset.GarageArea = np.log1p(dataset.GarageArea)\n",
    "dataset.OpenPorchSF = np.log1p(dataset.OpenPorchSF)\n",
    "dataset.EnclosedPorch = np.log1p(dataset.EnclosedPorch)\n",
    "dataset.WoodDeckSF = np.log1p(dataset.WoodDeckSF)\n",
    "\n",
    "# dataset = np.log1p(dataset.iloc[:,1:dataset.columns.size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Scale Price\n",
    "dataset.SalePrice = np.log1p(dataset.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['MasVnrArea'] = dataset['MasVnrArea'].apply(lambda x: 1 if x>0 else 0)\n",
    "# # # Numerical description graphs\n",
    "dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Numerical decription graphs\n",
    "# dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "# dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_numerical = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "# dataset_numerical.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Nulls Test\n",
    "test.drop(['LotFrontage', 'Alley', 'FireplaceQu', 'PoolQC',\n",
    "                 'Fence', 'MiscFeature','GarageType','GarageFinish'], axis=1, inplace=True)\n",
    "# for x in range(0, test.shape[1]):\n",
    "#     col = test.columns[x]\n",
    "#     if (test[col].dtype == object):\n",
    "#         test[col] = test[col].fillna(test[col].mode()[0])\n",
    "#     else:\n",
    "#         test[col] = test[col].fillna(test[col].mean())\n",
    "for i, column in enumerate(test):\n",
    "    if (test[column].dtype == object):\n",
    "        test[column] = test[column].fillna(test[column].mode()[0])\n",
    "    else:\n",
    "        test[column] = test[column].fillna(test[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Data Encoding\n",
    "# Categorical features\n",
    "cat_features = np.array([i for i in test.columns.tolist() if test[i].dtype == 'object'])\n",
    "\n",
    "for i in cat_features:\n",
    "    test[i] = enc_list[i].fit_transform(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Highly Corr Test\n",
    "test.drop(['GarageCars', 'TotRmsAbvGrd', '1stFlrSF', 'Exterior2nd',\n",
    "                 'GarageYrBlt', 'MSSubClass'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Low Corr Test\n",
    "drops = [\"Street\", \"LandContour\", \"Utilities\", \"LotConfig\", \"LandSlope\",\n",
    "             \"Condition2\", \"MasVnrType\", \"BsmtCond\", \"BsmtFinType2\", \"BsmtFinSF2\",\n",
    "             \"BsmtHalfBath\", \"LowQualFinSF\", \"3SsnPorch\", \"MiscVal\", \"MoSold\",\n",
    "             \"YrSold\"]\n",
    "test = test.drop(drops, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not Important Test\n",
    "drops = [\"RoofMatl\", \"Heating\", \"Electrical\", \"Functional\",\n",
    "             \"GarageQual\", \"GarageCond\", \"PavedDrive\",\n",
    "             \"PoolArea\"]\n",
    "test = test.drop(drops, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop One-Category\n",
    "drops = [\n",
    "'Condition1'  , \n",
    "'BldgType'    ,\n",
    "'ExterCond'    ,\n",
    "'BsmtQual'     ,\n",
    "'CentralAir'   ,\n",
    "'SaleType'     ,\n",
    "'SaleCondition']\n",
    "test = test.drop(drops, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"SaleType_WD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='WD' else 0)\n",
    "# dataset[\"SaleType_CWD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='CWD' else 0)\n",
    "# dataset[\"SaleType_VWD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='VWD' else 0)\n",
    "# test[\"SaleType\"] = test['SaleType'].apply(lambda x: 1 if x=='New' else 0)\n",
    "# dataset[\"SaleType_COD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='COD' else 0)\n",
    "# dataset[\"SaleType_Con\"] = dataset['SaleType'].apply(lambda x: 1 if x=='Con' else 0)\n",
    "# dataset[\"SaleType_ConLw\"] = dataset['SaleType'].apply(lambda x: 1 if x=='ConLw' else 0)\n",
    "# dataset[\"SaleType_ConLI\"] = dataset['SaleType'].apply(lambda x: 1 if x=='ConLI' else 0)\n",
    "# dataset[\"SaleType_ConLD\"] = dataset['SaleType'].apply(lambda x: 1 if x=='ConLD' else 0)\n",
    "# dataset[\"SaleType_Oth\"] = dataset['SaleType'].apply(lambda x: 1 if x=='Oth' else 0)\n",
    "test['EnclosedPorch'] = test['EnclosedPorch'].apply(lambda x: 1 if x>0 else 0)\n",
    "test['ScreenPorch'] = test['ScreenPorch'].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "cat_features = np.array([i for i in test.columns.tolist() if test[i].dtype == 'object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform Object Test\n",
    "# for x in range(0, test.shape[1]):\n",
    "#         if (test[test.columns[x]].dtype == object):\n",
    "#             le = preprocessing.LabelEncoder()\n",
    "#             le.fit(test[test.columns[x]])\n",
    "#             test[test.columns[x]] = le.transform(\n",
    "#                 test[test.columns[x]])\n",
    "# Categorical Data Encoding test\n",
    "# for i in cat_features:\n",
    "#     test[i] = enc_list[i].fit_transform(test[i])\n",
    "\n",
    "\n",
    "# test = pd.get_dummies(test,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = imputer.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Scale Data\n",
    "# # # dataset = np.log1p(dataset)\n",
    "test.BsmtFinSF1 = np.log1p(test.BsmtFinSF1)\n",
    "test.BsmtUnfSF = np.log1p(test.BsmtUnfSF)\n",
    "test.TotalBsmtSF = np.log1p(test.TotalBsmtSF)\n",
    "test.GarageArea = np.log1p(test.GarageArea)\n",
    "test.GrLivArea = np.log1p(test.GrLivArea)\n",
    "test.LotArea = np.log1p(test.LotArea)\n",
    "test.MasVnrArea = np.log1p(test.MasVnrArea)\n",
    "test.OpenPorchSF = np.log1p(test.OpenPorchSF)\n",
    "test.EnclosedPorch = np.log1p(test.EnclosedPorch)\n",
    "test.WoodDeckSF = np.log1p(test.WoodDeckSF)\n",
    "\n",
    "test['2ndFlrSF'] = np.log1p(test['2ndFlrSF'])\n",
    "test['MasVnrArea'] = test['MasVnrArea'].apply(lambda x: 1 if x>0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = dataset.columns.tolist()\n",
    "# test = test.reindex(columns=cols).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "array = dataset.values\n",
    "testarray = test.values\n",
    "n = dataset.shape[1]\n",
    "n = n-1\n",
    "\n",
    "# test_X = testarray[:, 0:n]  # features\n",
    "X = dataset.iloc[:,0:n]  # features\n",
    "Y = dataset['SalePrice']  # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XX = dataset.iloc[:, ~dataset.columns.isin(['Id','SalePrice'])]\n",
    "# YY = dataset[['SalePrice']]\n",
    "\n",
    "def rmse(y_true,y_pred):\n",
    "    return 1 - np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "\n",
    "scorer = make_scorer(rmse,greater_is_better=True)\n",
    "\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "sfs_range = SFS(estimator=rfr,\n",
    "                k_features=(6,30),\n",
    "                forward=True,\n",
    "                floating=False,\n",
    "                scoring=scorer,\n",
    "                cv=0,n_jobs=8)\n",
    "\n",
    "sfs_range.fit(X,Y)\n",
    "\n",
    "# print the accuracy of the best combination as well as the set of best features\n",
    "print('best combination (ACC: %.3f): %s\\n' % (sfs_range.k_score_, sfs_range.k_feature_idx_))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "# use the plot_sfs to visualize all accuracies\n",
    "plot_sfs(sfs_range.get_metric_dict(), kind='std_err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sfs = sfs_range.transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_sfs, Y, test_size=0.2, random_state=200)  # test = 20%, train = 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# pipeline1 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('linearregression', LinearRegression())\n",
    "# ])\n",
    "\n",
    "# param_grid = {'linearregression__fit_intercept': [True, False],\n",
    "#               'linearregression__copy_X': [True, False]\n",
    "#               }\n",
    "\n",
    "# grid_search1 = GridSearchCV(pipeline1, param_grid, cv=12)\n",
    "# grid_search1.fit(X,Y)\n",
    "\n",
    "# print('Parameters : ', grid_search1.best_params_,'\\nAccuracy Score : ', grid_search1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# pipeline2 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('clf2', DecisionTreeRegressor(random_state=42))\n",
    "# ])\n",
    "\n",
    "# param_grid2 = {\n",
    "#     'clf2__max_depth': [2, 3, 4, 5],\n",
    "#     'clf2__min_samples_split': [2, 5, 10],\n",
    "#     'clf2__min_samples_leaf': [1, 2, 4],\n",
    "#     'clf2__max_leaf_nodes': [None, 5, 10, 20]\n",
    "# }\n",
    "\n",
    "# grid_search2 = GridSearchCV(pipeline2, param_grid2, cv=15)\n",
    "# grid_search2.fit(X,Y)\n",
    "\n",
    "# print('Parameters : ', grid_search2.best_params_,'\\nAccuracy Score : ', grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline5 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('clf5', RandomForestRegressor())\n",
    "# ])\n",
    "\n",
    "# param_grid5 = {\n",
    "#     'clf5__n_estimators': [10, 50],\n",
    "#     'clf5__max_features': ['auto', 'sqrt'],\n",
    "#     'clf5__max_depth': [5, 15],\n",
    "#     'clf5__min_samples_split': [2, 5],\n",
    "#     'clf5__min_samples_leaf': [1, 3],\n",
    "# }\n",
    "\n",
    "# grid_search5 = GridSearchCV(pipeline5, param_grid5, cv=10,n_jobs=8)\n",
    "# grid_search5.fit(X,Y)\n",
    "\n",
    "# print('Parameters : ', grid_search5.best_params_,'\\nAccuracy Score : ', grid_search5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nRandom Forest\")\n",
    "# rfr = RandomForestRegressor(max_depth=15,max_features='sqrt',min_samples_leaf=1,min_samples_split=2,n_estimators=100)\n",
    "# rfr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = np.exp(rfr.predict(test.iloc[:,1:35]))\n",
    "# output = pd.DataFrame({'Id': test.Id, 'SalePrice': result})\n",
    "# print(output)\n",
    "# output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# pipeline6 = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('clf6', ensemble.GradientBoostingRegressor())\n",
    "# ])\n",
    "\n",
    "# param_grid6 = {\n",
    "#     'clf6__n_estimators': [1000,2000,3000,4000],\n",
    "#     'clf6__random_state': [1000,1234,1269],\n",
    "#     'clf6__max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'clf6__max_depth': [3,5, 15],\n",
    "#     'clf6__min_samples_split': [2, 5,10,15],\n",
    "#     'clf6__min_samples_leaf': [1, 3 ,6,11,15],\n",
    "# }\n",
    "\n",
    "# grid_search6 = GridSearchCV(pipeline6, param_grid6, cv=5,n_jobs=8)\n",
    "# grid_search6.fit(x_train,y_train)\n",
    "\n",
    "# print('Parameters : ', grid_search6.best_params_,'\\nAccuracy Score : ', grid_search6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nElasticNet\")\n",
    "# ens_test = linear_model.ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.0015, 0.01, 0.015, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "#                                      l1_ratio=[0.01, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99], max_iter=10000).fit(x_train, y_train)\n",
    "# ens_result = ens_test.predict(x_test)\n",
    "# print('\\tR2: {}'.format(r2_score(ens_result, y_test)))\n",
    "# print('\\tRMSE: {}'.format(np.sqrt(mean_squared_error(ens_result, y_test))))\n",
    "# scores = cross_val_score(ens_test, X, Y, cv=5)\n",
    "# print(\"\\tAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nDescisionTreeRegressor\")\n",
    "# dtr = DescisionTreeRegressor(2,2,2,'None')\n",
    "# dtr.fit(x_train, y_train)\n",
    "# preds = dtr.predict(x_test)\n",
    "# scores = cross_val_score(dtr, X, Y, cv=5)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "# print(\"RMSE: %f\" % (rmse))\n",
    "# print(\"\\tAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nXgBoost\")\n",
    "# xg_reg = xgb.XGBRegressor(objective='reg:linear', eval_metric='logloss',\n",
    "#                           scoring='neg_mean_squared_error', subsample=0.95, colsample_bytree=0.3, learning_rate=0.04,\n",
    "#                           max_depth=2, alpha=0.1, n_estimators=1000,)\n",
    "# xg_reg.fit(x_train, y_train)\n",
    "# preds = xg_reg.predict(x_test)\n",
    "# scores = cross_val_score(xg_reg, X, Y, cv=5)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "# print(\"RMSE: %f\" % (rmse))\n",
    "# print(\"\\tAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGradientBoostingRegressor\")\n",
    "g_best = ensemble.GradientBoostingRegressor(n_estimators=1850, random_state=1234, learning_rate=0.02, max_depth=3,\n",
    "                                            max_features='log2', min_samples_leaf=11, min_samples_split=15, loss='huber').fit(x_train, y_train)\n",
    "g_best_result = g_best.predict(x_test)\n",
    "print('\\tR2: {}'.format(r2_score(g_best_result, y_test)))\n",
    "print('\\tRMSE: {}'.format(np.sqrt(mean_squared_error(g_best_result, y_test))))\n",
    "scores = cross_val_score(g_best, X, Y, cv=5)\n",
    "print(\"\\tAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nLinearRegression\")\n",
    "# lr = linear_model.LinearRegression()\n",
    "# lr.fit(x_train, y_train)\n",
    "# lr_result = lr.predict(x_test)\n",
    "# print('\\tR2: {}'.format(r2_score(lr_result, y_test)))\n",
    "# print('\\tRMSE: {}'.format(np.sqrt(mean_squared_error(lr_result, y_test))))\n",
    "# scores = cross_val_score(lr, X, Y, cv=5)\n",
    "# print(\"\\tAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nRidge Regression\")\n",
    "# ridge = Ridge(max_iter=50000)\n",
    "# ridge_est = GridSearchCV(\n",
    "#     ridge, param_grid={\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]})\n",
    "# ridge_est.fit(x_train, y_train)\n",
    "# ridge_result = ridge_est.predict(x_test)\n",
    "# print('\\tR2: {}'.format(r2_score(ridge_result, y_test)))\n",
    "# print('\\tRMSE: {}'.format(np.sqrt(mean_squared_error(ridge_result, y_test))))\n",
    "# scores = cross_val_score(ridge_est, X, Y, cv=5)\n",
    "# print(\"\\tAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nLasso Regression\")\n",
    "# lasso = Lasso(max_iter=50000)\n",
    "# lasso_est = GridSearchCV(\n",
    "#     lasso, param_grid={\"alpha\": np.arange(0.0005, 0.001, 0.00001)})\n",
    "# lasso_est.fit(x_train, y_train)\n",
    "# lasso_result = lasso_est.predict(x_test)\n",
    "# print('\\tR2: {}'.format(r2_score(lasso_result, y_test)))\n",
    "# print('\\tRMSE: {}'.format(np.sqrt(mean_squared_error(lasso_result, y_test))))\n",
    "# scores = cross_val_score(lasso_est, X, Y, cv=5)\n",
    "# print(\"\\tAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.exp(g_best.predict(test.iloc[:,[...]]))\n",
    "output = pd.DataFrame({'Id': test.Id, 'SalePrice': result})\n",
    "print(output)\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
