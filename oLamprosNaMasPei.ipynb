{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8588be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopy.distance\n",
    "from scipy.stats import skew, kurtosis, boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "#Regressors\n",
    "from sklearn.linear_model import ARDRegression, BayesianRidge, ElasticNet, ElasticNetCV, HuberRegressor, Lars, LarsCV, Lasso, LassoCV, LassoLars, LassoLarsCV, LassoLarsIC, LinearRegression, OrthogonalMatchingPursuit, OrthogonalMatchingPursuitCV, PassiveAggressiveRegressor, PoissonRegressor, Ridge, RidgeCV, SGDRegressor, TheilSenRegressor\n",
    "from sklearn.svm import LinearSVR, NuSVR, SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.cross_decomposition import CCA, PLSCanonical, PLSRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import GammaRegressor, TweedieRegressor, PoissonRegressor, PassiveAggressiveRegressor, RANSACRegressor, HuberRegressor, QuantileRegressor\n",
    "\n",
    "from statistics import mean,stdev\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81470d5f",
   "metadata": {},
   "source": [
    "## Upload the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461045c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13315</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13320 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13315        Built-up  Area  Ready To Move                Whitefield   \n",
       "13316  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13317        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13318  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13319  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price  \n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  \n",
       "...          ...      ...        ...   ...      ...     ...  \n",
       "13315  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  \n",
       "13316      4 BHK      NaN       3600   5.0      NaN  400.00  \n",
       "13317      2 BHK  Mahla T       1141   2.0      1.0   60.00  \n",
       "13318      4 BHK  SollyCl       4689   4.0      1.0  488.00  \n",
       "13319      1 BHK      NaN        550   1.0      1.0   17.00  \n",
       "\n",
       "[13320 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('Train.csv')\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03bfc7",
   "metadata": {},
   "source": [
    "## Upload other csv files that might help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8b76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Google API, we calculated the coordinates of the locations mentioned in our training and test sets.\n",
    "#Using the coordinates of each location we found its ward. This was done using Google Earth Code Engine\n",
    "#The code we wrote can be found at: https://code.earthengine.google.com/3569f5aba1e32a025024407aff663c93\n",
    "locations = pd.read_csv('locations_lat_long.csv')\n",
    "\n",
    "#For each ward we found its corresponding population density\n",
    "#The source wikipedia table can be found here: https://en.wikipedia.org/wiki/List_of_wards_in_Bangalore\n",
    "ward_density = pd.read_csv('ward_density.csv')\n",
    "ward_parks = pd.read_csv('parks_per_ward.csv')\n",
    "\n",
    "#We found the addresses of high schools, universities, hospitals and police stations in Bangalore\n",
    "#We converted their addresses into lat-long coordinates using Google API\n",
    "high_schools = pd.read_csv('high_schools_lat_long.csv')\n",
    "universities = pd.read_csv('universities_lat_long.csv')\n",
    "hospitals = pd.read_csv('hospitals_lat_long.csv')\n",
    "police_stations = pd.read_csv('police_stations_lat_long.csv')\n",
    "primary_schools = pd.read_csv('primary_schools_lat_long.csv')\n",
    "parks = pd.read_csv('parks_lat_long.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f677822",
   "metadata": {},
   "source": [
    "Combine these csv files to create one table containing important info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bac1ebc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13315</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13320 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13315        Built-up  Area  Ready To Move                Whitefield   \n",
       "13316  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13317        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13318  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13319  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price  \n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  \n",
       "...          ...      ...        ...   ...      ...     ...  \n",
       "13315  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  \n",
       "13316      4 BHK      NaN       3600   5.0      NaN  400.00  \n",
       "13317      2 BHK  Mahla T       1141   2.0      1.0   60.00  \n",
       "13318      4 BHK  SollyCl       4689   4.0      1.0  488.00  \n",
       "13319      1 BHK      NaN        550   1.0      1.0   17.00  \n",
       "\n",
       "[13320 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trim unecessary spaces in the beginning of the column\n",
    "df1['location'] = df1['location'].str.lstrip()\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72791a66",
   "metadata": {},
   "source": [
    "### Drop records with empty location\n",
    "We will match each house with its ward. Therefore we want to get rid of blank location. They're not useful anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "392143ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13315</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13316</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13319 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13315        Built-up  Area  Ready To Move                Whitefield   \n",
       "13316  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13317        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13318  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13319  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price  \n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  \n",
       "...          ...      ...        ...   ...      ...     ...  \n",
       "13315  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  \n",
       "13316      4 BHK      NaN       3600   5.0      NaN  400.00  \n",
       "13317      2 BHK  Mahla T       1141   2.0      1.0   60.00  \n",
       "13318      4 BHK  SollyCl       4689   4.0      1.0  488.00  \n",
       "13319      1 BHK      NaN        550   1.0      1.0   17.00  \n",
       "\n",
       "[13319 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.dropna(subset=['location'])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0fea2",
   "metadata": {},
   "source": [
    "#### Merge the dataframe with the wards of each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf57a099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Mysore Highway</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>4 Bedroom Farm House in Bagalur</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10961</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>ittamadu</td>\n",
       "      <td>3 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Mysore Highway</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kanakapura Road</td>\n",
       "      <td>3 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Off Sarjapur road,</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Anand nagar</td>\n",
       "      <td>2 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>t.c palya</td>\n",
       "      <td>6 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1350</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>south</td>\n",
       "      <td>3 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Anand nagar</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>5 Bedroom Farm House in Lakshmipura</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24Guntha</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>BEML Layout 5th Stage</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8077</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kanakapura Main Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1080</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9021</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>RR Nagar</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Mysore Highway</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>south</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3420</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10487</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>2 Bedroom Furnished Farm House in Kolar Road</td>\n",
       "      <td>2 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.25Acres</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>21-Dec</td>\n",
       "      <td>Electronic city phase 1,</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11045</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Off Bannergatta Road</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1645</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Mysore Highway</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>21-Dec</td>\n",
       "      <td>Electronic City Phase 1,</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability  \\\n",
       "92     Super built-up  Area  Ready To Move   \n",
       "809              Plot  Area         18-Apr   \n",
       "2448             Plot  Area         18-Feb   \n",
       "2852         Built-up  Area  Ready To Move   \n",
       "3125         Built-up  Area  Ready To Move   \n",
       "3219             Plot  Area         19-Dec   \n",
       "3981             Plot  Area  Ready To Move   \n",
       "5187             Plot  Area  Ready To Move   \n",
       "5848             Plot  Area  Ready To Move   \n",
       "6533   Super built-up  Area  Ready To Move   \n",
       "6551             Plot  Area  Ready To Move   \n",
       "7339             Plot  Area  Ready To Move   \n",
       "8077   Super built-up  Area  Ready To Move   \n",
       "9021   Super built-up  Area         18-Jun   \n",
       "9070   Super built-up  Area  Ready To Move   \n",
       "9102         Built-up  Area  Ready To Move   \n",
       "10487            Plot  Area  Ready To Move   \n",
       "10976        Built-up  Area         21-Dec   \n",
       "11045  Super built-up  Area  Ready To Move   \n",
       "12309  Super built-up  Area  Ready To Move   \n",
       "12596        Built-up  Area         21-Dec   \n",
       "\n",
       "                                           location       size society  \\\n",
       "92                                   Mysore Highway      3 BHK     NaN   \n",
       "809                 4 Bedroom Farm House in Bagalur  4 Bedroom     NaN   \n",
       "2448                                       ittamadu  3 Bedroom     NaN   \n",
       "2852                                 Mysore Highway      1 BHK     NaN   \n",
       "3125                                Kanakapura Road  3 Bedroom     NaN   \n",
       "3219                            Off Sarjapur road,   4 Bedroom     NaN   \n",
       "3981                                    Anand nagar  2 Bedroom     NaN   \n",
       "5187                                      t.c palya  6 Bedroom     NaN   \n",
       "5848                                          south  3 Bedroom     NaN   \n",
       "6533                                    Anand nagar      3 BHK     NaN   \n",
       "6551            5 Bedroom Farm House in Lakshmipura  5 Bedroom     NaN   \n",
       "7339                          BEML Layout 5th Stage  4 Bedroom     NaN   \n",
       "8077                           Kanakapura Main Road      2 BHK     NaN   \n",
       "9021                                       RR Nagar      1 BHK     NaN   \n",
       "9070                                 Mysore Highway      1 BHK     NaN   \n",
       "9102                                          south      4 BHK     NaN   \n",
       "10487  2 Bedroom Furnished Farm House in Kolar Road  2 Bedroom     NaN   \n",
       "10976                     Electronic city phase 1,       2 BHK     NaN   \n",
       "11045                          Off Bannergatta Road      3 BHK     NaN   \n",
       "12309                                Mysore Highway      1 BHK     NaN   \n",
       "12596                     Electronic City Phase 1,       3 BHK     NaN   \n",
       "\n",
       "      total_sqft  bath  balcony  price  lat  long ward  \n",
       "92          1450   2.0      2.0   70.0  NaN   NaN  NaN  \n",
       "809        10961   4.0      1.0   80.0  NaN   NaN  NaN  \n",
       "2448         600   2.0      1.0  110.0  NaN   NaN  NaN  \n",
       "2852         600   1.0      1.0   17.0  NaN   NaN  NaN  \n",
       "3125        1950   3.0      2.0  130.0  NaN   NaN  NaN  \n",
       "3219        3000   4.0      3.0  342.0  NaN   NaN  NaN  \n",
       "3981        1200   2.0      0.0   70.0  NaN   NaN  NaN  \n",
       "5187        1350   6.0      3.0  160.0  NaN   NaN  NaN  \n",
       "5848        2400   2.0      0.0  480.0  NaN   NaN  NaN  \n",
       "6533        2010   3.0      3.0  125.0  NaN   NaN  NaN  \n",
       "6551    24Guntha   6.0      2.0  550.0  NaN   NaN  NaN  \n",
       "7339        1200   5.0      NaN  325.0  NaN   NaN  NaN  \n",
       "8077        1080   2.0      1.0   37.8  NaN   NaN  NaN  \n",
       "9021         648   1.0      1.0   34.0  NaN   NaN  NaN  \n",
       "9070         535   1.0      1.0   35.0  NaN   NaN  NaN  \n",
       "9102        3420   3.0      2.0  410.0  NaN   NaN  NaN  \n",
       "10487  1.25Acres   2.0      2.0  200.0  NaN   NaN  NaN  \n",
       "10976       1150   2.0      1.0   39.0  NaN   NaN  NaN  \n",
       "11045       1645   3.0      2.0   87.0  NaN   NaN  NaN  \n",
       "12309        700   1.0      1.0   25.5  NaN   NaN  NaN  \n",
       "12596       1500   3.0      2.0   50.0  NaN   NaN  NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dataframes on the 'location' column\n",
    "df3 = pd.merge(df2, locations, on='location', how='left')\n",
    "df3[df3['ward'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890048f",
   "metadata": {},
   "source": [
    "#### Replace values that are similar with valid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4a3a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>4 Bedroom Farm House in Bagalur</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10961</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>ittamadu</td>\n",
       "      <td>3 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Off Sarjapur road,</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Anand nagar</td>\n",
       "      <td>2 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>t.c palya</td>\n",
       "      <td>6 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1350</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>south</td>\n",
       "      <td>3 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Anand nagar</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>5 Bedroom Farm House in Lakshmipura</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24Guntha</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>BEML Layout 5th Stage</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>south</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3420</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10487</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>2 Bedroom Furnished Farm House in Kolar Road</td>\n",
       "      <td>2 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.25Acres</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>21-Dec</td>\n",
       "      <td>Electronic city phase 1,</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11045</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Off Bannergatta Road</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1645</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>21-Dec</td>\n",
       "      <td>Electronic City Phase 1,</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability  \\\n",
       "809              Plot  Area         18-Apr   \n",
       "2448             Plot  Area         18-Feb   \n",
       "3219             Plot  Area         19-Dec   \n",
       "3981             Plot  Area  Ready To Move   \n",
       "5187             Plot  Area  Ready To Move   \n",
       "5848             Plot  Area  Ready To Move   \n",
       "6533   Super built-up  Area  Ready To Move   \n",
       "6551             Plot  Area  Ready To Move   \n",
       "7339             Plot  Area  Ready To Move   \n",
       "9102         Built-up  Area  Ready To Move   \n",
       "10487            Plot  Area  Ready To Move   \n",
       "10976        Built-up  Area         21-Dec   \n",
       "11045  Super built-up  Area  Ready To Move   \n",
       "12596        Built-up  Area         21-Dec   \n",
       "\n",
       "                                           location       size society  \\\n",
       "809                 4 Bedroom Farm House in Bagalur  4 Bedroom     NaN   \n",
       "2448                                       ittamadu  3 Bedroom     NaN   \n",
       "3219                            Off Sarjapur road,   4 Bedroom     NaN   \n",
       "3981                                    Anand nagar  2 Bedroom     NaN   \n",
       "5187                                      t.c palya  6 Bedroom     NaN   \n",
       "5848                                          south  3 Bedroom     NaN   \n",
       "6533                                    Anand nagar      3 BHK     NaN   \n",
       "6551            5 Bedroom Farm House in Lakshmipura  5 Bedroom     NaN   \n",
       "7339                          BEML Layout 5th Stage  4 Bedroom     NaN   \n",
       "9102                                          south      4 BHK     NaN   \n",
       "10487  2 Bedroom Furnished Farm House in Kolar Road  2 Bedroom     NaN   \n",
       "10976                     Electronic city phase 1,       2 BHK     NaN   \n",
       "11045                          Off Bannergatta Road      3 BHK     NaN   \n",
       "12596                     Electronic City Phase 1,       3 BHK     NaN   \n",
       "\n",
       "      total_sqft  bath  balcony  price  lat  long ward  \n",
       "809        10961   4.0      1.0   80.0  NaN   NaN  NaN  \n",
       "2448         600   2.0      1.0  110.0  NaN   NaN  NaN  \n",
       "3219        3000   4.0      3.0  342.0  NaN   NaN  NaN  \n",
       "3981        1200   2.0      0.0   70.0  NaN   NaN  NaN  \n",
       "5187        1350   6.0      3.0  160.0  NaN   NaN  NaN  \n",
       "5848        2400   2.0      0.0  480.0  NaN   NaN  NaN  \n",
       "6533        2010   3.0      3.0  125.0  NaN   NaN  NaN  \n",
       "6551    24Guntha   6.0      2.0  550.0  NaN   NaN  NaN  \n",
       "7339        1200   5.0      NaN  325.0  NaN   NaN  NaN  \n",
       "9102        3420   3.0      2.0  410.0  NaN   NaN  NaN  \n",
       "10487  1.25Acres   2.0      2.0  200.0  NaN   NaN  NaN  \n",
       "10976       1150   2.0      1.0   39.0  NaN   NaN  NaN  \n",
       "11045       1645   3.0      2.0   87.0  NaN   NaN  NaN  \n",
       "12596       1500   3.0      2.0   50.0  NaN   NaN  NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[df2['location'] == 'RR Nagar','location'] = 'Rajarajeshwari Nagara'\n",
    "df2.loc[df2['location'] == 'Kanakapura Road', 'location'] = 'Kanakapura'\n",
    "df2.loc[df2['location'] == 'Kanakapura Main Road', 'location'] = 'Kanakapura'\n",
    "df2.loc[df2['location'] == 'Mysore Highway', 'location'] = 'Mysore Road'\n",
    "\n",
    "df3 = pd.merge(df2, locations, on='location', how='left')\n",
    "\n",
    "df3[df3['ward'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc37da",
   "metadata": {},
   "source": [
    "#### Drop records with empty ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136a69ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [area_type, availability, location, size, society, total_sqft, bath, balcony, price, lat, long, ward]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace empty strings with NaN values\n",
    "df3['ward'] = df3['ward'].replace('', pd.NA)\n",
    "\n",
    "# drop rows with NaN values in the 'ward' column\n",
    "df3 = df3.dropna(subset=['ward'])\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "df3[df3['ward'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69615d00",
   "metadata": {},
   "source": [
    "#### Merge the dataframe with Ward Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c102f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>77.679381</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>77.866742</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>77.552059</td>\n",
       "      <td>Vasanthapura</td>\n",
       "      <td>10852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>77.513787</td>\n",
       "      <td>Hemmigepura</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>77.642221</td>\n",
       "      <td>Horamavu</td>\n",
       "      <td>5437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>77.749972</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>77.614948</td>\n",
       "      <td>Sagayarapuram</td>\n",
       "      <td>45792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>77.520640</td>\n",
       "      <td>Rajarajeshwarinagar</td>\n",
       "      <td>5112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>77.556773</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>24311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>77.652802</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193   \n",
       "...          ...      ...        ...   ...      ...     ...        ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916   \n",
       "\n",
       "            long                 ward  density  \n",
       "0      77.679381      Outside of town    27566  \n",
       "1      77.866742      Outside of town    27566  \n",
       "2      77.552059         Vasanthapura    10852  \n",
       "3      77.513787          Hemmigepura     1652  \n",
       "4      77.642221             Horamavu     5437  \n",
       "...          ...                  ...      ...  \n",
       "13300  77.749972            Hagadooru     4003  \n",
       "13301  77.614948        Sagayarapuram    45792  \n",
       "13302  77.520640  Rajarajeshwarinagar     5112  \n",
       "13303  77.556773      Padmanabhanagar    24311  \n",
       "13304  77.652802      Outside of town    27566  \n",
       "\n",
       "[13305 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3b = pd.merge(df3, ward_density, on='ward', how='left')\n",
    "df3b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebeb22",
   "metadata": {},
   "source": [
    "#### Merge the dataframe with the number of parks per ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be0526f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>77.679381</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>77.866742</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>77.552059</td>\n",
       "      <td>Vasanthapura</td>\n",
       "      <td>10852</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>77.513787</td>\n",
       "      <td>Hemmigepura</td>\n",
       "      <td>1652</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>77.642221</td>\n",
       "      <td>Horamavu</td>\n",
       "      <td>5437</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>77.749972</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>77.614948</td>\n",
       "      <td>Sagayarapuram</td>\n",
       "      <td>45792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>77.520640</td>\n",
       "      <td>Rajarajeshwarinagar</td>\n",
       "      <td>5112</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>77.556773</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>24311</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>77.652802</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193   \n",
       "...          ...      ...        ...   ...      ...     ...        ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916   \n",
       "\n",
       "            long                 ward  density  parks_per_ward  \n",
       "0      77.679381      Outside of town    27566             NaN  \n",
       "1      77.866742      Outside of town    27566             NaN  \n",
       "2      77.552059         Vasanthapura    10852             4.0  \n",
       "3      77.513787          Hemmigepura     1652             3.0  \n",
       "4      77.642221             Horamavu     5437             1.0  \n",
       "...          ...                  ...      ...             ...  \n",
       "13300  77.749972            Hagadooru     4003             1.0  \n",
       "13301  77.614948        Sagayarapuram    45792             1.0  \n",
       "13302  77.520640  Rajarajeshwarinagar     5112            14.0  \n",
       "13303  77.556773      Padmanabhanagar    24311             8.0  \n",
       "13304  77.652802      Outside of town    27566             NaN  \n",
       "\n",
       "[13305 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3c = pd.merge(df3b, ward_parks, on='ward', how='left')\n",
    "df3c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f4a0c",
   "metadata": {},
   "source": [
    "### Find nearest amenities (Schools, Hospitals, Parks, Police Stations, Universities)\n",
    "#### Haversine distance is used to calculate the distance between 2 lat-long pairs. We assume the equatorial distance is 6367km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40ff635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572200c",
   "metadata": {},
   "source": [
    "#### Method that finds the number of amenities under a threshold distance and the closest amenity\n",
    "The commented for loop is replaced with a more complex algorithm that used numpy instead for faster calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe80fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_places(df_0, places, str1, str2, threshold):\n",
    "    df_1 = df_0.copy()\n",
    "    df_1 = df_1.merge(places, how='cross')\n",
    "    km = haversine_np(df_1['long_x'],df_1['lat_x'],df_1['long_y'],df_1['lat_y'])\n",
    "    \n",
    "    #FOR LOOPS TOO SLOW\n",
    "    #distances = []\n",
    "    #for i in range(len(df_0.index)):\n",
    "    #    for j in range(len(places.index)):\n",
    "    #        distances.append({'HouseIndex': i, \n",
    "    #                          'PlaceIndex': j, \n",
    "    #                          'Distance': km[i*len(places.index)+j]})\n",
    "    \n",
    "    \n",
    "    # convert distances to dataframe\n",
    "    km1 = km.values\n",
    "    km1 = km1.reshape(len(df_0.index), len(places.index))\n",
    "\n",
    "    x1 =np.repeat(np.arange(km1.shape[0]), len(km1.flatten())/len(np.arange(km1.shape[0])))\n",
    "    x2 =np.tile(np.arange(km1.shape[1]), int(len(km1.flatten())/len(np.arange(km1.shape[1]))))\n",
    "    x3= km1.flatten()\n",
    "\n",
    "    distances_df = pd.DataFrame(np.array([x1,x2,x3]).T, columns=['HouseIndex','PlaceIndex','Distance'])\n",
    "    distances_df['HouseIndex'] = distances_df['HouseIndex'].astype(int)\n",
    "    distances_df['PlaceIndex'] = distances_df['PlaceIndex'].astype(int)\n",
    "    \n",
    "    # calculate minimum distance for each house\n",
    "    result_1 = distances_df.groupby('HouseIndex').agg({'Distance': 'min'})\n",
    "    \n",
    "    # rename columns for clarity\n",
    "    result_1 = result_1.rename(columns={'Distance': str2})\n",
    "    \n",
    "    # filter distances to only include schools within 3km\n",
    "    close_places = distances_df.loc[distances_df['Distance'] <= threshold]\n",
    "\n",
    "    # calculate number of places for each house\n",
    "    result_2 = close_places.groupby('HouseIndex').agg({'PlaceIndex': 'count'})\n",
    "    \n",
    "    # rename columns for clarity\n",
    "    result_2 = result_2.rename(columns={'PlaceIndex': str1})\n",
    "\n",
    "    # merge results with original house dataframe\n",
    "    df_2 = pd.merge(df_0, result_1, how='left', left_index=True, right_index=True)\n",
    "    df_3 = pd.merge(df_2, result_2, how='left', left_index=True, right_index=True)\n",
    "    df_3[str1] = df_3[str1].fillna(0)\n",
    "    df_3[str1] = df_3[str1].astype(int)\n",
    "\n",
    "    # return final dataframe\n",
    "    return df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e7135",
   "metadata": {},
   "source": [
    "#### Nearest High Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc9b515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>77.679381</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842733</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>77.866742</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.578895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>77.552059</td>\n",
       "      <td>Vasanthapura</td>\n",
       "      <td>10852</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>77.513787</td>\n",
       "      <td>Hemmigepura</td>\n",
       "      <td>1652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.445457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>77.642221</td>\n",
       "      <td>Horamavu</td>\n",
       "      <td>5437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.549047</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>77.749972</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>77.614948</td>\n",
       "      <td>Sagayarapuram</td>\n",
       "      <td>45792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.464174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>77.520640</td>\n",
       "      <td>Rajarajeshwarinagar</td>\n",
       "      <td>5112</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.840693</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>77.556773</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>24311</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>77.652802</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489148</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193   \n",
       "...          ...      ...        ...   ...      ...     ...        ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916   \n",
       "\n",
       "            long                 ward  density  parks_per_ward  \\\n",
       "0      77.679381      Outside of town    27566             NaN   \n",
       "1      77.866742      Outside of town    27566             NaN   \n",
       "2      77.552059         Vasanthapura    10852             4.0   \n",
       "3      77.513787          Hemmigepura     1652             3.0   \n",
       "4      77.642221             Horamavu     5437             1.0   \n",
       "...          ...                  ...      ...             ...   \n",
       "13300  77.749972            Hagadooru     4003             1.0   \n",
       "13301  77.614948        Sagayarapuram    45792             1.0   \n",
       "13302  77.520640  Rajarajeshwarinagar     5112            14.0   \n",
       "13303  77.556773      Padmanabhanagar    24311             8.0   \n",
       "13304  77.652802      Outside of town    27566             NaN   \n",
       "\n",
       "       nearest_high_school  high_schools_3km  \n",
       "0                 0.842733                 4  \n",
       "1                 8.578895                 0  \n",
       "2                 0.000000                17  \n",
       "3                 2.445457                 1  \n",
       "4                 1.549047                 4  \n",
       "...                    ...               ...  \n",
       "13300             0.714559                 6  \n",
       "13301             1.464174                12  \n",
       "13302             0.840693                10  \n",
       "13303             0.109952                22  \n",
       "13304             0.489148                 3  \n",
       "\n",
       "[13305 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = find_nearest_places(df3c, high_schools, \"high_schools_3km\", \"nearest_high_school\", 3)\n",
    "\n",
    "df4\n",
    "\n",
    "#df4[df4[\"high_schools_3km\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46004b0b",
   "metadata": {},
   "source": [
    "#### Nearest Hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d72ddfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>77.679381</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842733</td>\n",
       "      <td>4</td>\n",
       "      <td>0.702709</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>77.866742</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.578895</td>\n",
       "      <td>0</td>\n",
       "      <td>13.856962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>77.552059</td>\n",
       "      <td>Vasanthapura</td>\n",
       "      <td>10852</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>77.513787</td>\n",
       "      <td>Hemmigepura</td>\n",
       "      <td>1652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.445457</td>\n",
       "      <td>1</td>\n",
       "      <td>3.403518</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>77.642221</td>\n",
       "      <td>Horamavu</td>\n",
       "      <td>5437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.549047</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>77.749972</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>77.614948</td>\n",
       "      <td>Sagayarapuram</td>\n",
       "      <td>45792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.464174</td>\n",
       "      <td>12</td>\n",
       "      <td>0.328717</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>77.520640</td>\n",
       "      <td>Rajarajeshwarinagar</td>\n",
       "      <td>5112</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.840693</td>\n",
       "      <td>10</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>77.556773</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>24311</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>22</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>77.652802</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489148</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530349</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193   \n",
       "...          ...      ...        ...   ...      ...     ...        ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916   \n",
       "\n",
       "            long                 ward  density  parks_per_ward  \\\n",
       "0      77.679381      Outside of town    27566             NaN   \n",
       "1      77.866742      Outside of town    27566             NaN   \n",
       "2      77.552059         Vasanthapura    10852             4.0   \n",
       "3      77.513787          Hemmigepura     1652             3.0   \n",
       "4      77.642221             Horamavu     5437             1.0   \n",
       "...          ...                  ...      ...             ...   \n",
       "13300  77.749972            Hagadooru     4003             1.0   \n",
       "13301  77.614948        Sagayarapuram    45792             1.0   \n",
       "13302  77.520640  Rajarajeshwarinagar     5112            14.0   \n",
       "13303  77.556773      Padmanabhanagar    24311             8.0   \n",
       "13304  77.652802      Outside of town    27566             NaN   \n",
       "\n",
       "       nearest_high_school  high_schools_3km  nearest_hospital  hospitals_5km  \n",
       "0                 0.842733                 4          0.702709             17  \n",
       "1                 8.578895                 0         13.856962              0  \n",
       "2                 0.000000                17          1.034118            132  \n",
       "3                 2.445457                 1          3.403518              9  \n",
       "4                 1.549047                 4          0.537671             48  \n",
       "...                    ...               ...               ...            ...  \n",
       "13300             0.714559                 6          0.000000             39  \n",
       "13301             1.464174                12          0.328717            158  \n",
       "13302             0.840693                10          0.197452             50  \n",
       "13303             0.109952                22          0.148021            163  \n",
       "13304             0.489148                 3          0.530349             20  \n",
       "\n",
       "[13305 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = find_nearest_places(df4, hospitals, \"hospitals_5km\", \"nearest_hospital\", 5)\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8c39a",
   "metadata": {},
   "source": [
    "#### Nearest Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f88f9b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>77.679381</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842733</td>\n",
       "      <td>4</td>\n",
       "      <td>0.702709</td>\n",
       "      <td>17</td>\n",
       "      <td>5.142606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>77.866742</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.578895</td>\n",
       "      <td>0</td>\n",
       "      <td>13.856962</td>\n",
       "      <td>0</td>\n",
       "      <td>11.292030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>77.552059</td>\n",
       "      <td>Vasanthapura</td>\n",
       "      <td>10852</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>132</td>\n",
       "      <td>3.612492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>77.513787</td>\n",
       "      <td>Hemmigepura</td>\n",
       "      <td>1652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.445457</td>\n",
       "      <td>1</td>\n",
       "      <td>3.403518</td>\n",
       "      <td>9</td>\n",
       "      <td>7.188967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>77.642221</td>\n",
       "      <td>Horamavu</td>\n",
       "      <td>5437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.549047</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>48</td>\n",
       "      <td>7.077577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>77.749972</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>12.268435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>77.614948</td>\n",
       "      <td>Sagayarapuram</td>\n",
       "      <td>45792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.464174</td>\n",
       "      <td>12</td>\n",
       "      <td>0.328717</td>\n",
       "      <td>158</td>\n",
       "      <td>3.789473</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>77.520640</td>\n",
       "      <td>Rajarajeshwarinagar</td>\n",
       "      <td>5112</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.840693</td>\n",
       "      <td>10</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>50</td>\n",
       "      <td>2.811538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>77.556773</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>24311</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>22</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>163</td>\n",
       "      <td>3.161392</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>77.652802</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489148</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530349</td>\n",
       "      <td>20</td>\n",
       "      <td>2.958492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193   \n",
       "...          ...      ...        ...   ...      ...     ...        ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916   \n",
       "\n",
       "            long                 ward  density  parks_per_ward  \\\n",
       "0      77.679381      Outside of town    27566             NaN   \n",
       "1      77.866742      Outside of town    27566             NaN   \n",
       "2      77.552059         Vasanthapura    10852             4.0   \n",
       "3      77.513787          Hemmigepura     1652             3.0   \n",
       "4      77.642221             Horamavu     5437             1.0   \n",
       "...          ...                  ...      ...             ...   \n",
       "13300  77.749972            Hagadooru     4003             1.0   \n",
       "13301  77.614948        Sagayarapuram    45792             1.0   \n",
       "13302  77.520640  Rajarajeshwarinagar     5112            14.0   \n",
       "13303  77.556773      Padmanabhanagar    24311             8.0   \n",
       "13304  77.652802      Outside of town    27566             NaN   \n",
       "\n",
       "       nearest_high_school  high_schools_3km  nearest_hospital  hospitals_5km  \\\n",
       "0                 0.842733                 4          0.702709             17   \n",
       "1                 8.578895                 0         13.856962              0   \n",
       "2                 0.000000                17          1.034118            132   \n",
       "3                 2.445457                 1          3.403518              9   \n",
       "4                 1.549047                 4          0.537671             48   \n",
       "...                    ...               ...               ...            ...   \n",
       "13300             0.714559                 6          0.000000             39   \n",
       "13301             1.464174                12          0.328717            158   \n",
       "13302             0.840693                10          0.197452             50   \n",
       "13303             0.109952                22          0.148021            163   \n",
       "13304             0.489148                 3          0.530349             20   \n",
       "\n",
       "       nearest_university  universities_5km  \n",
       "0                5.142606                 0  \n",
       "1               11.292030                 0  \n",
       "2                3.612492                 2  \n",
       "3                7.188967                 0  \n",
       "4                7.077577                 0  \n",
       "...                   ...               ...  \n",
       "13300           12.268435                 0  \n",
       "13301            3.789473                 5  \n",
       "13302            2.811538                 2  \n",
       "13303            3.161392                 2  \n",
       "13304            2.958492                 2  \n",
       "\n",
       "[13305 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = find_nearest_places(df5, universities, \"universities_5km\", \"nearest_university\", 5)\n",
    "\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20846b0a",
   "metadata": {},
   "source": [
    "#### Nearest Police Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a19262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>...</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842733</td>\n",
       "      <td>4</td>\n",
       "      <td>0.702709</td>\n",
       "      <td>17</td>\n",
       "      <td>5.142606</td>\n",
       "      <td>0</td>\n",
       "      <td>2.160838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>...</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.578895</td>\n",
       "      <td>0</td>\n",
       "      <td>13.856962</td>\n",
       "      <td>0</td>\n",
       "      <td>11.292030</td>\n",
       "      <td>0</td>\n",
       "      <td>6.912706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>...</td>\n",
       "      <td>10852</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>132</td>\n",
       "      <td>3.612492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.044202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>...</td>\n",
       "      <td>1652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.445457</td>\n",
       "      <td>1</td>\n",
       "      <td>3.403518</td>\n",
       "      <td>9</td>\n",
       "      <td>7.188967</td>\n",
       "      <td>0</td>\n",
       "      <td>2.283267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>...</td>\n",
       "      <td>5437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.549047</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>48</td>\n",
       "      <td>7.077577</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>...</td>\n",
       "      <td>4003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>12.268435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>...</td>\n",
       "      <td>45792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.464174</td>\n",
       "      <td>12</td>\n",
       "      <td>0.328717</td>\n",
       "      <td>158</td>\n",
       "      <td>3.789473</td>\n",
       "      <td>5</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>...</td>\n",
       "      <td>5112</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.840693</td>\n",
       "      <td>10</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>50</td>\n",
       "      <td>2.811538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>...</td>\n",
       "      <td>24311</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>22</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>163</td>\n",
       "      <td>3.161392</td>\n",
       "      <td>2</td>\n",
       "      <td>1.169012</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>...</td>\n",
       "      <td>27566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489148</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530349</td>\n",
       "      <td>20</td>\n",
       "      <td>2.958492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.173638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  ...  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149  ...   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745  ...   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982  ...   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358  ...   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193  ...   \n",
       "...          ...      ...        ...   ...      ...     ...        ...  ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820  ...   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322  ...   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860  ...   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569  ...   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916  ...   \n",
       "\n",
       "       density parks_per_ward  nearest_high_school  high_schools_3km  \\\n",
       "0        27566            NaN             0.842733                 4   \n",
       "1        27566            NaN             8.578895                 0   \n",
       "2        10852            4.0             0.000000                17   \n",
       "3         1652            3.0             2.445457                 1   \n",
       "4         5437            1.0             1.549047                 4   \n",
       "...        ...            ...                  ...               ...   \n",
       "13300     4003            1.0             0.714559                 6   \n",
       "13301    45792            1.0             1.464174                12   \n",
       "13302     5112           14.0             0.840693                10   \n",
       "13303    24311            8.0             0.109952                22   \n",
       "13304    27566            NaN             0.489148                 3   \n",
       "\n",
       "       nearest_hospital  hospitals_5km  nearest_university  universities_5km  \\\n",
       "0              0.702709             17            5.142606                 0   \n",
       "1             13.856962              0           11.292030                 0   \n",
       "2              1.034118            132            3.612492                 2   \n",
       "3              3.403518              9            7.188967                 0   \n",
       "4              0.537671             48            7.077577                 0   \n",
       "...                 ...            ...                 ...               ...   \n",
       "13300          0.000000             39           12.268435                 0   \n",
       "13301          0.328717            158            3.789473                 5   \n",
       "13302          0.197452             50            2.811538                 2   \n",
       "13303          0.148021            163            3.161392                 2   \n",
       "13304          0.530349             20            2.958492                 2   \n",
       "\n",
       "       nearest_police_station  police_stations_3km  \n",
       "0                    2.160838                    1  \n",
       "1                    6.912706                    0  \n",
       "2                    1.044202                    5  \n",
       "3                    2.283267                    1  \n",
       "4                    0.447469                    2  \n",
       "...                       ...                  ...  \n",
       "13300                0.629064                    2  \n",
       "13301                0.906158                    6  \n",
       "13302                0.222472                    3  \n",
       "13303                1.169012                    6  \n",
       "13304                1.173638                    1  \n",
       "\n",
       "[13305 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = find_nearest_places(df6, police_stations, \"police_stations_3km\", \"nearest_police_station\", 3)\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff2584",
   "metadata": {},
   "source": [
    "#### Nearest Parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69abe20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842733</td>\n",
       "      <td>4</td>\n",
       "      <td>0.702709</td>\n",
       "      <td>17</td>\n",
       "      <td>5.142606</td>\n",
       "      <td>0</td>\n",
       "      <td>2.160838</td>\n",
       "      <td>1</td>\n",
       "      <td>1.165816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>...</td>\n",
       "      <td>8.578895</td>\n",
       "      <td>0</td>\n",
       "      <td>13.856962</td>\n",
       "      <td>0</td>\n",
       "      <td>11.292030</td>\n",
       "      <td>0</td>\n",
       "      <td>6.912706</td>\n",
       "      <td>0</td>\n",
       "      <td>7.916471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>132</td>\n",
       "      <td>3.612492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.044202</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>...</td>\n",
       "      <td>2.445457</td>\n",
       "      <td>1</td>\n",
       "      <td>3.403518</td>\n",
       "      <td>9</td>\n",
       "      <td>7.188967</td>\n",
       "      <td>0</td>\n",
       "      <td>2.283267</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>...</td>\n",
       "      <td>1.549047</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>48</td>\n",
       "      <td>7.077577</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447469</td>\n",
       "      <td>2</td>\n",
       "      <td>1.939158</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>12.268435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629064</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293975</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>...</td>\n",
       "      <td>1.464174</td>\n",
       "      <td>12</td>\n",
       "      <td>0.328717</td>\n",
       "      <td>158</td>\n",
       "      <td>3.789473</td>\n",
       "      <td>5</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840693</td>\n",
       "      <td>10</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>50</td>\n",
       "      <td>2.811538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109952</td>\n",
       "      <td>22</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>163</td>\n",
       "      <td>3.161392</td>\n",
       "      <td>2</td>\n",
       "      <td>1.169012</td>\n",
       "      <td>6</td>\n",
       "      <td>0.161497</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489148</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530349</td>\n",
       "      <td>20</td>\n",
       "      <td>2.958492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.173638</td>\n",
       "      <td>1</td>\n",
       "      <td>2.607392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  ...  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149  ...   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745  ...   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982  ...   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358  ...   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193  ...   \n",
       "...          ...      ...        ...   ...      ...     ...        ...  ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820  ...   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322  ...   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860  ...   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569  ...   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916  ...   \n",
       "\n",
       "       nearest_high_school high_schools_3km  nearest_hospital  hospitals_5km  \\\n",
       "0                 0.842733                4          0.702709             17   \n",
       "1                 8.578895                0         13.856962              0   \n",
       "2                 0.000000               17          1.034118            132   \n",
       "3                 2.445457                1          3.403518              9   \n",
       "4                 1.549047                4          0.537671             48   \n",
       "...                    ...              ...               ...            ...   \n",
       "13300             0.714559                6          0.000000             39   \n",
       "13301             1.464174               12          0.328717            158   \n",
       "13302             0.840693               10          0.197452             50   \n",
       "13303             0.109952               22          0.148021            163   \n",
       "13304             0.489148                3          0.530349             20   \n",
       "\n",
       "       nearest_university  universities_5km  nearest_police_station  \\\n",
       "0                5.142606                 0                2.160838   \n",
       "1               11.292030                 0                6.912706   \n",
       "2                3.612492                 2                1.044202   \n",
       "3                7.188967                 0                2.283267   \n",
       "4                7.077577                 0                0.447469   \n",
       "...                   ...               ...                     ...   \n",
       "13300           12.268435                 0                0.629064   \n",
       "13301            3.789473                 5                0.906158   \n",
       "13302            2.811538                 2                0.222472   \n",
       "13303            3.161392                 2                1.169012   \n",
       "13304            2.958492                 2                1.173638   \n",
       "\n",
       "       police_stations_3km  nearest_park  parks_3km  \n",
       "0                        1      1.165816          3  \n",
       "1                        0      7.916471          0  \n",
       "2                        5      0.000000         51  \n",
       "3                        1      1.466480          1  \n",
       "4                        2      1.939158         16  \n",
       "...                    ...           ...        ...  \n",
       "13300                    2      0.293975          2  \n",
       "13301                    6      0.000000         40  \n",
       "13302                    3      0.000000         22  \n",
       "13303                    6      0.161497         66  \n",
       "13304                    1      2.607392          1  \n",
       "\n",
       "[13305 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7b = find_nearest_places(df7, parks, \"parks_3km\", \"nearest_park\", 3)\n",
    "\n",
    "df7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68171c49",
   "metadata": {},
   "source": [
    "#### Nearest Primary Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3b87eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702709</td>\n",
       "      <td>17</td>\n",
       "      <td>5.142606</td>\n",
       "      <td>0</td>\n",
       "      <td>2.160838</td>\n",
       "      <td>1</td>\n",
       "      <td>1.165816</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804007</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>...</td>\n",
       "      <td>13.856962</td>\n",
       "      <td>0</td>\n",
       "      <td>11.292030</td>\n",
       "      <td>0</td>\n",
       "      <td>6.912706</td>\n",
       "      <td>0</td>\n",
       "      <td>7.916471</td>\n",
       "      <td>0</td>\n",
       "      <td>2.268728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>132</td>\n",
       "      <td>3.612492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.044202</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>...</td>\n",
       "      <td>3.403518</td>\n",
       "      <td>9</td>\n",
       "      <td>7.188967</td>\n",
       "      <td>0</td>\n",
       "      <td>2.283267</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>48</td>\n",
       "      <td>7.077577</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447469</td>\n",
       "      <td>2</td>\n",
       "      <td>1.939158</td>\n",
       "      <td>16</td>\n",
       "      <td>0.889883</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Whitefield</td>\n",
       "      <td>5 Bedroom</td>\n",
       "      <td>ArsiaEx</td>\n",
       "      <td>3453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>12.268435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629064</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293975</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069651</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Richards Town</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.00</td>\n",
       "      <td>13.006322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328717</td>\n",
       "      <td>158</td>\n",
       "      <td>3.789473</td>\n",
       "      <td>5</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.363873</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13302</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Raja Rajeshwari Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Mahla T</td>\n",
       "      <td>1141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>12.914860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>50</td>\n",
       "      <td>2.811538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13303</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Jun</td>\n",
       "      <td>Padmanabhanagar</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>SollyCl</td>\n",
       "      <td>4689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>488.00</td>\n",
       "      <td>12.915569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>163</td>\n",
       "      <td>3.161392</td>\n",
       "      <td>2</td>\n",
       "      <td>1.169012</td>\n",
       "      <td>6</td>\n",
       "      <td>0.161497</td>\n",
       "      <td>66</td>\n",
       "      <td>0.440358</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13304</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Doddathoguru</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.847916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530349</td>\n",
       "      <td>20</td>\n",
       "      <td>2.958492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.173638</td>\n",
       "      <td>1</td>\n",
       "      <td>2.607392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.404010</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13305 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_type   availability                  location  \\\n",
       "0      Super built-up  Area         19-Dec  Electronic City Phase II   \n",
       "1                Plot  Area  Ready To Move          Chikka Tirupathi   \n",
       "2            Built-up  Area  Ready To Move               Uttarahalli   \n",
       "3      Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
       "4      Super built-up  Area  Ready To Move                  Kothanur   \n",
       "...                     ...            ...                       ...   \n",
       "13300        Built-up  Area  Ready To Move                Whitefield   \n",
       "13301  Super built-up  Area  Ready To Move             Richards Town   \n",
       "13302        Built-up  Area  Ready To Move     Raja Rajeshwari Nagar   \n",
       "13303  Super built-up  Area         18-Jun           Padmanabhanagar   \n",
       "13304  Super built-up  Area  Ready To Move              Doddathoguru   \n",
       "\n",
       "            size  society total_sqft  bath  balcony   price        lat  ...  \\\n",
       "0          2 BHK  Coomee        1056   2.0      1.0   39.07  12.844149  ...   \n",
       "1      4 Bedroom  Theanmp       2600   5.0      3.0  120.00  12.896745  ...   \n",
       "2          3 BHK      NaN       1440   2.0      3.0   62.00  12.906982  ...   \n",
       "3          3 BHK  Soiewre       1521   3.0      1.0   95.00  12.874358  ...   \n",
       "4          2 BHK      NaN       1200   2.0      1.0   51.00  13.055193  ...   \n",
       "...          ...      ...        ...   ...      ...     ...        ...  ...   \n",
       "13300  5 Bedroom  ArsiaEx       3453   4.0      0.0  231.00  12.969820  ...   \n",
       "13301      4 BHK      NaN       3600   5.0      NaN  400.00  13.006322  ...   \n",
       "13302      2 BHK  Mahla T       1141   2.0      1.0   60.00  12.914860  ...   \n",
       "13303      4 BHK  SollyCl       4689   4.0      1.0  488.00  12.915569  ...   \n",
       "13304      1 BHK      NaN        550   1.0      1.0   17.00  12.847916  ...   \n",
       "\n",
       "       nearest_hospital hospitals_5km  nearest_university  universities_5km  \\\n",
       "0              0.702709            17            5.142606                 0   \n",
       "1             13.856962             0           11.292030                 0   \n",
       "2              1.034118           132            3.612492                 2   \n",
       "3              3.403518             9            7.188967                 0   \n",
       "4              0.537671            48            7.077577                 0   \n",
       "...                 ...           ...                 ...               ...   \n",
       "13300          0.000000            39           12.268435                 0   \n",
       "13301          0.328717           158            3.789473                 5   \n",
       "13302          0.197452            50            2.811538                 2   \n",
       "13303          0.148021           163            3.161392                 2   \n",
       "13304          0.530349            20            2.958492                 2   \n",
       "\n",
       "       nearest_police_station  police_stations_3km  nearest_park  parks_3km  \\\n",
       "0                    2.160838                    1      1.165816          3   \n",
       "1                    6.912706                    0      7.916471          0   \n",
       "2                    1.044202                    5      0.000000         51   \n",
       "3                    2.283267                    1      1.466480          1   \n",
       "4                    0.447469                    2      1.939158         16   \n",
       "...                       ...                  ...           ...        ...   \n",
       "13300                0.629064                    2      0.293975          2   \n",
       "13301                0.906158                    6      0.000000         40   \n",
       "13302                0.222472                    3      0.000000         22   \n",
       "13303                1.169012                    6      0.161497         66   \n",
       "13304                1.173638                    1      2.607392          1   \n",
       "\n",
       "       nearest_primary_school  primary_schools_2km  \n",
       "0                    0.804007                   12  \n",
       "1                    2.268728                    0  \n",
       "2                    0.000000                   27  \n",
       "3                    0.189312                    3  \n",
       "4                    0.889883                    8  \n",
       "...                       ...                  ...  \n",
       "13300                0.069651                   15  \n",
       "13301                0.363873                   41  \n",
       "13302                0.000000                    8  \n",
       "13303                0.440358                   29  \n",
       "13304                0.404010                   10  \n",
       "\n",
       "[13305 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7c = find_nearest_places(df7b, primary_schools, \"primary_schools_2km\", \"nearest_primary_school\", 2)\n",
    "\n",
    "df7c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b0354",
   "metadata": {},
   "source": [
    "#### Save the current status of the dataframe after the feature expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5765bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7c.to_csv('new_train_set2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48d14df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>19-Dec</td>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Coomee</td>\n",
       "      <td>1056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702709</td>\n",
       "      <td>17</td>\n",
       "      <td>5.142606</td>\n",
       "      <td>0</td>\n",
       "      <td>2.160838</td>\n",
       "      <td>1</td>\n",
       "      <td>1.165816</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804007</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Theanmp</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>...</td>\n",
       "      <td>13.856962</td>\n",
       "      <td>0</td>\n",
       "      <td>11.292030</td>\n",
       "      <td>0</td>\n",
       "      <td>6.912706</td>\n",
       "      <td>0</td>\n",
       "      <td>7.916471</td>\n",
       "      <td>0</td>\n",
       "      <td>2.268728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034118</td>\n",
       "      <td>132</td>\n",
       "      <td>3.612492</td>\n",
       "      <td>2</td>\n",
       "      <td>1.044202</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Soiewre</td>\n",
       "      <td>1521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>...</td>\n",
       "      <td>3.403518</td>\n",
       "      <td>9</td>\n",
       "      <td>7.188967</td>\n",
       "      <td>0</td>\n",
       "      <td>2.283267</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kothanur</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>48</td>\n",
       "      <td>7.077577</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447469</td>\n",
       "      <td>2</td>\n",
       "      <td>1.939158</td>\n",
       "      <td>16</td>\n",
       "      <td>0.889883</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              area_type   availability                  location       size  \\\n",
       "0  Super built-up  Area         19-Dec  Electronic City Phase II      2 BHK   \n",
       "1            Plot  Area  Ready To Move          Chikka Tirupathi  4 Bedroom   \n",
       "2        Built-up  Area  Ready To Move               Uttarahalli      3 BHK   \n",
       "3  Super built-up  Area  Ready To Move        Lingadheeranahalli      3 BHK   \n",
       "4  Super built-up  Area  Ready To Move                  Kothanur      2 BHK   \n",
       "\n",
       "   society total_sqft  bath  balcony   price        lat  ...  \\\n",
       "0  Coomee        1056   2.0      1.0   39.07  12.844149  ...   \n",
       "1  Theanmp       2600   5.0      3.0  120.00  12.896745  ...   \n",
       "2      NaN       1440   2.0      3.0   62.00  12.906982  ...   \n",
       "3  Soiewre       1521   3.0      1.0   95.00  12.874358  ...   \n",
       "4      NaN       1200   2.0      1.0   51.00  13.055193  ...   \n",
       "\n",
       "   nearest_hospital hospitals_5km  nearest_university  universities_5km  \\\n",
       "0          0.702709            17            5.142606                 0   \n",
       "1         13.856962             0           11.292030                 0   \n",
       "2          1.034118           132            3.612492                 2   \n",
       "3          3.403518             9            7.188967                 0   \n",
       "4          0.537671            48            7.077577                 0   \n",
       "\n",
       "   nearest_police_station  police_stations_3km  nearest_park  parks_3km  \\\n",
       "0                2.160838                    1      1.165816          3   \n",
       "1                6.912706                    0      7.916471          0   \n",
       "2                1.044202                    5      0.000000         51   \n",
       "3                2.283267                    1      1.466480          1   \n",
       "4                0.447469                    2      1.939158         16   \n",
       "\n",
       "   nearest_primary_school  primary_schools_2km  \n",
       "0                0.804007                   12  \n",
       "1                2.268728                    0  \n",
       "2                0.000000                   27  \n",
       "3                0.189312                    3  \n",
       "4                0.889883                    8  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = df7c.reset_index(drop=True)\n",
    "\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfecfab",
   "metadata": {},
   "source": [
    "### We will now start evaluating our data and cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed456cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13305, 26)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3d8a8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area_type', 'availability', 'location', 'size', 'society',\n",
       "       'total_sqft', 'bath', 'balcony', 'price', 'lat', 'long', 'ward',\n",
       "       'density', 'parks_per_ward', 'nearest_high_school', 'high_schools_3km',\n",
       "       'nearest_hospital', 'hospitals_5km', 'nearest_university',\n",
       "       'universities_5km', 'nearest_police_station', 'police_stations_3km',\n",
       "       'nearest_park', 'parks_3km', 'nearest_primary_school',\n",
       "       'primary_schools_2km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2978fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area_type                  object\n",
       "availability               object\n",
       "location                   object\n",
       "size                       object\n",
       "society                    object\n",
       "total_sqft                 object\n",
       "bath                      float64\n",
       "balcony                   float64\n",
       "price                     float64\n",
       "lat                       float64\n",
       "long                      float64\n",
       "ward                       object\n",
       "density                     int64\n",
       "parks_per_ward            float64\n",
       "nearest_high_school       float64\n",
       "high_schools_3km            int32\n",
       "nearest_hospital          float64\n",
       "hospitals_5km               int32\n",
       "nearest_university        float64\n",
       "universities_5km            int32\n",
       "nearest_police_station    float64\n",
       "police_stations_3km         int32\n",
       "nearest_park              float64\n",
       "parks_3km                   int32\n",
       "nearest_primary_school    float64\n",
       "primary_schools_2km         int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd18dd",
   "metadata": {},
   "source": [
    "#### Drop unecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c38b03d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area_type                    0\n",
       "availability                 0\n",
       "location                     0\n",
       "size                        16\n",
       "society                   5488\n",
       "total_sqft                   0\n",
       "bath                        73\n",
       "balcony                    608\n",
       "price                        0\n",
       "lat                          0\n",
       "long                         0\n",
       "ward                         0\n",
       "density                      0\n",
       "parks_per_ward            2501\n",
       "nearest_high_school          0\n",
       "high_schools_3km             0\n",
       "nearest_hospital             0\n",
       "hospitals_5km                0\n",
       "nearest_university           0\n",
       "universities_5km             0\n",
       "nearest_police_station       0\n",
       "police_stations_3km          0\n",
       "nearest_park                 0\n",
       "parks_3km                    0\n",
       "nearest_primary_school       0\n",
       "primary_schools_2km          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61aba0d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Super built-up  Area    8787\n",
       "Built-up  Area          2415\n",
       "Plot  Area              2016\n",
       "Carpet  Area              87\n",
       "Name: area_type, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.area_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c88fe4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df8.area_type.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ef6e9",
   "metadata": {},
   "source": [
    "#### Replacing availability with the 'ready_to_move' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4830bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df8.copy()\n",
    "df9['ready_to_move'] = df9['availability'].apply(lambda x: 1 if x == 'Ready To Move' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "006c6898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location                   object\n",
       "size                       object\n",
       "total_sqft                 object\n",
       "bath                      float64\n",
       "price                     float64\n",
       "lat                       float64\n",
       "long                      float64\n",
       "ward                       object\n",
       "density                     int64\n",
       "parks_per_ward            float64\n",
       "nearest_high_school       float64\n",
       "high_schools_3km            int32\n",
       "nearest_hospital          float64\n",
       "hospitals_5km               int32\n",
       "nearest_university        float64\n",
       "universities_5km            int32\n",
       "nearest_police_station    float64\n",
       "police_stations_3km         int32\n",
       "nearest_park              float64\n",
       "parks_3km                   int32\n",
       "nearest_primary_school    float64\n",
       "primary_schools_2km         int32\n",
       "ready_to_move               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10 = df9.copy()\n",
    "df10.drop(columns=['availability','area_type', 'society', 'balcony'],inplace = True)\n",
    "df10.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755b99e",
   "metadata": {},
   "source": [
    "#### Convert object type columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33417533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df10.copy()\n",
    "# extract the number of bedrooms from the 'size' column\n",
    "df11['bedrooms'] = df11['size'].str.split().str[0]\n",
    "\n",
    "# replace empty strings with NaN values\n",
    "df11['bedrooms'] = df11['bedrooms'].replace('', pd.NA)\n",
    "\n",
    "# drop rows with NaN values in the 'bedrooms' column\n",
    "df11 = df11.dropna(subset=['bedrooms'])\n",
    "df11 = df11.reset_index(drop=True)\n",
    "df11['bedrooms'] = df11['bedrooms'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7a2fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = df11.copy()\n",
    "df12['bath'] = df12['bath'].fillna(df12['bath'].notnull().mean())\n",
    "df12['bath'] = df12['bath'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cdd4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12['parks_per_ward'] = df12['parks_per_ward'].fillna(df12['parks_per_ward'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6062ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13 = df12.copy()\n",
    "df13['studio'] = df13['size'].apply(lambda x: 0 if x.split()[1] == 'BHK' else 1)\n",
    "df13.drop(columns=['size'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e8abf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location                  0\n",
       "total_sqft                0\n",
       "bath                      0\n",
       "price                     0\n",
       "lat                       0\n",
       "long                      0\n",
       "ward                      0\n",
       "density                   0\n",
       "parks_per_ward            0\n",
       "nearest_high_school       0\n",
       "high_schools_3km          0\n",
       "nearest_hospital          0\n",
       "hospitals_5km             0\n",
       "nearest_university        0\n",
       "universities_5km          0\n",
       "nearest_police_station    0\n",
       "police_stations_3km       0\n",
       "nearest_park              0\n",
       "parks_3km                 0\n",
       "nearest_primary_school    0\n",
       "primary_schools_2km       0\n",
       "ready_to_move             0\n",
       "bedrooms                  0\n",
       "studio                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df13.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e6fdbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bf06527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>...</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Yelahanka</td>\n",
       "      <td>2100 - 2850</td>\n",
       "      <td>4</td>\n",
       "      <td>186.000</td>\n",
       "      <td>13.115466</td>\n",
       "      <td>77.606998</td>\n",
       "      <td>Kempegowda Ward</td>\n",
       "      <td>3182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Devanahalli</td>\n",
       "      <td>3010 - 3410</td>\n",
       "      <td>0</td>\n",
       "      <td>192.000</td>\n",
       "      <td>13.150773</td>\n",
       "      <td>77.708811</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>4.257527</td>\n",
       "      <td>4.934797</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.349833</td>\n",
       "      <td>0</td>\n",
       "      <td>9.734515</td>\n",
       "      <td>0</td>\n",
       "      <td>2.896529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>2957 - 3450</td>\n",
       "      <td>0</td>\n",
       "      <td>224.500</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>5</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Hebbal</td>\n",
       "      <td>3067 - 8156</td>\n",
       "      <td>4</td>\n",
       "      <td>477.000</td>\n",
       "      <td>13.035356</td>\n",
       "      <td>77.598787</td>\n",
       "      <td>Hebbala</td>\n",
       "      <td>26455</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.656391</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.049216</td>\n",
       "      <td>6</td>\n",
       "      <td>0.339309</td>\n",
       "      <td>17</td>\n",
       "      <td>0.210874</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>8th Phase JP Nagar</td>\n",
       "      <td>1042 - 1105</td>\n",
       "      <td>2</td>\n",
       "      <td>54.005</td>\n",
       "      <td>12.874108</td>\n",
       "      <td>77.579173</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>7049</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.614314</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.764432</td>\n",
       "      <td>2</td>\n",
       "      <td>0.485631</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Sarjapur</td>\n",
       "      <td>1145 - 1340</td>\n",
       "      <td>2</td>\n",
       "      <td>43.490</td>\n",
       "      <td>12.857558</td>\n",
       "      <td>77.786406</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>4.257527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.245514</td>\n",
       "      <td>0</td>\n",
       "      <td>11.063105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>KR Puram</td>\n",
       "      <td>1015 - 1540</td>\n",
       "      <td>2</td>\n",
       "      <td>56.800</td>\n",
       "      <td>13.016999</td>\n",
       "      <td>77.704433</td>\n",
       "      <td>Krishnarajapuram</td>\n",
       "      <td>7308</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.745847</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.688187</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Devanahalli</td>\n",
       "      <td>1520 - 1740</td>\n",
       "      <td>0</td>\n",
       "      <td>74.820</td>\n",
       "      <td>13.150773</td>\n",
       "      <td>77.708811</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>4.257527</td>\n",
       "      <td>4.934797</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.349833</td>\n",
       "      <td>0</td>\n",
       "      <td>9.734515</td>\n",
       "      <td>0</td>\n",
       "      <td>2.896529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Kengeri</td>\n",
       "      <td>34.46Sq. Meter</td>\n",
       "      <td>1</td>\n",
       "      <td>18.500</td>\n",
       "      <td>12.899668</td>\n",
       "      <td>77.482684</td>\n",
       "      <td>Hemmigepura</td>\n",
       "      <td>1652</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.143172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.150818</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>1195 - 1440</td>\n",
       "      <td>2</td>\n",
       "      <td>63.770</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>5</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               location      total_sqft  bath    price        lat       long  \\\n",
       "30            Yelahanka     2100 - 2850     4  186.000  13.115466  77.606998   \n",
       "56          Devanahalli     3010 - 3410     0  192.000  13.150773  77.708811   \n",
       "81          Hennur Road     2957 - 3450     0  224.500  13.013906  77.626650   \n",
       "122              Hebbal     3067 - 8156     4  477.000  13.035356  77.598787   \n",
       "137  8th Phase JP Nagar     1042 - 1105     2   54.005  12.874108  77.579173   \n",
       "165            Sarjapur     1145 - 1340     2   43.490  12.857558  77.786406   \n",
       "188            KR Puram     1015 - 1540     2   56.800  13.016999  77.704433   \n",
       "224         Devanahalli     1520 - 1740     0   74.820  13.150773  77.708811   \n",
       "410             Kengeri  34.46Sq. Meter     1   18.500  12.899668  77.482684   \n",
       "549         Hennur Road     1195 - 1440     2   63.770  13.013906  77.626650   \n",
       "\n",
       "                 ward  density  parks_per_ward  nearest_high_school  ...  \\\n",
       "30    Kempegowda Ward     3182        0.000000             0.000000  ...   \n",
       "56    Outside of town    27566        4.257527             4.934797  ...   \n",
       "81         HBR Layout    12717        5.000000             1.220832  ...   \n",
       "122           Hebbala    26455        5.000000             0.656391  ...   \n",
       "137         Gottigere     7049        2.000000             0.614314  ...   \n",
       "165   Outside of town    27566        4.257527             0.000000  ...   \n",
       "188  Krishnarajapuram     7308        3.000000             0.745847  ...   \n",
       "224   Outside of town    27566        4.257527             4.934797  ...   \n",
       "410       Hemmigepura     1652        3.000000             1.143172  ...   \n",
       "549        HBR Layout    12717        5.000000             1.220832  ...   \n",
       "\n",
       "     universities_5km  nearest_police_station  police_stations_3km  \\\n",
       "30                  0                0.000000                    1   \n",
       "56                  0                5.349833                    0   \n",
       "81                  1                1.773094                    5   \n",
       "122                 1                1.049216                    6   \n",
       "137                 0                1.764432                    2   \n",
       "165                 1                9.245514                    0   \n",
       "188                 0                0.000000                    3   \n",
       "224                 0                5.349833                    0   \n",
       "410                 0                1.150818                    2   \n",
       "549                 1                1.773094                    5   \n",
       "\n",
       "     nearest_park  parks_3km  nearest_primary_school  primary_schools_2km  \\\n",
       "30       0.000000         14                0.000000                   99   \n",
       "56       9.734515          0                2.896529                    0   \n",
       "81       0.108980         43                0.000000                   37   \n",
       "122      0.339309         17                0.210874                   37   \n",
       "137      0.485631         18                0.000000                   11   \n",
       "165     11.063105          0                0.000000                   24   \n",
       "188      0.688187          4                0.000000                   12   \n",
       "224      9.734515          0                2.896529                    0   \n",
       "410      0.000000         11                0.000000                   17   \n",
       "549      0.108980         43                0.000000                   37   \n",
       "\n",
       "     ready_to_move  bedrooms  studio  \n",
       "30               0         4       0  \n",
       "56               0         4       1  \n",
       "81               0         4       1  \n",
       "122              0         4       0  \n",
       "137              0         2       0  \n",
       "165              0         2       0  \n",
       "188              1         2       0  \n",
       "224              0         3       0  \n",
       "410              1         1       0  \n",
       "549              0         2       0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df13[~df13[\"total_sqft\"].apply(is_float)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d48ddbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion factors for non-numeric units\n",
    "conversion_dict = {\"Sq Meter\": 10.7639, \"Sq Yards\": 9, \"Acres\": 43560, \"Cents\": 435.6, \"Grounds\": 2400, \"Guntha\": 1089, \"Perch\": 272.25}\n",
    "\n",
    "def convert_to_sqft(value):\n",
    "    # check if value contains non-numeric unit\n",
    "    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*([a-zA-Z]+\\.*\\s*[a-zA-Z]*)', value)\n",
    "    if match:\n",
    "        numeric_value = float(match.group(1))\n",
    "        unit = match.group(2).strip().replace(\".\", \"\")\n",
    "        #print(unit)\n",
    "        # check if unit is in the conversion dictionary\n",
    "        if unit in conversion_dict:\n",
    "            # convert to square feet using conversion factor\n",
    "            sqft_value = numeric_value * conversion_dict[unit]\n",
    "            return int(sqft_value)\n",
    "    # if value does not contain a non-numeric unit, check if it is a range\n",
    "    elif '-' in value:\n",
    "        # extract range values\n",
    "        range_values = value.split('-')\n",
    "        # calculate median value of range\n",
    "        median_value = sum(map(float, range_values)) / len(range_values)\n",
    "        return int(median_value)\n",
    "    # if value is a single numeric value, convert to int\n",
    "    else:\n",
    "        if(value[-1]=='.'):\n",
    "            value = value[:-1]\n",
    "        numeric_value = float(re.sub('[^0-9\\.]', '', value))\n",
    "        return int(numeric_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7f703df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of maximum value: 1083\n",
      "location                       Narasapura\n",
      "total_sqft                        1306800\n",
      "bath                                    2\n",
      "price                                29.5\n",
      "lat                             13.109186\n",
      "long                            77.463026\n",
      "ward                      Outside of town\n",
      "density                             27566\n",
      "parks_per_ward                   4.257527\n",
      "nearest_high_school              3.167841\n",
      "high_schools_3km                        0\n",
      "nearest_hospital                 3.553192\n",
      "hospitals_5km                           1\n",
      "nearest_university              10.209925\n",
      "universities_5km                        0\n",
      "nearest_police_station           3.309776\n",
      "police_stations_3km                     0\n",
      "nearest_park                     6.628473\n",
      "parks_3km                               0\n",
      "nearest_primary_school           0.037024\n",
      "primary_schools_2km                     4\n",
      "ready_to_move                           0\n",
      "bedrooms                                2\n",
      "studio                                  1\n",
      "Name: 1083, dtype: object\n",
      "location                       Narasapura\n",
      "total_sqft                        30Acres\n",
      "bath                                    2\n",
      "price                                29.5\n",
      "lat                             13.109186\n",
      "long                            77.463026\n",
      "ward                      Outside of town\n",
      "density                             27566\n",
      "parks_per_ward                   4.257527\n",
      "nearest_high_school              3.167841\n",
      "high_schools_3km                        0\n",
      "nearest_hospital                 3.553192\n",
      "hospitals_5km                           1\n",
      "nearest_university              10.209925\n",
      "universities_5km                        0\n",
      "nearest_police_station           3.309776\n",
      "police_stations_3km                     0\n",
      "nearest_park                     6.628473\n",
      "parks_3km                               0\n",
      "nearest_primary_school           0.037024\n",
      "primary_schools_2km                     4\n",
      "ready_to_move                           0\n",
      "bedrooms                                2\n",
      "studio                                  1\n",
      "Name: 1083, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df14 = df13.copy()\n",
    "df14['total_sqft'] = df14['total_sqft'].apply(convert_to_sqft)\n",
    "max_id = df14['total_sqft'].idxmax()\n",
    "\n",
    "print('ID of maximum value:', max_id)\n",
    "print(df14.loc[max_id])\n",
    "print(df13.loc[max_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3765f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>...</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [location, total_sqft, bath, price, lat, long, ward, density, parks_per_ward, nearest_high_school, high_schools_3km, nearest_hospital, hospitals_5km, nearest_university, universities_5km, nearest_police_station, police_stations_3km, nearest_park, parks_3km, nearest_primary_school, primary_schools_2km, ready_to_move, bedrooms, studio]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df14[~df14[\"total_sqft\"].apply(is_float)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "231e85bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>...</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [location, total_sqft, bath, price, lat, long, ward, density, parks_per_ward, nearest_high_school, high_schools_3km, nearest_hospital, hospitals_5km, nearest_university, universities_5km, nearest_police_station, police_stations_3km, nearest_park, parks_3km, nearest_primary_school, primary_schools_2km, ready_to_move, bedrooms, studio]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df14[df14[\"total_sqft\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15c38538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1056\n",
       "1        2600\n",
       "2        1440\n",
       "3        1521\n",
       "4        1200\n",
       "         ... \n",
       "13284    3453\n",
       "13285    3600\n",
       "13286    1141\n",
       "13287    4689\n",
       "13288     550\n",
       "Name: total_sqft, Length: 13289, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df14[\"total_sqft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ef523cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location                   object\n",
       "total_sqft                  int64\n",
       "bath                        int32\n",
       "price                     float64\n",
       "lat                       float64\n",
       "long                      float64\n",
       "ward                       object\n",
       "density                     int64\n",
       "parks_per_ward            float64\n",
       "nearest_high_school       float64\n",
       "high_schools_3km            int32\n",
       "nearest_hospital          float64\n",
       "hospitals_5km               int32\n",
       "nearest_university        float64\n",
       "universities_5km            int32\n",
       "nearest_police_station    float64\n",
       "police_stations_3km         int32\n",
       "nearest_park              float64\n",
       "parks_3km                   int32\n",
       "nearest_primary_school    float64\n",
       "primary_schools_2km         int32\n",
       "ready_to_move               int64\n",
       "bedrooms                    int32\n",
       "studio                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df14.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f99be",
   "metadata": {},
   "source": [
    "#### We will deal with location and wards at a later stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6fde5",
   "metadata": {},
   "source": [
    "### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d7eec56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12947, 24)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15 = df14[~(df14.total_sqft/df14.bedrooms<200)]\n",
    "df15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ac880b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select the three columns you want to plot\n",
    "column1 = 'bedrooms'\n",
    "column2 = 'bath'\n",
    "column3 = 'total_sqft'\n",
    "\n",
    "# create a figure with three subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "# plot the boxplots of the three columns in each subplot\n",
    "axs[0].boxplot(df15[column1])\n",
    "axs[0].set_title(column1)\n",
    "axs[1].boxplot(df15[column2])\n",
    "axs[1].set_title(column2)\n",
    "axs[2].boxplot(df15[column3])\n",
    "axs[2].set_title(column3)\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "395c1df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12803, 24)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df16 = df15.copy()\n",
    "df16 = df16.drop(df16[df16['bath']>6].index)\n",
    "df16 = df16.drop(df16[df16['bedrooms']>7.0].index)\n",
    "df16.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f974c6c9",
   "metadata": {},
   "source": [
    "#### Creating a new columns named 'price_per_sqft' that is going to be used for outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c1ff24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>studio</th>\n",
       "      <th>price_per_sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electronic City Phase II</td>\n",
       "      <td>1056</td>\n",
       "      <td>2</td>\n",
       "      <td>39.07</td>\n",
       "      <td>12.844149</td>\n",
       "      <td>77.679381</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>4.257527</td>\n",
       "      <td>0.842733</td>\n",
       "      <td>...</td>\n",
       "      <td>2.160838</td>\n",
       "      <td>1</td>\n",
       "      <td>1.165816</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804007</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36998.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chikka Tirupathi</td>\n",
       "      <td>2600</td>\n",
       "      <td>5</td>\n",
       "      <td>120.00</td>\n",
       "      <td>12.896745</td>\n",
       "      <td>77.866742</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566</td>\n",
       "      <td>4.257527</td>\n",
       "      <td>8.578895</td>\n",
       "      <td>...</td>\n",
       "      <td>6.912706</td>\n",
       "      <td>0</td>\n",
       "      <td>7.916471</td>\n",
       "      <td>0</td>\n",
       "      <td>2.268728</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46153.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uttarahalli</td>\n",
       "      <td>1440</td>\n",
       "      <td>2</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.906982</td>\n",
       "      <td>77.552059</td>\n",
       "      <td>Vasanthapura</td>\n",
       "      <td>10852</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044202</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>43055.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lingadheeranahalli</td>\n",
       "      <td>1521</td>\n",
       "      <td>3</td>\n",
       "      <td>95.00</td>\n",
       "      <td>12.874358</td>\n",
       "      <td>77.513787</td>\n",
       "      <td>Hemmigepura</td>\n",
       "      <td>1652</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.445457</td>\n",
       "      <td>...</td>\n",
       "      <td>2.283267</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62458.908613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kothanur</td>\n",
       "      <td>1200</td>\n",
       "      <td>2</td>\n",
       "      <td>51.00</td>\n",
       "      <td>13.055193</td>\n",
       "      <td>77.642221</td>\n",
       "      <td>Horamavu</td>\n",
       "      <td>5437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.549047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447469</td>\n",
       "      <td>2</td>\n",
       "      <td>1.939158</td>\n",
       "      <td>16</td>\n",
       "      <td>0.889883</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   location  total_sqft  bath   price        lat       long  \\\n",
       "0  Electronic City Phase II        1056     2   39.07  12.844149  77.679381   \n",
       "1          Chikka Tirupathi        2600     5  120.00  12.896745  77.866742   \n",
       "2               Uttarahalli        1440     2   62.00  12.906982  77.552059   \n",
       "3        Lingadheeranahalli        1521     3   95.00  12.874358  77.513787   \n",
       "4                  Kothanur        1200     2   51.00  13.055193  77.642221   \n",
       "\n",
       "              ward  density  parks_per_ward  nearest_high_school  ...  \\\n",
       "0  Outside of town    27566        4.257527             0.842733  ...   \n",
       "1  Outside of town    27566        4.257527             8.578895  ...   \n",
       "2     Vasanthapura    10852        4.000000             0.000000  ...   \n",
       "3      Hemmigepura     1652        3.000000             2.445457  ...   \n",
       "4         Horamavu     5437        1.000000             1.549047  ...   \n",
       "\n",
       "   nearest_police_station  police_stations_3km  nearest_park  parks_3km  \\\n",
       "0                2.160838                    1      1.165816          3   \n",
       "1                6.912706                    0      7.916471          0   \n",
       "2                1.044202                    5      0.000000         51   \n",
       "3                2.283267                    1      1.466480          1   \n",
       "4                0.447469                    2      1.939158         16   \n",
       "\n",
       "   nearest_primary_school  primary_schools_2km  ready_to_move  bedrooms  \\\n",
       "0                0.804007                   12              0         2   \n",
       "1                2.268728                    0              1         4   \n",
       "2                0.000000                   27              1         3   \n",
       "3                0.189312                    3              1         3   \n",
       "4                0.889883                    8              1         2   \n",
       "\n",
       "   studio  price_per_sqft  \n",
       "0       0    36998.106061  \n",
       "1       1    46153.846154  \n",
       "2       0    43055.555556  \n",
       "3       0    62458.908613  \n",
       "4       0    42500.000000  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df17=df16.copy()\n",
    "df17[\"price_per_sqft\"]=df17[\"price\"]*1000000/df17[\"total_sqft\"]\n",
    "df17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c14f38",
   "metadata": {},
   "source": [
    "#### Checking for skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "145798f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness:\n",
      " total_sqft                82.790070\n",
      "price                      7.444456\n",
      "lat                        0.415428\n",
      "long                      -0.384092\n",
      "density                    0.917789\n",
      "parks_per_ward             2.883243\n",
      "nearest_high_school       37.455883\n",
      "nearest_hospital          23.776063\n",
      "nearest_university         7.280501\n",
      "nearest_police_station    19.249829\n",
      "nearest_park               4.259534\n",
      "nearest_primary_school    24.787675\n",
      "ready_to_move             -1.422203\n",
      "studio                     1.810233\n",
      "price_per_sqft             8.169132\n",
      "dtype: float64\n",
      "\n",
      "Kurtosis:\n",
      " total_sqft                7557.668683\n",
      "price                       94.207916\n",
      "lat                          1.196206\n",
      "long                        11.864653\n",
      "density                      0.499519\n",
      "parks_per_ward              10.616139\n",
      "nearest_high_school       2188.614332\n",
      "nearest_hospital          1196.463100\n",
      "nearest_university         230.418386\n",
      "nearest_police_station     900.748637\n",
      "nearest_park                42.512957\n",
      "nearest_primary_school    1010.630703\n",
      "ready_to_move                0.022666\n",
      "studio                       1.277142\n",
      "price_per_sqft             223.278393\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "num_cols = df17.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# calculate skewness and kurtosis for each column\n",
    "skewness = num_cols.skew()\n",
    "kurtosis = num_cols.kurtosis()\n",
    "\n",
    "# display the resulting series\n",
    "print(\"Skewness:\\n\", skewness)\n",
    "print(\"\\nKurtosis:\\n\", kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4677f8",
   "metadata": {},
   "source": [
    "#### Use of boxcox and logarithmic transformation to see which is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd2e2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_transform = 'price_per_sqft'\n",
    "\n",
    "# apply the Box-Cox transformation to the column\n",
    "transformed_col, lambda_value = boxcox(df17[col_to_transform])\n",
    "\n",
    "# add the transformed column to the DataFrame\n",
    "df17['transformed_col'] = transformed_col\n",
    "\n",
    "df17['transformed_col1'] = np.log(df17[col_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8deea410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness:\n",
      " total_sqft                82.790070\n",
      "price                      7.444456\n",
      "lat                        0.415428\n",
      "long                      -0.384092\n",
      "density                    0.917789\n",
      "parks_per_ward             2.883243\n",
      "nearest_high_school       37.455883\n",
      "nearest_hospital          23.776063\n",
      "nearest_university         7.280501\n",
      "nearest_police_station    19.249829\n",
      "nearest_park               4.259534\n",
      "nearest_primary_school    24.787675\n",
      "ready_to_move             -1.422203\n",
      "studio                     1.810233\n",
      "price_per_sqft             8.169132\n",
      "transformed_col            0.005762\n",
      "transformed_col1          -0.025119\n",
      "dtype: float64\n",
      "\n",
      "Kurtosis:\n",
      " total_sqft                7557.668683\n",
      "price                       94.207916\n",
      "lat                          1.196206\n",
      "long                        11.864653\n",
      "density                      0.499519\n",
      "parks_per_ward              10.616139\n",
      "nearest_high_school       2188.614332\n",
      "nearest_hospital          1196.463100\n",
      "nearest_university         230.418386\n",
      "nearest_police_station     900.748637\n",
      "nearest_park                42.512957\n",
      "nearest_primary_school    1010.630703\n",
      "ready_to_move                0.022666\n",
      "studio                       1.277142\n",
      "price_per_sqft             223.278393\n",
      "transformed_col             11.073979\n",
      "transformed_col1            11.469879\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "num_cols = df17.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# calculate skewness and kurtosis for each column\n",
    "skewness = num_cols.skew()\n",
    "kurtosis = num_cols.kurtosis()\n",
    "\n",
    "# display the resulting series\n",
    "print(\"Skewness:\\n\", skewness)\n",
    "print(\"\\nKurtosis:\\n\", kurtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09cf5eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select the column you want to plot\n",
    "column_to_plot = 'transformed_col'\n",
    "\n",
    "# create the histogram using matplotlib\n",
    "plt.hist(df17[column_to_plot], bins=1000, color='blue')\n",
    "\n",
    "# add x-axis and y-axis labels\n",
    "plt.xlabel(column_to_plot)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# add a title to the plot\n",
    "plt.title('Histogram of ' + column_to_plot)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ba0cf",
   "metadata": {},
   "source": [
    "#### Mean-STD Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a339b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8896, 27)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.transformed_col)\n",
    "        st = np.std(subdf.transformed_col)\n",
    "        reduced_df = subdf[(subdf.transformed_col>(m-st)) & (subdf.transformed_col<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df18 = remove_pps_outliers(df17)\n",
    "df18.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e57a39",
   "metadata": {},
   "source": [
    "#### Median-MAD Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e8223e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6424, 27)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_pps_outliers_mad(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = df['price_per_sqft'].median()\n",
    "        mad = sp.stats.median_abs_deviation(df['price_per_sqft'])\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-mad)) & (subdf.price_per_sqft<=(m+mad))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df18b = remove_pps_outliers_mad(df17)\n",
    "df18b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7013a",
   "metadata": {},
   "source": [
    "#### We will stick with a softer approach (Mean-STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9965e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select the column you want to plot\n",
    "column_to_plot = 'transformed_col'\n",
    "\n",
    "# create the histogram using matplotlib\n",
    "plt.hist(df18[column_to_plot], bins=1000, color='blue')\n",
    "\n",
    "# add x-axis and y-axis labels\n",
    "plt.xlabel(column_to_plot)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# add a title to the plot\n",
    "plt.title('Histogram of ' + column_to_plot)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fe2cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19 = df18.drop(columns=['transformed_col', 'transformed_col1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc441116",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df19.corr()\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(corr,mask = corr<0.7 ,annot= True,cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f73d2",
   "metadata": {},
   "source": [
    "#### Removing records with a location that appears in less than 10 records (Prone to false results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24d02dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whitefield              388\n",
       "Sarjapur  Road          280\n",
       "Kanakpura Road          240\n",
       "Electronic City         199\n",
       "Yelahanka               179\n",
       "                       ... \n",
       "Dasappa Layout            1\n",
       "Phase 1 Kammasandra       1\n",
       "Postal Colony             1\n",
       "Crimson Layout            1\n",
       "1st Block BEL Layout      1\n",
       "Name: location, Length: 773, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_stats = df19['location'].value_counts(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74e42d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Giri Nagar              10\n",
       "Bommenahalli            10\n",
       "Yelenahalli             10\n",
       "Yelachenahalli          10\n",
       "Dasarahalli             10\n",
       "                        ..\n",
       "Dasappa Layout           1\n",
       "Phase 1 Kammasandra      1\n",
       "Postal Colony            1\n",
       "Crimson Layout           1\n",
       "1st Block BEL Layout     1\n",
       "Name: location, Length: 595, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "location_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9da527c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1st Phase JP Nagar', '2nd Stage Nagarbhavi', '5th Phase JP Nagar',\n",
       "       '6th Phase JP Nagar', '7th Phase JP Nagar', '8th Phase JP Nagar',\n",
       "       '9th Phase JP Nagar', 'Abbigere', 'Akshaya Nagar', 'Ambalipura',\n",
       "       'Ambedkar Nagar', 'Amruthahalli', 'Anandapura', 'Ananth Nagar',\n",
       "       'Anekal', 'Ardendale', 'Attibele', 'BEML Layout', 'BTM 2nd Stage',\n",
       "       'BTM Layout', 'Babusapalaya', 'Balagere', 'Banashankari',\n",
       "       'Banashankari Stage II', 'Banashankari Stage III',\n",
       "       'Banashankari Stage V', 'Banaswadi', 'Bannerghatta',\n",
       "       'Bannerghatta Road', 'Basavangudi', 'Battarahalli', 'Begur',\n",
       "       'Begur Road', 'Bellandur', 'Benson Town', 'Bhoganhalli',\n",
       "       'Billekahalli', 'Binny Pete', 'Bisuvanahalli', 'Bommanahalli',\n",
       "       'Bommasandra', 'Bommasandra Industrial Area', 'Brookefield',\n",
       "       'Budigere', 'CV Raman Nagar', 'Chandapura', 'Channasandra',\n",
       "       'Chikka Tirupathi', 'Chikkalasandra', 'Choodasandra',\n",
       "       'Cunningham Road', 'Devanahalli', 'Devarachikkanahalli',\n",
       "       'Dodda Nekkundi', 'Doddathoguru', 'Domlur', 'Dommasandra',\n",
       "       'EPIP Zone', 'Electronic City', 'Electronic City Phase II',\n",
       "       'Electronics City Phase 1', 'Frazer Town', 'Garudachar Palya',\n",
       "       'Gottigere', 'Green Glen Layout', 'Gubbalala', 'Gunjur',\n",
       "       'HBR Layout', 'HRBR Layout', 'HSR Layout', 'Haralur Road',\n",
       "       'Harlur', 'Hebbal', 'Hebbal Kempapura', 'Hegde Nagar', 'Hennur',\n",
       "       'Hennur Road', 'Hoodi', 'Horamavu Agara', 'Horamavu Banaswadi',\n",
       "       'Hormavu', 'Hosa Road', 'Hosakerehalli', 'Hoskote', 'Hosur Road',\n",
       "       'Hulimavu', 'Iblur Village', 'Indira Nagar', 'JP Nagar', 'Jakkur',\n",
       "       'Jalahalli', 'Jalahalli East', 'Jigani', 'KR Puram', 'Kadugodi',\n",
       "       'Kaggadasapura', 'Kaggalipura', 'Kaikondrahalli',\n",
       "       'Kalena Agrahara', 'Kalyan nagar', 'Kambipura', 'Kammasandra',\n",
       "       'Kanakapura', 'Kanakpura Road', 'Kannamangala', 'Kasavanhalli',\n",
       "       'Kasturi Nagar', 'Kathriguppe', 'Kaval Byrasandra',\n",
       "       'Kenchenahalli', 'Kengeri', 'Kengeri Satellite Town',\n",
       "       'Kereguddadahalli', 'Kodichikkanahalli', 'Kogilu', 'Koramangala',\n",
       "       'Kothannur', 'Kothanur', 'Kudlu', 'Kudlu Gate',\n",
       "       'Kumaraswami Layout', 'Kundalahalli', 'Lakshminarayana Pura',\n",
       "       'Lingadheeranahalli', 'Magadi Road', 'Mahadevpura', 'Mallasandra',\n",
       "       'Malleshpalya', 'Malleshwaram', 'Marathahalli', 'Margondanahalli',\n",
       "       'Munnekollal', 'Mysore Road', 'Nagarbhavi', 'Nagavara',\n",
       "       'OMBR Layout', 'Old Airport Road', 'Old Madras Road',\n",
       "       'Padmanabhanagar', 'Pai Layout', 'Panathur', 'Parappana Agrahara',\n",
       "       'Poorna Pragna Layout', 'R.T. Nagar', 'Rachenahalli',\n",
       "       'Raja Rajeshwari Nagar', 'Rajaji Nagar', 'Ramagondanahalli',\n",
       "       'Ramamurthy Nagar', 'Rayasandra', 'Sahakara Nagar', 'Sanjay nagar',\n",
       "       'Sarjapur', 'Sarjapur  Road', 'Sarjapura - Attibele Road',\n",
       "       'Sector 7 HSR Layout', 'Seegehalli', 'Singasandra',\n",
       "       'Somasundara Palya', 'Sonnenahalli', 'Subramanyapura', 'TC Palaya',\n",
       "       'Talaghattapura', 'Thanisandra', 'Thigalarapalya', 'Thubarahalli',\n",
       "       'Tumkur Road', 'Ulsoor', 'Uttarahalli', 'Varthur', 'Vasanthapura',\n",
       "       'Vidyaranyapura', 'Vijayanagar', 'Vittasandra', 'Whitefield',\n",
       "       'Yelahanka', 'Yelahanka New Town', 'Yeshwanthpur'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df20 = df19.copy()\n",
    "\n",
    "df20.location = df20.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\n",
    "\n",
    "df20 = df20[df20.location != 'other']\n",
    "df20 = df20.reset_index(drop=True)\n",
    "df20['location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f0b274",
   "metadata": {},
   "source": [
    "#### The number of bathrooms and bedrooms is highly correlated. We can use that for outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2923158b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6972, 25)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21 = df20.copy()\n",
    "df21 = df21[df21.bath<df21.bedrooms+2]\n",
    "df21.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85802a39",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "#### Creating dummies for 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f289d261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Phase JP Nagar</th>\n",
       "      <th>2nd Stage Nagarbhavi</th>\n",
       "      <th>5th Phase JP Nagar</th>\n",
       "      <th>6th Phase JP Nagar</th>\n",
       "      <th>7th Phase JP Nagar</th>\n",
       "      <th>8th Phase JP Nagar</th>\n",
       "      <th>9th Phase JP Nagar</th>\n",
       "      <th>Abbigere</th>\n",
       "      <th>Akshaya Nagar</th>\n",
       "      <th>Ambalipura</th>\n",
       "      <th>...</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vijayanagar</th>\n",
       "      <th>Vittasandra</th>\n",
       "      <th>Whitefield</th>\n",
       "      <th>Yelahanka</th>\n",
       "      <th>Yelahanka New Town</th>\n",
       "      <th>Yeshwanthpur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1st Phase JP Nagar  2nd Stage Nagarbhavi  5th Phase JP Nagar  \\\n",
       "0                   1                     0                   0   \n",
       "1                   1                     0                   0   \n",
       "2                   1                     0                   0   \n",
       "\n",
       "   6th Phase JP Nagar  7th Phase JP Nagar  8th Phase JP Nagar  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "\n",
       "   9th Phase JP Nagar  Abbigere  Akshaya Nagar  Ambalipura  ...  Uttarahalli  \\\n",
       "0                   0         0              0           0  ...            0   \n",
       "1                   0         0              0           0  ...            0   \n",
       "2                   0         0              0           0  ...            0   \n",
       "\n",
       "   Varthur  Vasanthapura  Vidyaranyapura  Vijayanagar  Vittasandra  \\\n",
       "0        0             0               0            0            0   \n",
       "1        0             0               0            0            0   \n",
       "2        0             0               0            0            0   \n",
       "\n",
       "   Whitefield  Yelahanka  Yelahanka New Town  Yeshwanthpur  \n",
       "0           0          0                   0             0  \n",
       "1           0          0                   0             0  \n",
       "2           0          0                   0             0  \n",
       "\n",
       "[3 rows x 178 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df21.location)\n",
    "dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "171b05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22 = df21.copy()\n",
    "\n",
    "df22 = pd.concat([df22,dummies],axis='columns')\n",
    "\n",
    "## removing 'location' as we have already created the dummies\n",
    "df22 = df22.drop('location',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562efe6",
   "metadata": {},
   "source": [
    "#### Creating dummies for 'ward'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b728ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A. Narayanapura</th>\n",
       "      <th>Anjanapura</th>\n",
       "      <th>Arakere</th>\n",
       "      <th>Aramanenagar</th>\n",
       "      <th>Attur</th>\n",
       "      <th>BTM Layout</th>\n",
       "      <th>Banaswadi</th>\n",
       "      <th>Basavanagudi</th>\n",
       "      <th>Basavanapura</th>\n",
       "      <th>Begur</th>\n",
       "      <th>...</th>\n",
       "      <th>Singasandra</th>\n",
       "      <th>Thanisandra</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vasanthnagar</th>\n",
       "      <th>Vidyapeetha</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vignananagar</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A. Narayanapura  Anjanapura  Arakere  Aramanenagar  Attur  BTM Layout  \\\n",
       "0                0           0        0             0      0           0   \n",
       "1                0           0        0             0      0           0   \n",
       "2                0           0        0             0      0           0   \n",
       "\n",
       "   Banaswadi  Basavanagudi  Basavanapura  Begur  ...  Singasandra  \\\n",
       "0          0             0             0      0  ...            0   \n",
       "1          0             0             0      0  ...            0   \n",
       "2          0             0             0      0  ...            0   \n",
       "\n",
       "   Thanisandra  Uttarahalli  Varthur  Vasanthapura  Vasanthnagar  Vidyapeetha  \\\n",
       "0            0            0        0             0             0            0   \n",
       "1            0            0        0             0             0            0   \n",
       "2            0            0        0             0             0            0   \n",
       "\n",
       "   Vidyaranyapura  Vignananagar  Yelachenahalli  \n",
       "0               0             0               0  \n",
       "1               0             0               0  \n",
       "2               0             0               0  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies1 = pd.get_dummies(df22.ward)\n",
    "dummies1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df528f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>Singasandra</th>\n",
       "      <th>Thanisandra</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vasanthnagar</th>\n",
       "      <th>Vidyapeetha</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vignananagar</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2825</td>\n",
       "      <td>4</td>\n",
       "      <td>250.0</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1875</td>\n",
       "      <td>3</td>\n",
       "      <td>167.0</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2065</td>\n",
       "      <td>4</td>\n",
       "      <td>210.0</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>157.0</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2059</td>\n",
       "      <td>3</td>\n",
       "      <td>225.0</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_sqft  bath  price        lat       long  density  parks_per_ward  \\\n",
       "0        2825     4  250.0  12.911837  77.579495    13946             9.0   \n",
       "1        1875     3  167.0  12.911837  77.579495    13946             9.0   \n",
       "2        2065     4  210.0  12.911837  77.579495    13946             9.0   \n",
       "3        2024     3  157.0  12.911837  77.579495    13946             9.0   \n",
       "4        2059     3  225.0  12.911837  77.579495    13946             9.0   \n",
       "\n",
       "   nearest_high_school  high_schools_3km  nearest_hospital  ...  Singasandra  \\\n",
       "0             0.242898                19          0.093771  ...            0   \n",
       "1             0.242898                19          0.093771  ...            0   \n",
       "2             0.242898                19          0.093771  ...            0   \n",
       "3             0.242898                19          0.093771  ...            0   \n",
       "4             0.242898                19          0.093771  ...            0   \n",
       "\n",
       "   Thanisandra  Uttarahalli  Varthur  Vasanthapura  Vasanthnagar  Vidyapeetha  \\\n",
       "0            0            0        0             0             0            0   \n",
       "1            0            0        0             0             0            0   \n",
       "2            0            0        0             0             0            0   \n",
       "3            0            0        0             0             0            0   \n",
       "4            0            0        0             0             0            0   \n",
       "\n",
       "   Vidyaranyapura  Vignananagar  Yelachenahalli  \n",
       "0               0             0               0  \n",
       "1               0             0               0  \n",
       "2               0             0               0  \n",
       "3               0             0               0  \n",
       "4               0             0               0  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df23 = df22.copy()\n",
    "\n",
    "df23 = pd.concat([df23,dummies1],axis='columns')\n",
    "\n",
    "## removing 'location' as we have already created the dummies\n",
    "df23 = df23.drop('ward',axis = 1)\n",
    "\n",
    "df23.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6761ca0",
   "metadata": {},
   "source": [
    "#### Drop the supplementary column 'price_per_sqft' used for outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c2cd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24 = df23.drop('price_per_sqft',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199c63e",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b96f83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>...</th>\n",
       "      <th>Singasandra</th>\n",
       "      <th>Thanisandra</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vasanthnagar</th>\n",
       "      <th>Vidyapeetha</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vignananagar</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2825</td>\n",
       "      <td>4</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>197</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1875</td>\n",
       "      <td>3</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>197</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2065</td>\n",
       "      <td>4</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>13946</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.242898</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>197</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_sqft  bath        lat       long  density  parks_per_ward  \\\n",
       "0        2825     4  12.911837  77.579495    13946             9.0   \n",
       "1        1875     3  12.911837  77.579495    13946             9.0   \n",
       "2        2065     4  12.911837  77.579495    13946             9.0   \n",
       "\n",
       "   nearest_high_school  high_schools_3km  nearest_hospital  hospitals_5km  \\\n",
       "0             0.242898                19          0.093771            197   \n",
       "1             0.242898                19          0.093771            197   \n",
       "2             0.242898                19          0.093771            197   \n",
       "\n",
       "   ...  Singasandra  Thanisandra  Uttarahalli  Varthur  Vasanthapura  \\\n",
       "0  ...            0            0            0        0             0   \n",
       "1  ...            0            0            0        0             0   \n",
       "2  ...            0            0            0        0             0   \n",
       "\n",
       "   Vasanthnagar  Vidyapeetha  Vidyaranyapura  Vignananagar  Yelachenahalli  \n",
       "0             0            0               0             0               0  \n",
       "1             0            0               0             0               0  \n",
       "2             0            0               0             0               0  \n",
       "\n",
       "[3 rows x 278 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df24.drop(['price'],axis='columns')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "674205ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6972, 278)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "954376c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    250.0\n",
       "1    167.0\n",
       "2    210.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df24.price\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8d24dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6972"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d362e4",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "#### We create our custom scorer and run SFS\n",
    "Remove the comments if you want to run feature selection. Keep in mind that the parallel version (16 cores) takes ~22 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebf36b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Random Forest Classifier object with default values\n",
    "#rfs = RandomForestRegressor()\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "     return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    \n",
    "scorer = make_scorer(rmsle, greater_is_better=True)\n",
    "\n",
    "# run sequential forward selection\n",
    "# sfs_range = SFS(rfs, k_features='best', forward=True, floating=False, verbose=2, scoring=scorer, cv=5, n_jobs=16)\n",
    "\n",
    "# # train the sequential forward selection object\n",
    "# sfs_range = sfs_range.fit(X,y)\n",
    "\n",
    "# # print the accuracy of the best combination as well as the set of best features\n",
    "# print('best combination (ACC: %.3f): %s\\n' % (sfs_range.k_score_, sfs_range.k_feature_idx_))\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "# # use the plot_sfs to visualize all accuracies\n",
    "# plot_sfs(sfs_range.get_metric_dict(), kind='std_err')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e94f5a7",
   "metadata": {},
   "source": [
    "#### We are selecting the best columns based on the results of SFS. We do it manually to avoid running SFS in each run of the jupyter notebook. \n",
    "Uncomment the first line if you want to run SFS and select automatically the best rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bcdfde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>Sarakki</th>\n",
       "      <th>Shakambarinagar</th>\n",
       "      <th>Thanisandra</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vidyapeetha</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vignananagar</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2825</td>\n",
       "      <td>4</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>19</td>\n",
       "      <td>197</td>\n",
       "      <td>0.869022</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1875</td>\n",
       "      <td>3</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>19</td>\n",
       "      <td>197</td>\n",
       "      <td>0.869022</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2065</td>\n",
       "      <td>4</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>19</td>\n",
       "      <td>197</td>\n",
       "      <td>0.869022</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>19</td>\n",
       "      <td>197</td>\n",
       "      <td>0.869022</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2059</td>\n",
       "      <td>3</td>\n",
       "      <td>12.911837</td>\n",
       "      <td>77.579495</td>\n",
       "      <td>19</td>\n",
       "      <td>197</td>\n",
       "      <td>0.869022</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>1676</td>\n",
       "      <td>3</td>\n",
       "      <td>13.025030</td>\n",
       "      <td>77.534024</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>2503</td>\n",
       "      <td>3</td>\n",
       "      <td>13.025030</td>\n",
       "      <td>77.534024</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>1855</td>\n",
       "      <td>3</td>\n",
       "      <td>13.025030</td>\n",
       "      <td>77.534024</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>1876</td>\n",
       "      <td>3</td>\n",
       "      <td>13.025030</td>\n",
       "      <td>77.534024</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>1675</td>\n",
       "      <td>3</td>\n",
       "      <td>13.025030</td>\n",
       "      <td>77.534024</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6972 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_sqft  bath        lat       long  high_schools_3km  hospitals_5km  \\\n",
       "0           2825     4  12.911837  77.579495                19            197   \n",
       "1           1875     3  12.911837  77.579495                19            197   \n",
       "2           2065     4  12.911837  77.579495                19            197   \n",
       "3           2024     3  12.911837  77.579495                19            197   \n",
       "4           2059     3  12.911837  77.579495                19            197   \n",
       "...          ...   ...        ...        ...               ...            ...   \n",
       "7025        1676     3  13.025030  77.534024                13             77   \n",
       "7026        2503     3  13.025030  77.534024                13             77   \n",
       "7027        1855     3  13.025030  77.534024                13             77   \n",
       "7028        1876     3  13.025030  77.534024                13             77   \n",
       "7029        1675     3  13.025030  77.534024                13             77   \n",
       "\n",
       "      nearest_police_station  police_stations_3km  ready_to_move  bedrooms  \\\n",
       "0                   0.869022                    8              1         4   \n",
       "1                   0.869022                    8              1         3   \n",
       "2                   0.869022                    8              1         3   \n",
       "3                   0.869022                    8              1         3   \n",
       "4                   0.869022                    8              1         3   \n",
       "...                      ...                  ...            ...       ...   \n",
       "7025                0.000000                    6              1         3   \n",
       "7026                0.000000                    6              1         3   \n",
       "7027                0.000000                    6              1         3   \n",
       "7028                0.000000                    6              1         3   \n",
       "7029                0.000000                    6              1         3   \n",
       "\n",
       "      ...  Sarakki  Shakambarinagar  Thanisandra  Uttarahalli  Varthur  \\\n",
       "0     ...        0                1            0            0        0   \n",
       "1     ...        0                1            0            0        0   \n",
       "2     ...        0                1            0            0        0   \n",
       "3     ...        0                1            0            0        0   \n",
       "4     ...        0                1            0            0        0   \n",
       "...   ...      ...              ...          ...          ...      ...   \n",
       "7025  ...        0                0            0            0        0   \n",
       "7026  ...        0                0            0            0        0   \n",
       "7027  ...        0                0            0            0        0   \n",
       "7028  ...        0                0            0            0        0   \n",
       "7029  ...        0                0            0            0        0   \n",
       "\n",
       "      Vasanthapura  Vidyapeetha  Vidyaranyapura  Vignananagar  Yelachenahalli  \n",
       "0                0            0               0             0               0  \n",
       "1                0            0               0             0               0  \n",
       "2                0            0               0             0               0  \n",
       "3                0            0               0             0               0  \n",
       "4                0            0               0             0               0  \n",
       "...            ...          ...             ...           ...             ...  \n",
       "7025             0            0               0             0               0  \n",
       "7026             0            0               0             0               0  \n",
       "7027             0            0               0             0               0  \n",
       "7028             0            0               0             0               0  \n",
       "7029             0            0               0             0               0  \n",
       "\n",
       "[6972 rows x 192 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_sfs = X.iloc[:, list(sfs_range.k_feature_idx_)]\n",
    "X_sfs = X.iloc[:, [0, 1, 2, 3, 7, 9, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 63, 64, 65, 68, 70, 72, 73, 74, 75, 78, 79, 81, 83, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 100, 102, 103, 105, 106, 107, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 131, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 159, 160, 161, 163, 164, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 190, 193, 194, 195, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 255, 256, 257, 260, 262, 264, 265, 266, 269, 270, 271, 272, 274, 275, 276, 277]]\n",
    "X_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eca61ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_sqft                     int64\n",
       "bath                           int32\n",
       "lat                          float64\n",
       "long                         float64\n",
       "high_schools_3km               int32\n",
       "hospitals_5km                  int32\n",
       "nearest_police_station       float64\n",
       "police_stations_3km            int32\n",
       "ready_to_move                  int64\n",
       "bedrooms                       int32\n",
       "studio                         int64\n",
       "1st Phase JP Nagar             uint8\n",
       "2nd Stage Nagarbhavi           uint8\n",
       "5th Phase JP Nagar             uint8\n",
       "6th Phase JP Nagar             uint8\n",
       "7th Phase JP Nagar             uint8\n",
       "8th Phase JP Nagar             uint8\n",
       "9th Phase JP Nagar             uint8\n",
       "Abbigere                       uint8\n",
       "Ambalipura                     uint8\n",
       "Ambedkar Nagar                 uint8\n",
       "Amruthahalli                   uint8\n",
       "Anandapura                     uint8\n",
       "Ananth Nagar                   uint8\n",
       "Anekal                         uint8\n",
       "BEML Layout                    uint8\n",
       "BTM 2nd Stage                  uint8\n",
       "BTM Layout                     uint8\n",
       "Babusapalaya                   uint8\n",
       "Balagere                       uint8\n",
       "Banashankari                   uint8\n",
       "Banashankari Stage V           uint8\n",
       "Bannerghatta                   uint8\n",
       "Bannerghatta Road              uint8\n",
       "Basavangudi                    uint8\n",
       "Battarahalli                   uint8\n",
       "Begur                          uint8\n",
       "Begur Road                     uint8\n",
       "Bellandur                      uint8\n",
       "Benson Town                    uint8\n",
       "Billekahalli                   uint8\n",
       "Binny Pete                     uint8\n",
       "Bommasandra                    uint8\n",
       "Brookefield                    uint8\n",
       "Budigere                       uint8\n",
       "CV Raman Nagar                 uint8\n",
       "Chikka Tirupathi               uint8\n",
       "Choodasandra                   uint8\n",
       "Devanahalli                    uint8\n",
       "Devarachikkanahalli            uint8\n",
       "Dodda Nekkundi                 uint8\n",
       "Doddathoguru                   uint8\n",
       "EPIP Zone                      uint8\n",
       "Electronic City                uint8\n",
       "Electronics City Phase 1       uint8\n",
       "Garudachar Palya               uint8\n",
       "Gubbalala                      uint8\n",
       "Gunjur                         uint8\n",
       "HRBR Layout                    uint8\n",
       "HSR Layout                     uint8\n",
       "Haralur Road                   uint8\n",
       "Harlur                         uint8\n",
       "Hebbal Kempapura               uint8\n",
       "Hegde Nagar                    uint8\n",
       "Hennur                         uint8\n",
       "Hennur Road                    uint8\n",
       "Hoodi                          uint8\n",
       "Horamavu Banaswadi             uint8\n",
       "Hosa Road                      uint8\n",
       "Hosakerehalli                  uint8\n",
       "Hosur Road                     uint8\n",
       "Hulimavu                       uint8\n",
       "Iblur Village                  uint8\n",
       "JP Nagar                       uint8\n",
       "Jalahalli                      uint8\n",
       "Jalahalli East                 uint8\n",
       "Jigani                         uint8\n",
       "Kaggalipura                    uint8\n",
       "Kaikondrahalli                 uint8\n",
       "Kalena Agrahara                uint8\n",
       "Kalyan nagar                   uint8\n",
       "Kambipura                      uint8\n",
       "Kammasandra                    uint8\n",
       "Kanakapura                     uint8\n",
       "Kasavanhalli                   uint8\n",
       "Kasturi Nagar                  uint8\n",
       "Kathriguppe                    uint8\n",
       "Kaval Byrasandra               uint8\n",
       "Kengeri                        uint8\n",
       "Koramangala                    uint8\n",
       "Kothannur                      uint8\n",
       "Kudlu                          uint8\n",
       "Kudlu Gate                     uint8\n",
       "Kundalahalli                   uint8\n",
       "Lakshminarayana Pura           uint8\n",
       "Lingadheeranahalli             uint8\n",
       "Magadi Road                    uint8\n",
       "Mahadevpura                    uint8\n",
       "Mallasandra                    uint8\n",
       "Malleshpalya                   uint8\n",
       "Malleshwaram                   uint8\n",
       "Marathahalli                   uint8\n",
       "Mysore Road                    uint8\n",
       "Padmanabhanagar                uint8\n",
       "Pai Layout                     uint8\n",
       "Panathur                       uint8\n",
       "Poorna Pragna Layout           uint8\n",
       "R.T. Nagar                     uint8\n",
       "Raja Rajeshwari Nagar          uint8\n",
       "Rajaji Nagar                   uint8\n",
       "Ramagondanahalli               uint8\n",
       "Ramamurthy Nagar               uint8\n",
       "Rayasandra                     uint8\n",
       "Sanjay nagar                   uint8\n",
       "Sarjapur                       uint8\n",
       "Sarjapur  Road                 uint8\n",
       "Sarjapura - Attibele Road      uint8\n",
       "Sector 7 HSR Layout            uint8\n",
       "Seegehalli                     uint8\n",
       "Singasandra                    uint8\n",
       "Somasundara Palya              uint8\n",
       "Sonnenahalli                   uint8\n",
       "Subramanyapura                 uint8\n",
       "TC Palaya                      uint8\n",
       "Talaghattapura                 uint8\n",
       "Thanisandra                    uint8\n",
       "Thigalarapalya                 uint8\n",
       "Tumkur Road                    uint8\n",
       "Ulsoor                         uint8\n",
       "Varthur                        uint8\n",
       "Vijayanagar                    uint8\n",
       "Vittasandra                    uint8\n",
       "Whitefield                     uint8\n",
       "A. Narayanapura                uint8\n",
       "Anjanapura                     uint8\n",
       "Arakere                        uint8\n",
       "Attur                          uint8\n",
       "BTM Layout                     uint8\n",
       "Banaswadi                      uint8\n",
       "Basavanagudi                   uint8\n",
       "Basavanapura                   uint8\n",
       "Begur                          uint8\n",
       "Bellandur                      uint8\n",
       "Benniganahalli                 uint8\n",
       "Bilekahalli                    uint8\n",
       "Binnipete                      uint8\n",
       "Bommanahalli                   uint8\n",
       "Byatarayanapura                uint8\n",
       "C. V. Raman Nagar              uint8\n",
       "Chikkalasandra                 uint8\n",
       "Doddanekkundi                  uint8\n",
       "Domlur                         uint8\n",
       "Ganesh Mandira                 uint8\n",
       "Ganganagar                     uint8\n",
       "Girinagar                      uint8\n",
       "Govindarajanagar               uint8\n",
       "H. M. T.                       uint8\n",
       "HAL Airport                    uint8\n",
       "HBR Layout                     uint8\n",
       "Hebbala                        uint8\n",
       "Hemmigepura                    uint8\n",
       "Hongasandra                    uint8\n",
       "Hoodi                          uint8\n",
       "Horamavu                       uint8\n",
       "Jakkur                         uint8\n",
       "Jalahalli                      uint8\n",
       "Jayanagar                      uint8\n",
       "Jayanagar East                 uint8\n",
       "Kadugudi                       uint8\n",
       "Kathriguppe                    uint8\n",
       "Kempegowda Ward                uint8\n",
       "Koramangala                    uint8\n",
       "Kottigepalya                   uint8\n",
       "Krishnarajapuram               uint8\n",
       "Kuvempunagar                   uint8\n",
       "Mangammanapalya                uint8\n",
       "Nagavara                       uint8\n",
       "Outside of town                uint8\n",
       "Padmanabhanagar                uint8\n",
       "Rajajinagar                    uint8\n",
       "Ramamurthynagar                uint8\n",
       "Sanjaynagar                    uint8\n",
       "Sarakki                        uint8\n",
       "Shakambarinagar                uint8\n",
       "Thanisandra                    uint8\n",
       "Uttarahalli                    uint8\n",
       "Varthur                        uint8\n",
       "Vasanthapura                   uint8\n",
       "Vidyapeetha                    uint8\n",
       "Vidyaranyapura                 uint8\n",
       "Vignananagar                   uint8\n",
       "Yelachenahalli                 uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000) # display up to 1000 rows\n",
    "X_sfs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74b6f731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9218138 , 0.91367538, 0.90021845, 0.90656594, 0.91484272])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(RandomForestRegressor(), X_sfs, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cae87672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>Sarakki</th>\n",
       "      <th>Shakambarinagar</th>\n",
       "      <th>Thanisandra</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vidyapeetha</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vignananagar</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "      <td>6972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1449.567126</td>\n",
       "      <td>2.385542</td>\n",
       "      <td>12.947500</td>\n",
       "      <td>77.637832</td>\n",
       "      <td>8.789443</td>\n",
       "      <td>57.688612</td>\n",
       "      <td>1.838093</td>\n",
       "      <td>2.955536</td>\n",
       "      <td>0.760757</td>\n",
       "      <td>2.516495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.040448</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.001865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>659.135249</td>\n",
       "      <td>0.820906</td>\n",
       "      <td>0.083292</td>\n",
       "      <td>0.075568</td>\n",
       "      <td>5.277182</td>\n",
       "      <td>51.273965</td>\n",
       "      <td>2.178988</td>\n",
       "      <td>3.435831</td>\n",
       "      <td>0.426652</td>\n",
       "      <td>0.751711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086863</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>0.197020</td>\n",
       "      <td>0.082694</td>\n",
       "      <td>0.141749</td>\n",
       "      <td>0.168546</td>\n",
       "      <td>0.052136</td>\n",
       "      <td>0.056089</td>\n",
       "      <td>0.054803</td>\n",
       "      <td>0.043144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.709058</td>\n",
       "      <td>77.459445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1110.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.890984</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.622560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1280.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.935193</td>\n",
       "      <td>77.643148</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.305272</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1630.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.694364</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.973203</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11890.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.229278</td>\n",
       "      <td>77.866742</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>15.156187</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_sqft         bath          lat         long  high_schools_3km  \\\n",
       "count   6972.000000  6972.000000  6972.000000  6972.000000       6972.000000   \n",
       "mean    1449.567126     2.385542    12.947500    77.637832          8.789443   \n",
       "std      659.135249     0.820906     0.083292     0.075568          5.277182   \n",
       "min      300.000000     0.000000    12.709058    77.459445          0.000000   \n",
       "25%     1110.000000     2.000000    12.890984    77.584508          4.000000   \n",
       "50%     1280.000000     2.000000    12.935193    77.643148          9.000000   \n",
       "75%     1630.000000     3.000000    13.013906    77.694364         12.000000   \n",
       "max    11890.000000     6.000000    13.229278    77.866742         27.000000   \n",
       "\n",
       "       hospitals_5km  nearest_police_station  police_stations_3km  \\\n",
       "count    6972.000000             6972.000000          6972.000000   \n",
       "mean       57.688612                1.838093             2.955536   \n",
       "std        51.273965                2.178988             3.435831   \n",
       "min         0.000000                0.000000             0.000000   \n",
       "25%        18.000000                0.622560             1.000000   \n",
       "50%        48.000000                1.305272             2.000000   \n",
       "75%        72.000000                1.973203             4.000000   \n",
       "max       239.000000               15.156187            28.000000   \n",
       "\n",
       "       ready_to_move     bedrooms  ...      Sarakki  Shakambarinagar  \\\n",
       "count    6972.000000  6972.000000  ...  6972.000000      6972.000000   \n",
       "mean        0.760757     2.516495  ...     0.007602         0.002582   \n",
       "std         0.426652     0.751711  ...     0.086863         0.050749   \n",
       "min         0.000000     1.000000  ...     0.000000         0.000000   \n",
       "25%         1.000000     2.000000  ...     0.000000         0.000000   \n",
       "50%         1.000000     2.000000  ...     0.000000         0.000000   \n",
       "75%         1.000000     3.000000  ...     0.000000         0.000000   \n",
       "max         1.000000     7.000000  ...     1.000000         1.000000   \n",
       "\n",
       "       Thanisandra  Uttarahalli      Varthur  Vasanthapura  Vidyapeetha  \\\n",
       "count  6972.000000  6972.000000  6972.000000   6972.000000  6972.000000   \n",
       "mean      0.040448     0.006885     0.020511      0.029260     0.002725   \n",
       "std       0.197020     0.082694     0.141749      0.168546     0.052136   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       Vidyaranyapura  Vignananagar  Yelachenahalli  \n",
       "count     6972.000000   6972.000000     6972.000000  \n",
       "mean         0.003155      0.003012        0.001865  \n",
       "std          0.056089      0.054803        0.043144  \n",
       "min          0.000000      0.000000        0.000000  \n",
       "25%          0.000000      0.000000        0.000000  \n",
       "50%          0.000000      0.000000        0.000000  \n",
       "75%          0.000000      0.000000        0.000000  \n",
       "max          1.000000      1.000000        1.000000  \n",
       "\n",
       "[8 rows x 192 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sfs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84cf2a5",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "#### We tested all the regressor algorithms to see which works best for our dataset\n",
    "REMOVED ALL THE REGRESSORS THAT PRODUCE NEGATIVE VALUES - THIS IS THE REASON WE GOT 0% ON OUR MACHINE HACK SUBMISSION\n",
    "The metric RMSLE can't deal with negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5cb9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    {'name': 'AdaBoostRegressor', 'reg': AdaBoostRegressor(), 'params': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]}},\n",
    "    {'name': 'BaggingRegressor', 'reg': BaggingRegressor(), 'params': {'n_estimators': [10, 50, 100], 'max_samples': [0.5, 1.0], 'max_features': [0.5, 1.0], 'bootstrap': [True, False]}},\n",
    "    {'name': 'DecisionTreeRegressor', 'reg': DecisionTreeRegressor(), 'params': {'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}},\n",
    "    {'name': 'ExtraTreeRegressor', 'reg': ExtraTreeRegressor(), 'params': {'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}},\n",
    "    {'name': 'ExtraTreesRegressor', 'reg': ExtraTreesRegressor(), 'params': {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}},\n",
    "    {'name': 'GradientBoostingRegressor', 'reg': GradientBoostingRegressor(), 'params': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}},\n",
    "    {'name': 'HistGradientBoostingRegressor', 'reg': HistGradientBoostingRegressor(), 'params': {'max_iter': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [None, 5, 10], 'min_samples_leaf': [1, 2, 4], 'l2_regularization': [0, 0.1, 1]}},\n",
    "    {'name': 'KNeighborsRegressor', 'reg': KNeighborsRegressor(), 'params': {'n_neighbors': [3, 5, 10], 'weights': ['uniform', 'distance']}},\n",
    "    {'name': 'LassoLars', 'reg': LassoLars(), 'params': {'alpha': [0.1, 1, 10]}},\n",
    "    {'name': 'PoissonRegressor', 'reg': PoissonRegressor(), 'params': {'alpha': [0.1, 1, 10]}},\n",
    "    {'name': 'RandomForestRegressor', 'reg': RandomForestRegressor(), 'params': {'n_estimators': [50, 100, 200], 'max_features': ['auto', 'sqrt', 'log2']}},\n",
    "    {'name': 'StackingRegressor', 'reg': StackingRegressor(estimators= [('knn', KNeighborsRegressor())], final_estimator=LinearRegression()), 'params': {}},\n",
    "    {'name': 'VotingRegressor', 'reg': VotingRegressor([(\"lr\", LinearRegression()), (\"knn\", KNeighborsRegressor()), (\"rf\", RandomForestRegressor())]), 'params': {}},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6dff8359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=50;, score=0.683 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=50;, score=0.700 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=50;, score=0.683 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=50;, score=0.692 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=50;, score=0.695 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=100;, score=0.682 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=100;, score=0.700 total time=   3.3s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=100;, score=0.683 total time=   3.7s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=100;, score=0.691 total time=   4.0s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=100;, score=0.695 total time=   3.3s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=200;, score=0.684 total time=   6.8s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=200;, score=0.702 total time=   6.6s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=200;, score=0.685 total time=   7.3s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   6.9s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=200;, score=0.697 total time=   6.6s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=50;, score=0.651 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=50;, score=0.659 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=50;, score=0.659 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=50;, score=0.648 total time=   2.2s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=50;, score=0.702 total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=100;, score=0.647 total time=   4.4s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=100;, score=0.655 total time=   3.9s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=100;, score=0.645 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=100;, score=0.646 total time=   2.8s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=100;, score=0.658 total time=   2.8s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=200;, score=0.621 total time=   5.6s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=200;, score=0.637 total time=   5.8s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=200;, score=0.619 total time=   5.5s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=200;, score=0.629 total time=   5.4s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=200;, score=0.629 total time=   5.5s\n",
      "[CV 1/5] END ..learning_rate=1, n_estimators=50;, score=0.496 total time=   1.1s\n",
      "[CV 2/5] END ..learning_rate=1, n_estimators=50;, score=0.459 total time=   1.1s\n",
      "[CV 3/5] END ..learning_rate=1, n_estimators=50;, score=0.507 total time=   1.1s\n",
      "[CV 4/5] END ..learning_rate=1, n_estimators=50;, score=0.494 total time=   1.2s\n",
      "[CV 5/5] END ..learning_rate=1, n_estimators=50;, score=0.533 total time=   1.1s\n",
      "[CV 1/5] END .learning_rate=1, n_estimators=100;, score=0.408 total time=   2.1s\n",
      "[CV 2/5] END .learning_rate=1, n_estimators=100;, score=0.404 total time=   2.1s\n",
      "[CV 3/5] END .learning_rate=1, n_estimators=100;, score=0.371 total time=   2.0s\n",
      "[CV 4/5] END .learning_rate=1, n_estimators=100;, score=0.420 total time=   2.2s\n",
      "[CV 5/5] END .learning_rate=1, n_estimators=100;, score=0.423 total time=   2.1s\n",
      "[CV 1/5] END .learning_rate=1, n_estimators=200;, score=0.298 total time=   4.1s\n",
      "[CV 2/5] END .learning_rate=1, n_estimators=200;, score=0.321 total time=   4.0s\n",
      "[CV 3/5] END .learning_rate=1, n_estimators=200;, score=0.320 total time=   4.0s\n",
      "[CV 4/5] END .learning_rate=1, n_estimators=200;, score=0.320 total time=   4.1s\n",
      "[CV 5/5] END .learning_rate=1, n_estimators=200;, score=0.343 total time=   3.9s\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.796 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.797 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.807 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.812 total time=   0.6s\n",
      "[CV 2/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.816 total time=   0.7s\n",
      "[CV 3/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.815 total time=   0.6s\n",
      "[CV 4/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.824 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.812 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.808 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.814 total time=   1.8s\n",
      "[CV 4/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.827 total time=   1.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.817 total time=   1.3s\n",
      "[CV 1/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.785 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.768 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.844 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.805 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.813 total time=   0.8s\n",
      "[CV 2/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 3/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.818 total time=   0.9s\n",
      "[CV 4/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.818 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.821 total time=   1.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.823 total time=   2.6s\n",
      "[CV 2/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.821 total time=   2.4s\n",
      "[CV 3/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.815 total time=   2.3s\n",
      "[CV 4/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.831 total time=   2.3s\n",
      "[CV 5/5] END bootstrap=True, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.815 total time=   2.6s\n",
      "[CV 1/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.837 total time=   0.4s\n",
      "[CV 2/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.835 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.827 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.838 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.840 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.844 total time=   1.5s\n",
      "[CV 2/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.842 total time=   2.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.830 total time=   1.6s\n",
      "[CV 4/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.844 total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.839 total time=   1.5s\n",
      "[CV 1/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.845 total time=   3.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.843 total time=   3.2s\n",
      "[CV 3/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.831 total time=   3.2s\n",
      "[CV 4/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.846 total time=   3.5s\n",
      "[CV 5/5] END bootstrap=True, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.842 total time=   3.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.833 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.829 total time=   0.4s\n",
      "[CV 4/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.840 total time=   0.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.837 total time=   0.4s\n",
      "[CV 1/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.846 total time=   2.2s\n",
      "[CV 2/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.841 total time=   2.2s\n",
      "[CV 3/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.833 total time=   2.2s\n",
      "[CV 4/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.848 total time=   2.1s\n",
      "[CV 5/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.841 total time=   2.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.846 total time=   4.4s\n",
      "[CV 2/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.842 total time=   4.5s\n",
      "[CV 3/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.833 total time=   4.3s\n",
      "[CV 4/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.848 total time=   4.4s\n",
      "[CV 5/5] END bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.841 total time=   4.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.780 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.784 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.805 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.799 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.834 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.813 total time=   0.7s\n",
      "[CV 2/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.817 total time=   0.8s\n",
      "[CV 3/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.809 total time=   0.7s\n",
      "[CV 4/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.831 total time=   0.8s\n",
      "[CV 5/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=50;, score=0.822 total time=   0.8s\n",
      "[CV 1/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.818 total time=   1.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.820 total time=   1.6s\n",
      "[CV 3/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.802 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.821 total time=   1.6s\n",
      "[CV 5/5] END bootstrap=False, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.825 total time=   1.7s\n",
      "[CV 1/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.828 total time=   0.2s\n",
      "[CV 2/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.808 total time=   0.2s\n",
      "[CV 3/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.806 total time=   0.2s\n",
      "[CV 4/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.834 total time=   0.2s\n",
      "[CV 5/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=10;, score=0.827 total time=   0.2s\n",
      "[CV 1/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.810 total time=   1.3s\n",
      "[CV 2/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.808 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.812 total time=   1.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.824 total time=   1.3s\n",
      "[CV 5/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=50;, score=0.818 total time=   1.4s\n",
      "[CV 1/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.822 total time=   2.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.818 total time=   2.7s\n",
      "[CV 3/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.811 total time=   2.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.829 total time=   2.7s\n",
      "[CV 5/5] END bootstrap=False, max_features=0.5, max_samples=1.0, n_estimators=100;, score=0.817 total time=   2.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.836 total time=   0.3s\n",
      "[CV 3/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.825 total time=   0.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.843 total time=   0.3s\n",
      "[CV 5/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=10;, score=0.838 total time=   0.3s\n",
      "[CV 1/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.845 total time=   1.7s\n",
      "[CV 2/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.843 total time=   1.7s\n",
      "[CV 3/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.832 total time=   2.1s\n",
      "[CV 4/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.847 total time=   2.7s\n",
      "[CV 5/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=50;, score=0.841 total time=   2.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.847 total time=   4.6s\n",
      "[CV 2/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.843 total time=   4.7s\n",
      "[CV 3/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.832 total time=   4.1s\n",
      "[CV 4/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.847 total time=   3.6s\n",
      "[CV 5/5] END bootstrap=False, max_features=1.0, max_samples=0.5, n_estimators=100;, score=0.842 total time=   3.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.810 total time=   0.5s\n",
      "[CV 2/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.799 total time=   0.5s\n",
      "[CV 3/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.799 total time=   0.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.810 total time=   0.6s\n",
      "[CV 5/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=10;, score=0.808 total time=   0.6s\n",
      "[CV 1/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.810 total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.799 total time=   2.9s\n",
      "[CV 3/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.799 total time=   2.9s\n",
      "[CV 4/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.812 total time=   3.1s\n",
      "[CV 5/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=50;, score=0.809 total time=   3.1s\n",
      "[CV 1/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.810 total time=   5.9s\n",
      "[CV 2/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.799 total time=   6.3s\n",
      "[CV 3/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.799 total time=   6.7s\n",
      "[CV 4/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.812 total time=   6.2s\n",
      "[CV 5/5] END bootstrap=False, max_features=1.0, max_samples=1.0, n_estimators=100;, score=0.809 total time=   6.7s\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.813 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.798 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.809 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.817 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.810 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.801 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.816 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.809 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.817 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.813 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.821 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.802 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.817 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.817 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.820 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.817 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.817 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.741 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.788 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.801 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.802 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.788 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.795 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.795 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.788 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.790 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.801 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.801 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.791 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.801 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.801 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.791 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.801 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.801 total time=   0.0s\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.801 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.797 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.809 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.793 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.780 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.797 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10;, score=0.801 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.802 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.783 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.798 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.806 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10;, score=0.790 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.801 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.802 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.797 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.791 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.802 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.640 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.622 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.686 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.663 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=0.617 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.657 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.664 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.651 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.695 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5;, score=0.582 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.589 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.676 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.684 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.556 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.623 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.623 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.699 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.659 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.641 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.629 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.669 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.676 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.684 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.704 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=0.681 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.685 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.683 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.664 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.693 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.617 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.646 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.647 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.659 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10;, score=0.682 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.768 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2;, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.759 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.769 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5;, score=0.765 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.745 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.752 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.751 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.771 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.759 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.757 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2;, score=0.754 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.776 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.773 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5;, score=0.754 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.752 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.773 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.755 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2;, score=0.752 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.763 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5;, score=0.758 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.749 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.756 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10;, score=0.756 total time=   0.0s\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.834 total time=   0.4s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.830 total time=   0.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.823 total time=   0.4s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.837 total time=   0.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.827 total time=   0.4s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.840 total time=   2.3s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.834 total time=   2.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.827 total time=   2.3s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.843 total time=   2.3s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.833 total time=   2.2s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.840 total time=   4.7s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.836 total time=   5.5s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.827 total time=   7.6s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.843 total time=   7.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.835 total time=   5.8s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.835 total time=   0.4s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.836 total time=   0.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.828 total time=   0.4s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.843 total time=   0.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.837 total time=   0.4s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.844 total time=   2.3s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.842 total time=   2.1s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.833 total time=   2.1s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.846 total time=   2.1s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.840 total time=   2.1s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.843 total time=   4.8s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.842 total time=   4.8s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   5.2s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.848 total time=   4.9s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.842 total time=   4.7s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.844 total time=   0.4s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.839 total time=   0.5s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.826 total time=   0.4s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.845 total time=   0.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.836 total time=   0.4s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.845 total time=   2.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.842 total time=   1.9s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.833 total time=   2.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.848 total time=   2.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.841 total time=   2.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.844 total time=   4.1s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.843 total time=   4.2s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.835 total time=   3.9s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.850 total time=   4.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.841 total time=   4.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.844 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.839 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.828 total time=   0.4s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.844 total time=   0.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.837 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.844 total time=   2.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.842 total time=   2.0s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.834 total time=   1.9s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.847 total time=   2.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.840 total time=   2.1s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.844 total time=   4.4s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.843 total time=   4.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   4.8s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.846 total time=   6.7s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.842 total time=   5.5s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.841 total time=   0.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.826 total time=   0.4s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.841 total time=   0.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.839 total time=   0.4s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.844 total time=   2.6s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.842 total time=   2.1s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.832 total time=   2.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.847 total time=   2.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.840 total time=   2.1s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.844 total time=   4.1s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.842 total time=   4.1s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.832 total time=   3.9s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.847 total time=   4.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.841 total time=   3.9s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.838 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.827 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.839 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.838 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.844 total time=   1.8s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.840 total time=   1.8s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.832 total time=   1.8s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.846 total time=   1.9s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.840 total time=   2.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.844 total time=   4.9s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.843 total time=   5.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.832 total time=   4.7s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.846 total time=   4.2s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.840 total time=   5.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.835 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.834 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.826 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.837 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.835 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.838 total time=   1.7s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.837 total time=   1.8s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.828 total time=   1.8s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.839 total time=   1.8s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.835 total time=   1.8s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.838 total time=   3.7s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   3.7s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.829 total time=   3.6s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.841 total time=   4.0s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.836 total time=   4.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.834 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.831 total time=   0.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.824 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.839 total time=   0.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.831 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.839 total time=   2.1s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.837 total time=   3.7s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.828 total time=   2.5s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.842 total time=   3.2s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.837 total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.838 total time=   4.9s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.837 total time=   3.9s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.828 total time=   3.8s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.842 total time=   4.1s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.836 total time=   4.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.835 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.834 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.825 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.839 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.834 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.838 total time=   1.8s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.836 total time=   1.7s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.828 total time=   1.8s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.841 total time=   1.9s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.836 total time=   1.7s\n",
      "[CV 1/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.837 total time=   3.6s\n",
      "[CV 2/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.837 total time=   3.8s\n",
      "[CV 3/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.828 total time=   4.1s\n",
      "[CV 4/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.840 total time=   3.9s\n",
      "[CV 5/5] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.835 total time=   3.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.712 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.713 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.711 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.717 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.711 total time=   0.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.719 total time=   0.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.723 total time=   0.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.723 total time=   0.7s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.724 total time=   0.6s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.716 total time=   1.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.724 total time=   1.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.721 total time=   1.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.729 total time=   1.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.731 total time=   1.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.715 total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.723 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.708 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.729 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.738 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.710 total time=   0.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.717 total time=   0.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.719 total time=   0.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.717 total time=   0.7s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.722 total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.712 total time=   1.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.719 total time=   1.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.718 total time=   1.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.714 total time=   1.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.724 total time=   1.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.702 total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.711 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.713 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.728 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.718 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.710 total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.719 total time=   0.7s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.715 total time=   0.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.725 total time=   0.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.725 total time=   0.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.712 total time=   1.4s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.720 total time=   1.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.718 total time=   1.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.726 total time=   1.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.723 total time=   1.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.702 total time=   0.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.712 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.719 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.728 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.717 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.713 total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.721 total time=   0.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.715 total time=   0.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.720 total time=   0.8s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.729 total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.713 total time=   1.8s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.720 total time=   1.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.714 total time=   1.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.730 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.723 total time=   1.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.723 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.724 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.734 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.716 total time=   0.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.717 total time=   0.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.718 total time=   0.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.728 total time=   0.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.728 total time=   0.8s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.712 total time=   1.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.721 total time=   1.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.716 total time=   1.8s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.727 total time=   2.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.728 total time=   1.8s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.721 total time=   0.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.707 total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.717 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.729 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.709 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.708 total time=   1.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.724 total time=   0.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.728 total time=   1.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.721 total time=   0.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.724 total time=   1.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.713 total time=   1.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.719 total time=   1.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.718 total time=   1.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.732 total time=   1.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.721 total time=   1.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.730 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.712 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.726 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.717 total time=   0.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.726 total time=   0.7s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.720 total time=   0.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.727 total time=   0.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.722 total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.714 total time=   1.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.724 total time=   1.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.720 total time=   1.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.732 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.726 total time=   1.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.711 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.738 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.728 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.717 total time=   0.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.713 total time=   0.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.716 total time=   0.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.712 total time=   0.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.730 total time=   0.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.713 total time=   1.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.716 total time=   1.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.717 total time=   1.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.722 total time=   1.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.723 total time=   1.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.716 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.715 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.694 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.727 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.726 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.714 total time=   0.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.714 total time=   0.6s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.721 total time=   0.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.722 total time=   0.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.723 total time=   0.6s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.715 total time=   1.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.723 total time=   1.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.722 total time=   1.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.731 total time=   1.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.718 total time=   1.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.794 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.786 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.785 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.790 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=0.787 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.789 total time=   1.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.794 total time=   1.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.788 total time=   1.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.796 total time=   1.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.795 total time=   1.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.788 total time=   2.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.791 total time=   2.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.787 total time=   2.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.796 total time=   2.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.793 total time=   2.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.781 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.786 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.789 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.795 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=0.784 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.787 total time=   1.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.791 total time=   1.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.790 total time=   1.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.800 total time=   1.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.792 total time=   1.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.789 total time=   2.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.793 total time=   2.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.788 total time=   2.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.798 total time=   2.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.794 total time=   2.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.783 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.796 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.787 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.794 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=0.787 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.785 total time=   1.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.790 total time=   1.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.787 total time=   1.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.795 total time=   1.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.791 total time=   1.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.789 total time=   2.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.791 total time=   2.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.787 total time=   2.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.798 total time=   2.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.793 total time=   2.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.789 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.790 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.786 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.792 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=0.786 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.789 total time=   1.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.794 total time=   1.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.789 total time=   1.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.796 total time=   1.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.794 total time=   1.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.790 total time=   4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.794 total time=   3.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.788 total time=   4.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.796 total time=   3.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.793 total time=   4.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.785 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.787 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.784 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.799 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=0.792 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.790 total time=   1.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.793 total time=   1.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.787 total time=   2.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.797 total time=   1.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.791 total time=   1.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.789 total time=   2.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.792 total time=   2.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.787 total time=   2.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.796 total time=   2.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.793 total time=   2.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.790 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.792 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.778 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.797 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=0.789 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.788 total time=   1.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.791 total time=   1.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.789 total time=   1.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.798 total time=   1.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.794 total time=   1.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.791 total time=   2.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.792 total time=   2.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.788 total time=   2.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.798 total time=   2.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.792 total time=   2.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.788 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.783 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.799 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=10;, score=0.791 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.789 total time=   1.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.793 total time=   1.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.788 total time=   1.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.800 total time=   1.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.796 total time=   1.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.789 total time=   2.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.794 total time=   2.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.790 total time=   2.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.799 total time=   2.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.795 total time=   2.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.792 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.783 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.795 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=10;, score=0.785 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.791 total time=   1.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.792 total time=   1.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.791 total time=   1.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.799 total time=   1.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.791 total time=   1.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.790 total time=   2.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.792 total time=   2.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.790 total time=   2.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.800 total time=   2.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.795 total time=   2.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.786 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.792 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.780 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.795 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=10;, score=0.787 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.792 total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.790 total time=   1.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.788 total time=   1.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.798 total time=   1.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.793 total time=   1.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.791 total time=   2.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.792 total time=   2.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.788 total time=   2.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.799 total time=   2.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.795 total time=   3.4s\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.561 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.567 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.569 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.567 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.570 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.633 total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.642 total time=   1.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.641 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.639 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.645 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.708 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.716 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.711 total time=   2.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.714 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.721 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.561 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.567 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.569 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.567 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.570 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.633 total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.642 total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.641 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.639 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.645 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.708 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.716 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.711 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.714 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.721 total time=   2.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.561 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.567 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.569 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.567 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.570 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.633 total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.642 total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.641 total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.639 total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.645 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.708 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.716 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.711 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.714 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.721 total time=   2.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.561 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.567 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.569 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.567 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.570 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.633 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.642 total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.641 total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.639 total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.645 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.708 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.715 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.711 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.714 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.721 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.561 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.567 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.569 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.567 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.570 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.633 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.642 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.641 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.639 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.645 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.708 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.715 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.711 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.714 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.721 total time=   3.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.561 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.567 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.569 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.567 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.570 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.633 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.642 total time=   1.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.641 total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.639 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.645 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.708 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.715 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.711 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.714 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.721 total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.561 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.567 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.569 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.567 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.570 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.632 total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.642 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.641 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.639 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.645 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.707 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.715 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.711 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.714 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.721 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.561 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.567 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.569 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.567 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.570 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.632 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.642 total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.641 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.639 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.645 total time=   1.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.707 total time=   2.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.715 total time=   2.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.711 total time=   2.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.714 total time=   2.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.721 total time=   2.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.561 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.567 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.569 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.567 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.570 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.632 total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.642 total time=   1.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.641 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.639 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.645 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.707 total time=   2.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.715 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.711 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.714 total time=   2.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.721 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.581 total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.583 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.590 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.585 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.590 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.669 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.672 total time=   2.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.677 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.674 total time=   2.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.682 total time=   2.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.758 total time=   5.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.757 total time=   5.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.758 total time=   5.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.763 total time=   4.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.767 total time=   4.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.581 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.583 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.590 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.585 total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.670 total time=   2.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.672 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.677 total time=   2.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.674 total time=   2.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.682 total time=   2.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.758 total time=   5.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.757 total time=   4.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.758 total time=   3.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.763 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.767 total time=   4.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.581 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.583 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.585 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.670 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.672 total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.676 total time=   2.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.674 total time=   2.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.682 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.758 total time=   4.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.757 total time=   4.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.758 total time=   4.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.763 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.767 total time=   3.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.581 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.583 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.590 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.585 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.670 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.672 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.677 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.674 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.682 total time=   2.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.758 total time=   6.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.757 total time=   5.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.759 total time=   5.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.763 total time=   4.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.767 total time=   4.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.581 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.583 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.590 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.585 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.590 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.670 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.672 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.677 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.674 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.682 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.758 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.757 total time=   4.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.758 total time=   3.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.763 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.767 total time=   4.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.581 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.583 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.590 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.585 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.590 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.670 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.672 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.677 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.674 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.682 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.758 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.757 total time=   3.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.758 total time=   3.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.763 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.767 total time=   4.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.581 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.583 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.584 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.670 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.672 total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.677 total time=   2.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.674 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.682 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.758 total time=   4.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.757 total time=   5.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.759 total time=   5.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.763 total time=   5.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.768 total time=   4.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.581 total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.583 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.584 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.590 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.670 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.672 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.677 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.674 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.682 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.758 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.757 total time=   4.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.759 total time=   4.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.763 total time=   4.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.768 total time=   4.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.581 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.583 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.590 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.584 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.590 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.670 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.672 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.677 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.674 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.682 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.758 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.758 total time=   4.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.758 total time=   4.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.763 total time=   4.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.768 total time=   4.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.604 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.600 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.606 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.602 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.607 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.706 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.702 total time=   3.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.704 total time=   3.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.704 total time=   3.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.709 total time=   3.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.803 total time=   9.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.798 total time=   9.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.796 total time=   7.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.803 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.801 total time=   7.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.603 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.601 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.606 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.602 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.608 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.705 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.702 total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.704 total time=   3.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.704 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.711 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.803 total time=   6.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.798 total time=   7.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.795 total time=   6.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.803 total time=   7.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.803 total time=   6.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.603 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.600 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.606 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.602 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.608 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.705 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.701 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.705 total time=   4.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.704 total time=   4.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.711 total time=   4.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.802 total time=   8.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.798 total time=   6.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.796 total time=   6.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.804 total time=   7.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.803 total time=   6.7s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.604 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.601 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.607 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.602 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.607 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.706 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.703 total time=   3.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.707 total time=   3.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.705 total time=   3.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.710 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.804 total time=   7.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.799 total time=   6.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.798 total time=   6.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.803 total time=   7.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.803 total time=   6.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.603 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.601 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.607 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.602 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.607 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.706 total time=   4.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.702 total time=   4.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.706 total time=   4.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.705 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.710 total time=   3.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.804 total time=   7.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.799 total time=   6.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.796 total time=   6.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.804 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.803 total time=   6.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.604 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.601 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.606 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.602 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.607 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.705 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.703 total time=   3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.706 total time=   3.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.705 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.711 total time=   3.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.803 total time=   7.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.800 total time=   6.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.796 total time=   6.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.805 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.805 total time=   7.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.603 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.602 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.607 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.600 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.608 total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.705 total time=   5.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.703 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.707 total time=   3.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.704 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.710 total time=   3.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.801 total time=   6.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.801 total time=   6.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.797 total time=   7.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.804 total time=   6.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.802 total time=   7.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.603 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.602 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.607 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.600 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.608 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.705 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.704 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.707 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.704 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.710 total time=   3.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.801 total time=   6.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.801 total time=   6.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.797 total time=   7.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.804 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.802 total time=   8.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.603 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.602 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.607 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.600 total time=   2.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.607 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.704 total time=   4.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.703 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.707 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.704 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.710 total time=   3.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.801 total time=   6.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.800 total time=   6.8s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.797 total time=   6.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.803 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.802 total time=   6.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.777 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.781 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.780 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.789 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.791 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.805 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.807 total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.804 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.815 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.814 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.823 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.826 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.828 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.777 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.781 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.780 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.790 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.791 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.805 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.804 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.814 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.814 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.822 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.826 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.828 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.780 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.783 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.782 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.789 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.789 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.805 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.807 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.813 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.813 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.820 total time=   3.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.822 total time=   2.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.821 total time=   2.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.826 total time=   3.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.828 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.782 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.783 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.780 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.793 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.793 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.806 total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.807 total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.804 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.814 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.814 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.820 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.823 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.827 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.826 total time=   2.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.782 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.783 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.783 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.793 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.793 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.805 total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.814 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.814 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.820 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.823 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.827 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.826 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.781 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.782 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.783 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.791 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.805 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.815 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.814 total time=   1.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.828 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.826 total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.780 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.783 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.780 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.792 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.804 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.805 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.815 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.813 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.822 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.823 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.820 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.826 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.826 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.780 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.783 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.779 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.792 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.792 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.804 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.805 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.815 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.813 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.822 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.823 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.820 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.826 total time=   2.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.826 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.780 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.783 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.783 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.791 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.792 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.804 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.806 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.805 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.815 total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.814 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.822 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.824 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.821 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.827 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.828 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.818 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.814 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.824 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.820 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.831 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.830 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.829 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.838 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.832 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.839 total time=   3.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.841 total time=   3.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.837 total time=   3.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.847 total time=   3.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.840 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.818 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.812 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.824 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.822 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.831 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.828 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.837 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.840 total time=   4.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.841 total time=   4.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.839 total time=   3.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.846 total time=   3.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.841 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.812 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.813 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.825 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.821 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.829 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.828 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.828 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.837 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.832 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.838 total time=   3.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.840 total time=   4.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.837 total time=   4.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.846 total time=   4.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.843 total time=   4.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.818 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.814 total time=   1.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.814 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.825 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.820 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.831 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.828 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.837 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.833 total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.839 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.840 total time=   3.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.836 total time=   3.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.846 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.840 total time=   3.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.819 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.814 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.825 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.821 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.831 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.830 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.838 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.839 total time=   3.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.842 total time=   3.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.837 total time=   3.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.846 total time=   3.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.842 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.816 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.823 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.821 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.830 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.830 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.828 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.836 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.834 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.839 total time=   3.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.842 total time=   3.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.837 total time=   3.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.845 total time=   3.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.842 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.817 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.815 total time=   1.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.815 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.824 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.820 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.830 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.830 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.829 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.836 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.832 total time=   2.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.840 total time=   4.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.840 total time=   4.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.836 total time=   4.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.846 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.841 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.817 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.824 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.820 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.830 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.830 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.829 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.836 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.832 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.840 total time=   3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.840 total time=   3.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.836 total time=   3.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.846 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.841 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.812 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.814 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.824 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.817 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.831 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.826 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.828 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.838 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.832 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.838 total time=   3.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.838 total time=   3.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.836 total time=   3.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.846 total time=   4.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.841 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.844 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.842 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.832 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.847 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.837 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.848 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.844 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.835 total time=   4.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.851 total time=   4.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.840 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.848 total time=   7.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.843 total time=   7.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.834 total time=   7.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.850 total time=   7.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.841 total time=   7.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.843 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.842 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.832 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.846 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.839 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.847 total time=   3.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.845 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.835 total time=   3.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.849 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.843 total time=   3.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.846 total time=   7.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.845 total time=   7.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.834 total time=   7.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.849 total time=   7.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.843 total time=   8.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.845 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.844 total time=   2.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.833 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.847 total time=   2.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.842 total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.848 total time=   3.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.847 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.838 total time=   3.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.853 total time=   3.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.846 total time=   3.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.849 total time=   7.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.848 total time=   7.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.838 total time=   7.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.854 total time=   7.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.847 total time=   7.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.843 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.842 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.846 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.839 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.846 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.846 total time=   3.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.836 total time=   3.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.849 total time=   3.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.843 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.847 total time=   6.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.847 total time=   6.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.836 total time=   7.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.852 total time=   9.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.842 total time=   8.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.844 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.842 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.830 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.846 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.839 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.848 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.846 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.834 total time=   3.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.851 total time=   3.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.843 total time=   3.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.849 total time=   6.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.846 total time=   7.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.834 total time=   7.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.852 total time=   7.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.843 total time=   7.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.841 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.842 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.833 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.847 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.841 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.846 total time=   3.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.846 total time=   3.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.837 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.852 total time=   3.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.845 total time=   3.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.847 total time=   7.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.847 total time=   9.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.838 total time=   9.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.853 total time=   7.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.847 total time=   7.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.840 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.843 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.845 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.838 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.844 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.848 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.836 total time=   3.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.849 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.840 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.847 total time=   7.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.850 total time=   7.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.838 total time=   8.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.852 total time=   7.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.842 total time=   7.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.839 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.843 total time=   2.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.833 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.846 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.837 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.844 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.848 total time=   4.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.836 total time=   4.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.849 total time=   4.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.840 total time=   5.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.847 total time=   9.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.849 total time=   7.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.838 total time=   7.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.851 total time=   7.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.842 total time=   7.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.841 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.843 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.833 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.845 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.837 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.844 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.848 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.837 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.849 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.841 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.846 total time=   7.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.850 total time=   7.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.839 total time=   7.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.852 total time=   7.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.842 total time=   7.2s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.800 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.816 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.810 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.788 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.818 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   1.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.810 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.825 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.786 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.817 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   2.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.812 total time=   3.0s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.825 total time=   2.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.781 total time=   2.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.805 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.812 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.808 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.802 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.810 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.820 total time=   1.2s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.818 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.832 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=nan total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.819 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   2.3s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.816 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.831 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   2.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.804 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.810 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.822 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.819 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.824 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.825 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.827 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.834 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.827 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.823 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.812 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.814 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.809 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.805 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.827 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.824 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.817 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.817 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.818 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.828 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.829 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.817 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.806 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.823 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.821 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.812 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.808 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.814 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.830 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.823 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.813 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.816 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.826 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.828 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.827 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.818 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.824 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.823 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.823 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.815 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.804 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.826 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.828 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   1.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.821 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.823 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.828 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   2.3s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.824 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.828 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.824 total time=   2.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.802 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.810 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.811 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.816 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   1.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.812 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.837 total time=   1.4s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.820 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.840 total time=   2.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.821 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.801 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.811 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.816 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.837 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.820 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   2.6s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.840 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.821 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.810 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.800 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.813 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.816 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.814 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.824 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.806 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.821 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.834 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.818 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.819 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   2.3s\n",
      "[CV 3/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.825 total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.836 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.821 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.820 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   0.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.829 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.817 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.817 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.813 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   3.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.797 total time=   3.6s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.817 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.818 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.816 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.823 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.821 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.813 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.817 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.812 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.811 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.823 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.813 total time=   3.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.809 total time=   3.7s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.803 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   5.0s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.819 total time=   4.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.824 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.821 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.808 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.835 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.816 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.824 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.821 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.814 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.818 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   3.6s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.817 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.804 total time=   3.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.819 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.811 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.822 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.827 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=nan total time=   0.9s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.820 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.812 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.820 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.825 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.816 total time=   3.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.805 total time=   3.7s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.812 total time=   3.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.817 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   3.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.816 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.818 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   0.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.822 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.798 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.813 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.810 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.810 total time=   3.7s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.800 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   3.6s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.811 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   3.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.817 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.824 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   0.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.836 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.798 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.813 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.822 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   2.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.834 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   2.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.808 total time=   4.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.819 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   3.7s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.830 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   3.6s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.829 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=nan total time=   0.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.823 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.825 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.823 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.823 total time=   3.7s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.817 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   3.7s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.815 total time=   3.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.829 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.823 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.825 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.823 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.823 total time=   3.7s\n",
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.817 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   3.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.815 total time=   3.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.813 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   0.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.815 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.824 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.820 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.817 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.815 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   1.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.825 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.818 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   3.6s\n",
      "[CV 3/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.810 total time=   4.7s\n",
      "[CV 4/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.812 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   1.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.769 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=nan total time=   1.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.806 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.801 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.799 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.786 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   3.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.805 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.797 total time=   3.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.806 total time=   6.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.797 total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=nan total time=   6.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.801 total time=   6.7s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.801 total time=   6.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.800 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.795 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.785 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.792 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.792 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.799 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.793 total time=   3.3s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.749 total time=   3.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.803 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.787 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.798 total time=   6.7s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.792 total time=   6.7s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.763 total time=   6.8s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.799 total time=   9.4s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.782 total time=   8.5s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.804 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.790 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.780 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.816 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.796 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.801 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.796 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   3.4s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.812 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   3.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.799 total time=   6.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.795 total time=   6.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.777 total time=   6.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.811 total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   6.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.809 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.796 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.789 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.812 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.798 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.795 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.779 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.771 total time=   3.3s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.808 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.787 total time=   3.3s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.803 total time=   6.8s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.782 total time=   6.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.784 total time=   9.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.804 total time=   8.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.794 total time=   7.6s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.807 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.804 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=nan total time=   1.6s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.812 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.796 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.803 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=nan total time=   3.4s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.807 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.791 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.802 total time=   6.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.799 total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=nan total time=   6.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.806 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.792 total time=   7.0s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.806 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.777 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=nan total time=   1.7s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.812 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.808 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.804 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.784 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=nan total time=   3.4s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.805 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.800 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.797 total time=  16.3s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.785 total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=  16.7s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.801 total time=  15.9s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.796 total time=  16.4s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.812 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.806 total time=   3.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.798 total time=   4.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.813 total time=   4.0s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.795 total time=   4.0s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.804 total time=   7.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.797 total time=   7.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.799 total time=   8.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.808 total time=   9.1s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.789 total time=   9.1s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.810 total time=  17.7s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.795 total time=  15.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.788 total time=  16.1s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.806 total time=  15.8s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.790 total time=  16.0s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.811 total time=   4.0s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.805 total time=   4.4s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.799 total time=   4.2s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.813 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.795 total time=   4.4s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.805 total time=   8.9s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.801 total time=   9.1s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.793 total time=   9.0s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.809 total time=   7.9s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.792 total time=   7.9s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.800 total time=  15.7s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.799 total time=  16.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.787 total time=  21.2s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.806 total time=  17.3s\n",
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.791 total time=  18.2s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.802 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.811 total time=   4.5s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.790 total time=   4.7s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.820 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=nan total time=   3.9s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.800 total time=   8.0s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.804 total time=   7.8s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.792 total time=   7.9s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.813 total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=nan total time=   7.8s\n",
      "[CV 1/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.800 total time=  16.2s\n",
      "[CV 2/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.798 total time=  15.9s\n",
      "[CV 3/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.789 total time=  16.5s\n",
      "[CV 4/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.811 total time=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.56661259 0.64000507 0.71389936 0.56661917 0.64000009 0.71389929\n",
      " 0.56661917 0.64000507 0.71389929 0.56660839 0.64002803 0.71396204\n",
      " 0.56660839 0.64002803 0.71396204 0.56660839 0.64002803 0.71396204\n",
      " 0.56660839 0.63997974 0.71384017 0.56660839 0.63997974 0.71384017\n",
      " 0.56660839 0.63997974 0.71384017 0.58581931 0.67489443 0.76069951\n",
      " 0.58583368 0.67489977 0.76055776 0.5857004  0.67480576 0.76059772\n",
      " 0.58585005 0.67508731 0.76082449 0.58586394 0.67504786 0.76077704\n",
      " 0.58576184 0.67491813 0.76075149 0.5857503  0.6749685  0.76090452\n",
      " 0.58575496 0.67496377 0.76090319 0.58565661 0.67496918 0.76103084\n",
      " 0.60372084 0.7050537  0.80033875 0.6040731  0.70537446 0.80043352\n",
      " 0.60378631 0.70525042 0.80090551 0.60413433 0.70591195 0.80154733\n",
      " 0.60402266 0.70570303 0.80115623 0.60395142 0.70586167 0.8017888\n",
      " 0.60403727 0.70579012 0.80090266 0.60402513 0.70579017 0.80090766\n",
      " 0.60394893 0.7056713  0.80080632 0.78357841 0.80895507 0.82362291\n",
      " 0.78372163 0.80863583 0.823525   0.78480589 0.80896132 0.82333252\n",
      " 0.7860892  0.80882605 0.82326269 0.78656061 0.80900867 0.82355559\n",
      " 0.78580186 0.80920158 0.82354137 0.78518735 0.80854461 0.82347149\n",
      " 0.78517504 0.80855202 0.82347029 0.7855695  0.80879106 0.82414709\n",
      " 0.8182657  0.83184806 0.84103485 0.81833621 0.8315367  0.84121284\n",
      " 0.81719786 0.83071606 0.84082384 0.81812574 0.83167109 0.84038671\n",
      " 0.81881215 0.83222684 0.84120279 0.81832391 0.8317461  0.84089447\n",
      " 0.81816254 0.83148513 0.84060031 0.81817101 0.83156151 0.84074501\n",
      " 0.81638264 0.8308922  0.83985923 0.84029247 0.84344997 0.843181\n",
      " 0.84021413 0.84366314 0.84354984 0.8422556  0.84630868 0.8470729\n",
      " 0.84071382 0.84400325 0.84467366 0.84037859 0.84438933 0.84476245\n",
      " 0.84084991 0.84505274 0.84642639 0.83966219 0.84328798 0.84565685\n",
      " 0.83972356 0.84324332 0.84552504 0.83975583 0.84385352 0.84587662\n",
      "        nan        nan        nan 0.80738247        nan        nan\n",
      "        nan        nan        nan 0.81249335 0.82072644 0.82048844\n",
      "        nan 0.82147393 0.82404064        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.81063171 0.82061996        nan        nan        nan        nan\n",
      " 0.81898942 0.81537728        nan 0.82072975        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.79285691 0.78630171 0.78678527\n",
      " 0.79703412        nan        nan 0.80063172 0.78791016 0.79350832\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.8049857  0.79955026 0.79801645 0.80474486 0.79989317 0.79635093\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=  16.4s\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.580 total time=   5.4s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.582 total time=   5.3s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.590 total time=   5.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.585 total time=   5.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.592 total time=   5.2s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.581 total time=   5.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   5.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.590 total time=   5.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.585 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.592 total time=   5.2s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.581 total time=   4.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.583 total time=   4.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.591 total time=   4.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.585 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.592 total time=   5.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.667 total time=  10.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.671 total time=  10.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.675 total time=  10.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.673 total time=  10.3s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.681 total time=  10.4s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.668 total time=  10.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.671 total time=  10.2s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.676 total time=  10.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.673 total time=  10.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.681 total time=  10.3s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.669 total time=   9.9s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.672 total time=  10.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.677 total time=   9.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.675 total time=  10.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.682 total time=   9.8s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.757 total time=  20.4s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.757 total time=  20.4s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.758 total time=  20.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.763 total time=  20.6s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.768 total time=  20.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.757 total time=  20.2s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.758 total time=  20.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.759 total time=  20.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.763 total time=  19.9s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.769 total time=  20.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  19.7s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  19.6s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  19.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.765 total time=  19.7s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.769 total time=  19.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.581 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.583 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.589 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.585 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.591 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.581 total time=   2.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.589 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.584 total time=   2.8s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.591 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.581 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.582 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.589 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.584 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.590 total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.669 total time=   5.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.672 total time=   5.6s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.675 total time=   5.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.673 total time=   5.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.682 total time=   5.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.669 total time=   5.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.672 total time=   5.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.675 total time=   5.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.673 total time=   5.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.682 total time=   5.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.670 total time=   5.2s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.671 total time=   5.2s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.676 total time=   5.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.674 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.682 total time=   5.3s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.757 total time=  11.3s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.757 total time=  11.3s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.756 total time=  11.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.762 total time=  11.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.767 total time=  11.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.758 total time=  11.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.757 total time=  11.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.756 total time=  10.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.762 total time=  11.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.767 total time=  10.9s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.757 total time=  10.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.757 total time=  10.8s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.756 total time=  10.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.762 total time=  10.7s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.767 total time=  10.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.580 total time=   5.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.582 total time=   5.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.590 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.585 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.592 total time=   5.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.581 total time=   5.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   5.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.590 total time=   5.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.585 total time=   5.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.592 total time=   5.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.581 total time=   4.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.583 total time=   4.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.591 total time=   4.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.585 total time=   5.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.592 total time=   5.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.667 total time=  10.4s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.671 total time=  10.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.675 total time=  10.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.673 total time=  10.4s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.681 total time=  10.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.668 total time=  10.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.671 total time=  10.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.676 total time=  10.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.673 total time=  10.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.681 total time=  10.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.669 total time=   9.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.672 total time=   9.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.677 total time=  10.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.675 total time=  10.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.682 total time=  10.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.756 total time=  20.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.757 total time=  20.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.759 total time=  20.4s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.763 total time=  16.8s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.768 total time=  11.6s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.757 total time=  11.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.758 total time=  11.3s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.759 total time=  11.4s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.764 total time=  11.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.768 total time=  11.4s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  10.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  11.2s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  11.2s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.765 total time=  11.4s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.769 total time=  11.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   3.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.826 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.837 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.833 total time=   3.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.831 total time=   3.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.832 total time=   3.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.827 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.836 total time=   3.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.831 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.829 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.830 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.828 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.835 total time=   2.8s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.834 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.841 total time=   6.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.838 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.848 total time=   5.9s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.843 total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.842 total time=   5.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.846 total time=   5.7s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.839 total time=   5.7s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.848 total time=   5.7s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.841 total time=   5.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.844 total time=   5.7s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.838 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.849 total time=   5.8s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.844 total time=  11.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.846 total time=  11.4s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.842 total time=  11.4s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.853 total time=  11.3s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.846 total time=  11.4s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.846 total time=  11.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.850 total time=  11.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.842 total time=  11.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.853 total time=  11.4s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.846 total time=  11.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.848 total time=  11.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.849 total time=  10.8s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.841 total time=  10.7s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.854 total time=  11.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.847 total time=  10.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.816 total time=   1.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.812 total time=   1.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.816 total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.823 total time=   1.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.816 total time=   1.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.814 total time=   1.4s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.814 total time=   1.4s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.812 total time=   1.4s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.824 total time=   1.4s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.818 total time=   1.4s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.814 total time=   1.3s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.812 total time=   1.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.813 total time=   1.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.823 total time=   1.4s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.820 total time=   1.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.831 total time=   3.2s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.828 total time=   3.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.829 total time=   3.2s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.836 total time=   3.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.830 total time=   3.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.829 total time=   2.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.830 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.827 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.837 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.832 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.829 total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.828 total time=   2.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.828 total time=   2.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.836 total time=   2.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.832 total time=   2.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.838 total time=   6.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.838 total time=   6.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.838 total time=   5.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.845 total time=   5.7s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.840 total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.837 total time=   5.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.840 total time=   5.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.835 total time=   5.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.846 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.840 total time=   5.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.838 total time=   4.2s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.839 total time=   4.2s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.836 total time=   4.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.845 total time=   4.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.841 total time=   4.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.826 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.836 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.828 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.831 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.826 total time=   2.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.836 total time=   3.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.833 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.829 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.830 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.825 total time=   2.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.837 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.832 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.840 total time=   5.7s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   5.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.838 total time=   5.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.848 total time=   5.6s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   5.9s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.841 total time=   5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.844 total time=   5.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.838 total time=   5.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.847 total time=   5.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.842 total time=   5.4s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.838 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.848 total time=   5.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.842 total time=   5.2s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.844 total time=  11.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.846 total time=  11.2s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.843 total time=  11.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.853 total time=  11.4s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.846 total time=  11.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.844 total time=  10.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.849 total time=  10.5s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.842 total time=  10.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.852 total time=  10.8s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.847 total time=  10.6s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.848 total time=  10.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.849 total time=  10.1s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.842 total time=  10.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.854 total time=  10.2s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.846 total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=nan total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=nan total time=   3.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.792 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.825 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.812 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.805 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.818 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.812 total time=   2.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.824 total time=   3.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.800 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.812 total time=   2.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.820 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.801 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.820 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=nan total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=nan total time=   6.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.781 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.781 total time=   6.2s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.818 total time=   5.9s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.806 total time=   6.0s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.799 total time=   5.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.806 total time=   5.7s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.807 total time=   5.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.816 total time=   6.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.752 total time=   5.9s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.807 total time=   5.7s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.813 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=nan total time=   5.7s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.798 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=nan total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=nan total time=  11.9s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.776 total time=  12.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.776 total time=  11.7s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.814 total time=  11.6s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.802 total time=  11.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.792 total time=  11.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.798 total time=  11.4s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.802 total time=  11.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.811 total time=  11.6s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.755 total time=  11.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.804 total time=  10.8s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.813 total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=nan total time=  10.7s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.808 total time=  10.8s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.799 total time=  11.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.824 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=nan total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=nan total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=nan total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=nan total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=nan total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=nan total time=   1.3s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.807 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=nan total time=   1.3s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.821 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=nan total time=   1.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.812 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=nan total time=   1.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.826 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=nan total time=   1.1s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.818 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=nan total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=nan total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.808 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=nan total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=nan total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=nan total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.801 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=nan total time=   2.8s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.820 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=nan total time=   2.3s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.791 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=nan total time=   2.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.826 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=nan total time=   2.3s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.811 total time=   6.1s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.789 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=nan total time=   6.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.794 total time=   6.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.806 total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=nan total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=nan total time=   5.3s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.802 total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=nan total time=   5.3s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.820 total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=nan total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=nan total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=nan total time=   4.3s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.826 total time=   4.5s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.813 total time=   4.5s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.788 total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.807 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.800 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.823 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=nan total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=nan total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.815 total time=   2.6s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.800 total time=   2.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.819 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=nan total time=   2.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.811 total time=   2.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.818 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=nan total time=   2.5s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.824 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=nan total time=   2.4s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.786 total time=   5.2s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.803 total time=   5.2s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.796 total time=   5.2s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.815 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=nan total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=nan total time=   5.0s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.809 total time=   5.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.792 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.818 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=nan total time=   5.2s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.808 total time=   4.6s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.812 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=nan total time=   4.6s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.817 total time=   4.7s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.807 total time=   4.7s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.784 total time=  10.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.798 total time=  11.0s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.793 total time=  11.0s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.810 total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=nan total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=nan total time=  10.2s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.803 total time=   9.9s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.787 total time=   9.9s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.812 total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=nan total time=   9.9s\n",
      "[CV 1/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.804 total time=   9.5s\n",
      "[CV 2/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.806 total time=   9.4s\n",
      "[CV 3/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.790 total time=   9.7s\n",
      "[CV 4/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.810 total time=  10.0s\n",
      "[CV 5/5] END l2_regularization=0, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.806 total time=  10.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.580 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.582 total time=   3.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.591 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.585 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.593 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.580 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.591 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.585 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.593 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.582 total time=   2.8s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.583 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.591 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.585 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.593 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.667 total time=   5.8s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.671 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.677 total time=   6.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.674 total time=   5.8s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.682 total time=   5.9s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.668 total time=   5.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.671 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.677 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.674 total time=   6.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.682 total time=   6.2s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.670 total time=   6.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.672 total time=   6.0s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.677 total time=   6.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.675 total time=   6.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.682 total time=   5.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.757 total time=  11.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.758 total time=  11.8s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.759 total time=  11.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.763 total time=  12.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.768 total time=  11.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.758 total time=  11.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.758 total time=  11.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.759 total time=  12.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.765 total time=  13.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.769 total time=  12.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  11.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  11.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.760 total time=  11.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.765 total time=  11.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.769 total time=  11.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.581 total time=   1.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.583 total time=   1.6s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.589 total time=   1.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.584 total time=   1.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.591 total time=   1.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.581 total time=   1.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.582 total time=   1.6s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.589 total time=   1.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.584 total time=   1.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.591 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.581 total time=   1.5s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.582 total time=   1.5s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.589 total time=   1.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.584 total time=   1.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.590 total time=   1.6s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.669 total time=   3.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.672 total time=   3.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.675 total time=   3.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.673 total time=   3.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.682 total time=   3.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.669 total time=   3.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.672 total time=   3.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.675 total time=   3.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.673 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.682 total time=   3.2s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.669 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.671 total time=   3.0s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.675 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.674 total time=   3.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.682 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.758 total time=   6.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.757 total time=   6.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.757 total time=   6.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.762 total time=   6.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.767 total time=   6.3s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.757 total time=   6.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.757 total time=   6.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.756 total time=   6.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.762 total time=   6.3s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.767 total time=   6.6s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.757 total time=   6.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.757 total time=   6.5s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.756 total time=   6.5s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.762 total time=   6.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.766 total time=   6.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.580 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.582 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.591 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.585 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.593 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.580 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.591 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.585 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.593 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.582 total time=   2.8s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.583 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.591 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.585 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.593 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.667 total time=   6.1s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.671 total time=   6.1s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.677 total time=   6.2s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.674 total time=   6.2s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.682 total time=   6.3s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.668 total time=   6.2s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.671 total time=   6.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.677 total time=   6.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.674 total time=   6.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.682 total time=   6.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.670 total time=   6.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.672 total time=   6.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.677 total time=   6.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.675 total time=   6.2s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.682 total time=   6.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.756 total time=  12.2s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.758 total time=  12.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.759 total time=  12.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.763 total time=  12.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.768 total time=  11.9s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.758 total time=  12.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.758 total time=  12.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.759 total time=  12.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.764 total time=  11.7s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.769 total time=  11.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  11.1s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  11.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.759 total time=  11.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.765 total time=  11.3s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.769 total time=  11.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.827 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.835 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.833 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.830 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.831 total time=   3.0s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.826 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.836 total time=   3.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.833 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.830 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.831 total time=   3.0s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.826 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.836 total time=   2.8s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.833 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.843 total time=   5.7s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   6.0s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.837 total time=   6.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.848 total time=   5.8s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.841 total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.841 total time=   5.7s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.843 total time=   5.8s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.837 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.848 total time=   5.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.843 total time=   5.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.844 total time=   5.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.838 total time=   5.5s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.848 total time=   5.5s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.844 total time=   5.9s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  12.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.846 total time=  12.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.841 total time=  11.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.853 total time=  11.3s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.846 total time=  11.3s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.845 total time=  11.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.848 total time=  10.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.841 total time=  11.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.853 total time=  11.2s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.847 total time=  11.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.848 total time=  11.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.848 total time=  11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.841 total time=  11.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.854 total time=  10.8s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.847 total time=  10.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.816 total time=   1.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.815 total time=   1.5s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.812 total time=   1.5s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.824 total time=   1.5s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.818 total time=   1.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.814 total time=   1.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.815 total time=   1.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.812 total time=   1.5s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.824 total time=   1.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.820 total time=   1.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.815 total time=   1.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.811 total time=   1.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.813 total time=   1.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.822 total time=   1.3s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.818 total time=   1.3s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.829 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.829 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.828 total time=   2.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.838 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.832 total time=   2.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.830 total time=   2.5s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.831 total time=   2.5s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.827 total time=   2.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.836 total time=   2.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.833 total time=   2.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.831 total time=   2.2s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.828 total time=   2.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.828 total time=   2.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.835 total time=   2.2s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.832 total time=   2.2s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.835 total time=   5.5s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.838 total time=   5.6s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.837 total time=   5.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.846 total time=   5.5s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.842 total time=   5.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.838 total time=   4.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.841 total time=   4.8s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.836 total time=   4.9s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.844 total time=   4.8s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.840 total time=   4.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.839 total time=   3.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.841 total time=   4.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.836 total time=   4.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.845 total time=   4.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.842 total time=   4.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.831 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.826 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.836 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.833 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.829 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.829 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.826 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.835 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.832 total time=   2.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.830 total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.829 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.825 total time=   2.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.834 total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.831 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   5.2s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   5.6s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.836 total time=   5.5s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.847 total time=   5.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.843 total time=   5.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.841 total time=   5.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.842 total time=   5.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.837 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.847 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.843 total time=   5.1s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.842 total time=   4.8s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   4.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.837 total time=   4.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.846 total time=   4.9s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.842 total time=   4.8s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.846 total time=  10.2s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  10.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.842 total time=  10.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.852 total time=  10.2s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  10.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.846 total time=  10.5s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.847 total time=  10.5s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.841 total time=  10.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.852 total time=  10.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.847 total time=  10.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.847 total time=   9.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.847 total time=   9.6s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.842 total time=   9.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.853 total time=   9.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.846 total time=   9.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.798 total time=   2.8s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.812 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=nan total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.821 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=nan total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=nan total time=   3.1s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.818 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=nan total time=   2.9s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.821 total time=   3.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.806 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=nan total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.820 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.815 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.832 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=nan total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.796 total time=   6.1s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.806 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=nan total time=   5.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.817 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=nan total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=nan total time=   5.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.810 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=nan total time=   5.5s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.818 total time=   5.3s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.808 total time=   5.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.793 total time=   5.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.819 total time=   5.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.812 total time=   5.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.827 total time=   5.5s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.808 total time=   5.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.792 total time=  14.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.797 total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=nan total time=  12.0s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.812 total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=nan total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=nan total time=  11.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.803 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=nan total time=  11.2s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.798 total time=  11.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.800 total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=nan total time=  10.8s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.812 total time=  11.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.805 total time=  11.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.819 total time=  10.6s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.808 total time=  10.8s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.815 total time=   1.5s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.783 total time=   1.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.819 total time=   1.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.813 total time=   1.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.814 total time=   1.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.817 total time=   1.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.790 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=nan total time=   1.2s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.825 total time=   1.1s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.813 total time=   1.2s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.821 total time=   1.0s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.803 total time=   1.2s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.808 total time=   1.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.834 total time=   1.2s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.817 total time=   1.1s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.810 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.790 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.813 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.808 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.816 total time=   2.7s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.821 total time=   2.5s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.795 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=nan total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.819 total time=   2.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.811 total time=   2.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.819 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=nan total time=   2.1s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.808 total time=   2.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.836 total time=   2.2s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.816 total time=   2.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.802 total time=   5.9s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.785 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.806 total time=   6.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.807 total time=   6.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.808 total time=   6.1s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.816 total time=   5.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.805 total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=nan total time=   5.3s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.809 total time=   5.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.807 total time=   5.2s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.814 total time=   4.3s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.758 total time=   4.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.809 total time=   4.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.832 total time=   4.4s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.815 total time=   4.2s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.812 total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.791 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=nan total time=   2.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.823 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.813 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=nan total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.798 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=nan total time=   2.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.817 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=nan total time=   2.5s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.819 total time=   2.4s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.793 total time=   2.4s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.802 total time=   2.4s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.821 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=nan total time=   2.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.808 total time=   5.2s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.778 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=nan total time=   5.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.822 total time=   5.7s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.808 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=nan total time=   5.8s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.797 total time=   6.1s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.783 total time=   5.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.810 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=nan total time=   5.3s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.823 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=nan total time=   5.3s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.799 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.816 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=nan total time=   5.2s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.806 total time=  11.6s\n",
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.775 total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=nan total time=  10.7s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.820 total time=  11.0s\n",
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.804 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=nan total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=nan total time=  10.5s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.777 total time=  10.6s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.802 total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=nan total time=  10.4s\n",
      "[CV 1/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.816 total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=nan total time=   9.7s\n",
      "[CV 3/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.794 total time=   9.5s\n",
      "[CV 4/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.809 total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=0.1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=nan total time=   9.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.583 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.583 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.591 total time=   2.9s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.587 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.593 total time=   3.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   3.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.591 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.587 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.593 total time=   3.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.583 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.584 total time=   3.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.592 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.587 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.594 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.671 total time=   5.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.674 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.679 total time=   5.9s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.677 total time=   5.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.683 total time=   5.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.671 total time=   5.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.674 total time=   5.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.679 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.677 total time=   5.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.684 total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.672 total time=   5.7s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.674 total time=   5.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.679 total time=   6.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.678 total time=   5.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.684 total time=   6.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.759 total time=  12.4s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.761 total time=  12.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.760 total time=  11.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.767 total time=  11.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.770 total time=  11.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.759 total time=  11.7s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.761 total time=  11.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.761 total time=  11.6s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.766 total time=  11.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.770 total time=  12.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.760 total time=  12.2s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.762 total time=  12.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.761 total time=  12.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.767 total time=  12.0s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.770 total time=  11.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.580 total time=   1.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.581 total time=   1.6s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.588 total time=   1.6s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.584 total time=   1.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.589 total time=   1.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.580 total time=   1.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.581 total time=   1.7s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.588 total time=   1.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   1.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.589 total time=   1.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.580 total time=   1.4s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.581 total time=   1.5s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.588 total time=   1.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.584 total time=   1.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.589 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.668 total time=   3.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.671 total time=   3.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.674 total time=   3.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.673 total time=   3.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.680 total time=   3.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.668 total time=   3.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.671 total time=   3.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.674 total time=   3.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.673 total time=   3.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.680 total time=   3.4s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.668 total time=   3.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.671 total time=   3.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.675 total time=   3.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.673 total time=   3.3s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.680 total time=   3.4s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.756 total time=   6.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.757 total time=   7.0s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.755 total time=   6.4s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.762 total time=   6.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.764 total time=   6.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.756 total time=   6.5s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.757 total time=   6.5s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.755 total time=   6.6s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.761 total time=   6.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.765 total time=   6.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.756 total time=   6.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.757 total time=   6.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.755 total time=   6.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.762 total time=   6.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.764 total time=   6.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.583 total time=   3.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.583 total time=   3.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.591 total time=   3.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.587 total time=   3.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.593 total time=   3.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   3.2s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.583 total time=   3.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.591 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.587 total time=   3.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.593 total time=   3.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.583 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.584 total time=   3.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.592 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.587 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.594 total time=   3.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.671 total time=   6.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.674 total time=   6.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.679 total time=   6.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.677 total time=   6.3s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.683 total time=   6.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.671 total time=   6.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.674 total time=   6.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.679 total time=   6.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.677 total time=   6.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.684 total time=   6.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.672 total time=   6.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.674 total time=   6.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.679 total time=   6.4s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.678 total time=   6.3s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.685 total time=   6.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.759 total time=  12.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.761 total time=  12.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.760 total time=  13.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.766 total time=  12.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.770 total time=  12.4s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.759 total time=  12.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.761 total time=  12.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.760 total time=  12.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.767 total time=  12.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.770 total time=  12.7s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.760 total time=  11.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.761 total time=  11.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.761 total time=  11.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.767 total time=  11.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.770 total time=  11.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.829 total time=   3.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   3.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.824 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.835 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.831 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.829 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.830 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.825 total time=   2.9s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.836 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.831 total time=   3.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.830 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.831 total time=   3.0s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.824 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.836 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.832 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.841 total time=   6.2s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   6.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.838 total time=   5.9s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.849 total time=   5.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.843 total time=   6.0s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.842 total time=   5.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.843 total time=   6.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.837 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.850 total time=   5.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.842 total time=   5.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.844 total time=   6.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.836 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.849 total time=   5.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  12.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  12.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.842 total time=  12.3s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.856 total time=  12.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  12.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.846 total time=  11.5s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.848 total time=  11.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.841 total time=  11.4s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.855 total time=  13.3s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.847 total time=  13.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.848 total time=  12.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.849 total time=  12.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.841 total time=  13.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.856 total time=  12.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.848 total time=  11.7s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.813 total time=   1.5s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.810 total time=   1.5s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.812 total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.824 total time=   1.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.817 total time=   1.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.814 total time=   1.4s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.811 total time=   1.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.808 total time=   1.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.824 total time=   1.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.818 total time=   1.4s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.814 total time=   1.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.811 total time=   1.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.810 total time=   1.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.821 total time=   1.4s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.817 total time=   1.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.827 total time=   3.2s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.827 total time=   2.6s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.826 total time=   2.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.836 total time=   3.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.830 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.829 total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.827 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.825 total time=   2.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.836 total time=   2.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.830 total time=   2.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.829 total time=   2.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.829 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.827 total time=   3.0s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.834 total time=   2.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.829 total time=   2.4s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.834 total time=   5.5s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.840 total time=   5.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.834 total time=   5.4s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.845 total time=   5.6s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.839 total time=   5.4s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.837 total time=   5.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.839 total time=   5.0s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.835 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.845 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.839 total time=   5.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.838 total time=   4.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.840 total time=   4.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.836 total time=   4.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.845 total time=   4.4s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.838 total time=   4.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.828 total time=   3.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.828 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.824 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.832 total time=   2.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.830 total time=   2.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.829 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.827 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.824 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.836 total time=   2.9s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.831 total time=   3.0s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.828 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.827 total time=   2.7s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.822 total time=   2.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.831 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.830 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.840 total time=   6.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.843 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.837 total time=   5.6s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.846 total time=   5.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.842 total time=   5.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.840 total time=   5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.842 total time=   5.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.838 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.847 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.842 total time=   5.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.841 total time=   5.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.0s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.837 total time=   5.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.847 total time=   5.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.843 total time=   5.0s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.844 total time=  10.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  10.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.841 total time=  10.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.853 total time=  10.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.847 total time=  11.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.846 total time=  10.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.847 total time=  10.7s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.842 total time=  10.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.854 total time=  10.3s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.847 total time=  10.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.847 total time=   9.4s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.848 total time=   9.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.841 total time=   9.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.854 total time=   9.6s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=0.1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.848 total time=   9.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.823 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.813 total time=   3.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.812 total time=   3.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.826 total time=   3.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=1;, score=0.824 total time=   5.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.822 total time=   5.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.826 total time=   3.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.818 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.836 total time=   3.4s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=2;, score=0.819 total time=   3.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.785 total time=   3.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.822 total time=   2.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=0.806 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=nan total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=50, min_samples_leaf=4;, score=nan total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.818 total time=   5.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.821 total time=   6.1s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.810 total time=   6.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.817 total time=   6.0s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=1;, score=0.826 total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.820 total time=   5.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.820 total time=   5.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.814 total time=   5.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.831 total time=   5.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=2;, score=0.817 total time=   5.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.802 total time=   5.5s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.819 total time=   5.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=0.804 total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=nan total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=100, min_samples_leaf=4;, score=nan total time=   5.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.815 total time=  12.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.808 total time=  11.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.807 total time=  11.4s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.812 total time=  12.0s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=1;, score=0.824 total time=  11.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.818 total time=  11.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.813 total time=  11.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.808 total time=  10.9s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.825 total time=  11.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=2;, score=0.810 total time=  11.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.774 total time=  11.0s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.814 total time=  11.0s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=0.803 total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=nan total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=None, max_iter=200, min_samples_leaf=4;, score=nan total time=  10.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.816 total time=   1.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.815 total time=   1.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.816 total time=   1.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.834 total time=   1.6s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=1;, score=0.829 total time=   1.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.820 total time=   1.4s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.825 total time=   1.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.804 total time=   1.2s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.829 total time=   1.3s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=2;, score=0.825 total time=   1.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.826 total time=   1.1s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.818 total time=   1.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.815 total time=   1.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.823 total time=   1.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=50, min_samples_leaf=4;, score=0.823 total time=   1.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.816 total time=   2.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.810 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.815 total time=   2.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.827 total time=   2.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=1;, score=0.827 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.811 total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.825 total time=   2.5s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.811 total time=   2.5s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.831 total time=   2.6s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=2;, score=0.827 total time=   2.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.827 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=nan total time=   2.4s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.820 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=nan total time=   2.3s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=100, min_samples_leaf=4;, score=0.825 total time=   2.3s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.814 total time=   5.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.808 total time=   5.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.812 total time=   5.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.824 total time=   5.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=1;, score=0.820 total time=   5.9s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.814 total time=   5.4s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.823 total time=   5.3s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.813 total time=   5.4s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.827 total time=   5.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=2;, score=0.823 total time=   5.0s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.824 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=nan total time=   4.5s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.820 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=nan total time=   4.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=5, max_iter=200, min_samples_leaf=4;, score=0.823 total time=   4.5s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.808 total time=   2.6s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.822 total time=   2.8s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.813 total time=   2.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.832 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=1;, score=0.823 total time=   2.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.825 total time=   2.7s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.817 total time=   2.6s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.808 total time=   2.6s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.818 total time=   2.6s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=2;, score=0.821 total time=   2.7s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.821 total time=   2.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.821 total time=   2.6s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.816 total time=   2.6s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.822 total time=   2.7s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=50, min_samples_leaf=4;, score=0.822 total time=   2.6s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.807 total time=   5.8s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.818 total time=   5.7s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.811 total time=   5.7s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.824 total time=   5.4s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=1;, score=0.813 total time=   5.4s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.827 total time=   5.3s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.800 total time=   5.0s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.802 total time=   5.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.817 total time=   5.2s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=2;, score=0.821 total time=   5.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.817 total time=   4.9s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.820 total time=   4.9s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.812 total time=   4.8s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.816 total time=   4.8s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=100, min_samples_leaf=4;, score=0.821 total time=   4.8s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.801 total time=  10.7s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.814 total time=  10.5s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.807 total time=  10.9s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.818 total time=  11.0s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=1;, score=0.808 total time=  11.1s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.821 total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lambr\\AppData\\Local\\Temp\\ipykernel_22524\\2328077497.py\", line 5, in rmsle\n",
      "    return 1 - np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 521, in mean_squared_log_error\n",
      "    raise ValueError(\n",
      "ValueError: Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=nan total time=  10.2s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.801 total time=  10.1s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.810 total time=  10.1s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=2;, score=0.818 total time=  10.2s\n",
      "[CV 1/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.815 total time=   9.5s\n",
      "[CV 2/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.812 total time=   9.5s\n",
      "[CV 3/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.805 total time=   9.6s\n",
      "[CV 4/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.816 total time=   9.5s\n",
      "[CV 5/5] END l2_regularization=1, learning_rate=1, max_depth=10, max_iter=200, min_samples_leaf=4;, score=0.812 total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.58581253 0.5860431  0.58658381 0.67338008 0.6739439  0.67508172\n",
      " 0.76074    0.76117809 0.7622586  0.58569484 0.58549181 0.58553323\n",
      " 0.67455496 0.67445502 0.67447747 0.75983607 0.76008618 0.75992892\n",
      " 0.58581253 0.5860431  0.58658381 0.67338008 0.6739439  0.67508172\n",
      " 0.76053383 0.76106157 0.76225974 0.83118889 0.83127342 0.83124464\n",
      " 0.84212551 0.84309738 0.84352869 0.84623804 0.8475318  0.84803456\n",
      " 0.81662682 0.816318   0.81638218 0.83095445 0.83103837 0.83058128\n",
      " 0.83991588 0.83974581 0.83997948 0.8304961  0.83075731 0.83055896\n",
      " 0.84200121 0.8423336  0.84295214 0.84631965 0.84686493 0.84778716\n",
      "        nan 0.81169821        nan        nan 0.79605734        nan\n",
      "        nan 0.79161919        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.80327708 0.58618107 0.58630285 0.58676544\n",
      " 0.67396681 0.67438603 0.67527054 0.76103134 0.76184748 0.76248736\n",
      " 0.58557785 0.58538172 0.58544863 0.67442034 0.67432669 0.67424817\n",
      " 0.76001532 0.759679   0.75983015 0.58618107 0.58630285 0.58676544\n",
      " 0.67396681 0.67438603 0.67527054 0.76089651 0.76171771 0.76229809\n",
      " 0.83104497 0.83106688 0.83096281 0.84234995 0.84243264 0.84328215\n",
      " 0.84658042 0.84687217 0.84787707 0.8169256  0.81715621 0.81594805\n",
      " 0.83122244 0.83126038 0.83083343 0.83959208 0.83976072 0.84074196\n",
      " 0.83095103 0.83017845 0.82984113 0.84186084 0.84202373 0.84193474\n",
      " 0.84676849 0.8466729  0.84724545        nan        nan        nan\n",
      "        nan        nan 0.81153485        nan        nan        nan\n",
      " 0.80891238        nan 0.81646034 0.80755868        nan        nan\n",
      " 0.8016818         nan 0.80565038        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58738965 0.58750684 0.58785173 0.67671494 0.67701671 0.67760993\n",
      " 0.76340894 0.76336182 0.76398648 0.58433498 0.58428351 0.58446423\n",
      " 0.67303857 0.67305105 0.67329693 0.75865292 0.75878155 0.75890534\n",
      " 0.58738965 0.58750684 0.58785173 0.6767265  0.67703234 0.67765126\n",
      " 0.76319164 0.76334992 0.763788   0.82975001 0.83016185 0.83039903\n",
      " 0.84241262 0.84253949 0.84299662 0.84766278 0.84721015 0.848328\n",
      " 0.81518074 0.81512661 0.81445392 0.82925929 0.82946203 0.82967804\n",
      " 0.8382051  0.83904478 0.83935249 0.8283126  0.82934548 0.82774754\n",
      " 0.84156647 0.84162979 0.84215005 0.84645124 0.84715084 0.84747762\n",
      " 0.81963268 0.8241865         nan 0.81853007 0.82035948        nan\n",
      " 0.81309388 0.81477999        nan 0.82181452 0.82056749 0.82124681\n",
      " 0.81902058 0.82093295        nan 0.81564498 0.81991716        nan\n",
      " 0.81961181 0.8177706  0.82050921 0.81484722 0.81331301 0.81711143\n",
      " 0.80933806        nan 0.81194476]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ....n_neighbors=3, weights=uniform;, score=0.776 total time=   0.1s\n",
      "[CV 2/5] END ....n_neighbors=3, weights=uniform;, score=0.783 total time=   0.1s\n",
      "[CV 3/5] END ....n_neighbors=3, weights=uniform;, score=0.766 total time=   0.1s\n",
      "[CV 4/5] END ....n_neighbors=3, weights=uniform;, score=0.774 total time=   0.1s\n",
      "[CV 5/5] END ....n_neighbors=3, weights=uniform;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ...n_neighbors=3, weights=distance;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END ...n_neighbors=3, weights=distance;, score=0.788 total time=   0.1s\n",
      "[CV 3/5] END ...n_neighbors=3, weights=distance;, score=0.776 total time=   0.1s\n",
      "[CV 4/5] END ...n_neighbors=3, weights=distance;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ...n_neighbors=3, weights=distance;, score=0.788 total time=   0.1s\n",
      "[CV 1/5] END ....n_neighbors=5, weights=uniform;, score=0.775 total time=   0.1s\n",
      "[CV 2/5] END ....n_neighbors=5, weights=uniform;, score=0.782 total time=   0.1s\n",
      "[CV 3/5] END ....n_neighbors=5, weights=uniform;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END ....n_neighbors=5, weights=uniform;, score=0.771 total time=   0.1s\n",
      "[CV 5/5] END ....n_neighbors=5, weights=uniform;, score=0.776 total time=   0.1s\n",
      "[CV 1/5] END ...n_neighbors=5, weights=distance;, score=0.792 total time=   0.1s\n",
      "[CV 2/5] END ...n_neighbors=5, weights=distance;, score=0.796 total time=   0.1s\n",
      "[CV 3/5] END ...n_neighbors=5, weights=distance;, score=0.780 total time=   0.1s\n",
      "[CV 4/5] END ...n_neighbors=5, weights=distance;, score=0.792 total time=   0.1s\n",
      "[CV 5/5] END ...n_neighbors=5, weights=distance;, score=0.794 total time=   0.1s\n",
      "[CV 1/5] END ...n_neighbors=10, weights=uniform;, score=0.763 total time=   0.1s\n",
      "[CV 2/5] END ...n_neighbors=10, weights=uniform;, score=0.772 total time=   0.1s\n",
      "[CV 3/5] END ...n_neighbors=10, weights=uniform;, score=0.757 total time=   0.1s\n",
      "[CV 4/5] END ...n_neighbors=10, weights=uniform;, score=0.768 total time=   0.1s\n",
      "[CV 5/5] END ...n_neighbors=10, weights=uniform;, score=0.770 total time=   0.1s\n",
      "[CV 1/5] END ..n_neighbors=10, weights=distance;, score=0.793 total time=   0.1s\n",
      "[CV 2/5] END ..n_neighbors=10, weights=distance;, score=0.798 total time=   0.1s\n",
      "[CV 3/5] END ..n_neighbors=10, weights=distance;, score=0.782 total time=   0.1s\n",
      "[CV 4/5] END ..n_neighbors=10, weights=distance;, score=0.797 total time=   0.1s\n",
      "[CV 5/5] END ..n_neighbors=10, weights=distance;, score=0.798 total time=   0.1s\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.111e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.065e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.095e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .........................alpha=0.1;, score=0.718 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=0.1;, score=0.721 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=0.1;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=0.1;, score=0.725 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=0.1;, score=0.721 total time=   0.0s\n",
      "[CV 1/5] END ...........................alpha=1;, score=0.420 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...........................alpha=1;, score=0.413 total time=   0.0s\n",
      "[CV 3/5] END ...........................alpha=1;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END ...........................alpha=1;, score=0.418 total time=   0.0s\n",
      "[CV 5/5] END ...........................alpha=1;, score=0.412 total time=   0.0s\n",
      "[CV 1/5] END ..........................alpha=10;, score=0.420 total time=   0.0s\n",
      "[CV 2/5] END ..........................alpha=10;, score=0.413 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..........................alpha=10;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END ..........................alpha=10;, score=0.418 total time=   0.0s\n",
      "[CV 5/5] END ..........................alpha=10;, score=0.412 total time=   0.0s\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .........................alpha=0.1;, score=0.420 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=0.1;, score=0.413 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=0.1;, score=0.415 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .........................alpha=0.1;, score=0.418 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=0.1;, score=0.412 total time=   0.0s\n",
      "[CV 1/5] END ...........................alpha=1;, score=0.420 total time=   0.0s\n",
      "[CV 2/5] END ...........................alpha=1;, score=0.413 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...........................alpha=1;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END ...........................alpha=1;, score=0.418 total time=   0.0s\n",
      "[CV 5/5] END ...........................alpha=1;, score=0.412 total time=   0.0s\n",
      "[CV 1/5] END ..........................alpha=10;, score=0.420 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:90: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\link.py:93: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(lin_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: overflow encountered in multiply\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "  devp = np.concatenate(([temp.sum()], temp @ X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\_loss\\glm_distribution.py:323: RuntimeWarning: overflow encountered in multiply\n",
      "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..........................alpha=10;, score=0.413 total time=   0.0s\n",
      "[CV 3/5] END ..........................alpha=10;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END ..........................alpha=10;, score=0.418 total time=   0.0s\n",
      "[CV 5/5] END ..........................alpha=10;, score=0.412 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_glm\\glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END max_features=auto, n_estimators=50;, score=0.846 total time=   2.4s\n",
      "[CV 2/5] END max_features=auto, n_estimators=50;, score=0.841 total time=   2.0s\n",
      "[CV 3/5] END max_features=auto, n_estimators=50;, score=0.832 total time=   1.9s\n",
      "[CV 4/5] END max_features=auto, n_estimators=50;, score=0.846 total time=   1.9s\n",
      "[CV 5/5] END max_features=auto, n_estimators=50;, score=0.841 total time=   1.8s\n",
      "[CV 1/5] END max_features=auto, n_estimators=100;, score=0.846 total time=   3.7s\n",
      "[CV 2/5] END max_features=auto, n_estimators=100;, score=0.841 total time=   4.1s\n",
      "[CV 3/5] END max_features=auto, n_estimators=100;, score=0.832 total time=   4.0s\n",
      "[CV 4/5] END max_features=auto, n_estimators=100;, score=0.849 total time=   3.9s\n",
      "[CV 5/5] END max_features=auto, n_estimators=100;, score=0.841 total time=   4.2s\n",
      "[CV 1/5] END max_features=auto, n_estimators=200;, score=0.847 total time=   7.8s\n",
      "[CV 2/5] END max_features=auto, n_estimators=200;, score=0.842 total time=   8.1s\n",
      "[CV 3/5] END max_features=auto, n_estimators=200;, score=0.833 total time=   7.6s\n",
      "[CV 4/5] END max_features=auto, n_estimators=200;, score=0.849 total time=   8.2s\n",
      "[CV 5/5] END max_features=auto, n_estimators=200;, score=0.842 total time=   7.6s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=50;, score=0.838 total time=   0.6s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=50;, score=0.832 total time=   0.6s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=50;, score=0.825 total time=   0.6s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=50;, score=0.835 total time=   0.6s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=50;, score=0.837 total time=   0.5s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=100;, score=0.838 total time=   1.2s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=100;, score=0.830 total time=   1.2s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=100;, score=0.825 total time=   1.2s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=100;, score=0.837 total time=   1.2s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=100;, score=0.837 total time=   1.2s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=200;, score=0.838 total time=   2.5s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=200;, score=0.832 total time=   2.5s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=200;, score=0.827 total time=   2.6s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=200;, score=0.836 total time=   2.5s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=200;, score=0.836 total time=   2.5s\n",
      "[CV 1/5] END max_features=log2, n_estimators=50;, score=0.831 total time=   0.8s\n",
      "[CV 2/5] END max_features=log2, n_estimators=50;, score=0.827 total time=   1.1s\n",
      "[CV 3/5] END max_features=log2, n_estimators=50;, score=0.819 total time=   0.8s\n",
      "[CV 4/5] END max_features=log2, n_estimators=50;, score=0.831 total time=   0.9s\n",
      "[CV 5/5] END max_features=log2, n_estimators=50;, score=0.832 total time=   0.7s\n",
      "[CV 1/5] END max_features=log2, n_estimators=100;, score=0.835 total time=   1.8s\n",
      "[CV 2/5] END max_features=log2, n_estimators=100;, score=0.824 total time=   1.6s\n",
      "[CV 3/5] END max_features=log2, n_estimators=100;, score=0.818 total time=   1.7s\n",
      "[CV 4/5] END max_features=log2, n_estimators=100;, score=0.834 total time=   1.6s\n",
      "[CV 5/5] END max_features=log2, n_estimators=100;, score=0.833 total time=   1.7s\n",
      "[CV 1/5] END max_features=log2, n_estimators=200;, score=0.834 total time=   3.1s\n",
      "[CV 2/5] END max_features=log2, n_estimators=200;, score=0.827 total time=   3.0s\n",
      "[CV 3/5] END max_features=log2, n_estimators=200;, score=0.821 total time=   2.5s\n",
      "[CV 4/5] END max_features=log2, n_estimators=200;, score=0.833 total time=   2.5s\n",
      "[CV 5/5] END max_features=log2, n_estimators=200;, score=0.831 total time=   2.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..................................., score=0.773 total time=   0.7s\n",
      "[CV 2/5] END ..................................., score=0.780 total time=   0.7s\n",
      "[CV 3/5] END ..................................., score=0.764 total time=   0.7s\n",
      "[CV 4/5] END ..................................., score=0.769 total time=   0.7s\n",
      "[CV 5/5] END ..................................., score=0.775 total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..................................., score=0.829 total time=   3.9s\n",
      "[CV 2/5] END ..................................., score=0.831 total time=   4.0s\n",
      "[CV 3/5] END ..................................., score=0.820 total time=   4.0s\n",
      "[CV 4/5] END ..................................., score=0.833 total time=   4.0s\n",
      "[CV 5/5] END ..................................., score=0.831 total time=   3.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.692052</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>0.842190</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 1.0, 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.816792</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 4, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>0.802335</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.842655</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.847073</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'min_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.848328</td>\n",
       "      <td>{'l2_regularization': 1, 'learning_rate': 0.1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.793683</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>0.719723</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>0.415559</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.842679</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>0.772386</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VotingRegressor</td>\n",
       "      <td>0.828807</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  best_score  \\\n",
       "0               AdaBoostRegressor    0.692052   \n",
       "1                BaggingRegressor    0.842190   \n",
       "2           DecisionTreeRegressor    0.816792   \n",
       "3              ExtraTreeRegressor    0.802335   \n",
       "4             ExtraTreesRegressor    0.842655   \n",
       "5       GradientBoostingRegressor    0.847073   \n",
       "6   HistGradientBoostingRegressor    0.848328   \n",
       "7             KNeighborsRegressor    0.793683   \n",
       "8                       LassoLars    0.719723   \n",
       "9                PoissonRegressor    0.415559   \n",
       "10          RandomForestRegressor    0.842679   \n",
       "11              StackingRegressor    0.772386   \n",
       "12                VotingRegressor    0.828807   \n",
       "\n",
       "                                          best_params  \n",
       "0        {'learning_rate': 0.01, 'n_estimators': 200}  \n",
       "1   {'bootstrap': True, 'max_features': 1.0, 'max_...  \n",
       "2   {'max_depth': None, 'min_samples_leaf': 4, 'mi...  \n",
       "3   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
       "4   {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
       "5   {'learning_rate': 0.1, 'max_depth': 10, 'min_s...  \n",
       "6   {'l2_regularization': 1, 'learning_rate': 0.1,...  \n",
       "7          {'n_neighbors': 10, 'weights': 'distance'}  \n",
       "8                                      {'alpha': 0.1}  \n",
       "9                                      {'alpha': 0.1}  \n",
       "10      {'max_features': 'auto', 'n_estimators': 200}  \n",
       "11                                                 {}  \n",
       "12                                                 {}  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_model_using_gridsearchcv(XX,y):\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for config in regressors:\n",
    "        gs =  GridSearchCV(config['reg'], config['params'], cv=cv, return_train_score=False, verbose=3, scoring=scorer)\n",
    "        gs.fit(XX,y)\n",
    "        scores.append({\n",
    "            'model': config['name'],\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "scores = []\n",
    "best_regr = find_best_model_using_gridsearchcv(X_sfs,y)\n",
    "best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b47bc8ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.692052</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>0.842190</td>\n",
       "      <td>{'bootstrap': True, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.816792</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>0.802335</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.842655</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.847073</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>0.848328</td>\n",
       "      <td>{'l2_regularization': 1, 'learning_rate': 0.1, 'max_depth': None, 'max_iter': 200, 'min_samples_leaf': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.793683</td>\n",
       "      <td>{'n_neighbors': 10, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>0.719723</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>0.415559</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.842679</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>0.772386</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VotingRegressor</td>\n",
       "      <td>0.828807</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  best_score  \\\n",
       "0               AdaBoostRegressor    0.692052   \n",
       "1                BaggingRegressor    0.842190   \n",
       "2           DecisionTreeRegressor    0.816792   \n",
       "3              ExtraTreeRegressor    0.802335   \n",
       "4             ExtraTreesRegressor    0.842655   \n",
       "5       GradientBoostingRegressor    0.847073   \n",
       "6   HistGradientBoostingRegressor    0.848328   \n",
       "7             KNeighborsRegressor    0.793683   \n",
       "8                       LassoLars    0.719723   \n",
       "9                PoissonRegressor    0.415559   \n",
       "10          RandomForestRegressor    0.842679   \n",
       "11              StackingRegressor    0.772386   \n",
       "12                VotingRegressor    0.828807   \n",
       "\n",
       "                                                                                                     best_params  \n",
       "0                                                                   {'learning_rate': 0.01, 'n_estimators': 200}  \n",
       "1                              {'bootstrap': True, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100}  \n",
       "2                                            {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10}  \n",
       "3                                             {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}  \n",
       "4                       {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}  \n",
       "5   {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}  \n",
       "6      {'l2_regularization': 1, 'learning_rate': 0.1, 'max_depth': None, 'max_iter': 200, 'min_samples_leaf': 4}  \n",
       "7                                                                     {'n_neighbors': 10, 'weights': 'distance'}  \n",
       "8                                                                                                 {'alpha': 0.1}  \n",
       "9                                                                                                 {'alpha': 0.1}  \n",
       "10                                                                 {'max_features': 'auto', 'n_estimators': 200}  \n",
       "11                                                                                                            {}  \n",
       "12                                                                                                            {}  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "best_regr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a5838",
   "metadata": {},
   "source": [
    "#### We train the best algorithms and some of the best algorithms too (the difference is pretty small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "79906159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingRegressor(l2_regularization=1, max_iter=200,\n",
       "                              min_samples_leaf=4)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_name = best_row['model']\n",
    "parameters = best_row['best_params']\n",
    "algorithm = eval(algorithm_name)(**parameters)\n",
    "algorithm.fit(X_sfs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3ffc56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_regr = BaggingRegressor(bootstrap=True, max_features=1.0, max_samples=1.0, n_estimators=100)\n",
    "extra_trees_regr = ExtraTreesRegressor(max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100)\n",
    "grad_boost_regr = GradientBoostingRegressor(learning_rate=0.1, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200)\n",
    "hist_grad_boost_regr = HistGradientBoostingRegressor(l2_regularization=1, learning_rate=0.1, max_depth=None, max_iter=200, min_samples_leaf=4)\n",
    "random_forest_regr = RandomForestRegressor(max_features='auto', n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "162586d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(n_estimators=100)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_regr.fit(X_sfs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fa17a299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(min_samples_split=10)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees_regr.fit(X_sfs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "102c3043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=10, min_samples_split=10, n_estimators=200)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_regr.fit(X_sfs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5923e3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingRegressor(l2_regularization=1, max_iter=200,\n",
       "                              min_samples_leaf=4)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_grad_boost_regr.fit(X_sfs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "90bf94e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=200)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_regr.fit(X_sfs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35f3ac",
   "metadata": {},
   "source": [
    "### Getting our test dataset ready\n",
    "#### We apply almost the same sequence of actions as above. However, we never delete any records. Instead we fill them with the mean value when it's possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3f12401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony  price  \n",
       "0     Roeekbl       1225   2.0      2.0    NaN  \n",
       "1         NaN       2400   9.0      2.0    NaN  \n",
       "2     Saandtt       1650   5.0      2.0    NaN  \n",
       "3     Winerri       1322   3.0      1.0    NaN  \n",
       "4     AmageSa       1161   2.0      1.0    NaN  \n",
       "...       ...        ...   ...      ...    ...  \n",
       "1475  Prlla C       1246   2.0      1.0    NaN  \n",
       "1476      NaN       1660   3.0      2.0    NaN  \n",
       "1477  Unm 2El       1216   2.0      2.0    NaN  \n",
       "1478  Sahtsva        996   2.0      1.0    NaN  \n",
       "1479  MaicaRS       1150   2.0      2.0    NaN  \n",
       "\n",
       "[1480 rows x 9 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = pd.read_csv('Test.csv')\n",
    "\n",
    "ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd1fb6a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony  \n",
       "0     Roeekbl       1225   2.0      2.0  \n",
       "1         NaN       2400   9.0      2.0  \n",
       "2     Saandtt       1650   5.0      2.0  \n",
       "3     Winerri       1322   3.0      1.0  \n",
       "4     AmageSa       1161   2.0      1.0  \n",
       "...       ...        ...   ...      ...  \n",
       "1475  Prlla C       1246   2.0      1.0  \n",
       "1476      NaN       1660   3.0      2.0  \n",
       "1477  Unm 2El       1216   2.0      2.0  \n",
       "1478  Sahtsva        996   2.0      1.0  \n",
       "1479  MaicaRS       1150   2.0      2.0  \n",
       "\n",
       "[1480 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trim unecessary spaces in the beginning of the column\n",
    "ts1['location'] = ts1['location'].str.lstrip()\n",
    "ts1.drop(columns=['price'],inplace = True)\n",
    "\n",
    "ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "88af1d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony  \n",
       "0     Roeekbl       1225   2.0      2.0  \n",
       "1         NaN       2400   9.0      2.0  \n",
       "2     Saandtt       1650   5.0      2.0  \n",
       "3     Winerri       1322   3.0      1.0  \n",
       "4     AmageSa       1161   2.0      1.0  \n",
       "...       ...        ...   ...      ...  \n",
       "1475  Prlla C       1246   2.0      1.0  \n",
       "1476      NaN       1660   3.0      2.0  \n",
       "1477  Unm 2El       1216   2.0      2.0  \n",
       "1478  Sahtsva        996   2.0      1.0  \n",
       "1479  MaicaRS       1150   2.0      2.0  \n",
       "\n",
       "[1480 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2 = ts1.copy()\n",
    "\n",
    "ts2['location'] = ts2['location'].fillna('missing')\n",
    "\n",
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "806e504c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>nynappanahalli</td>\n",
       "      <td>3 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>18-Mar</td>\n",
       "      <td>Rajarajeshwari Nagar</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1410</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Shanthinagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1080</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>near ullas theater</td>\n",
       "      <td>4 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability              location       size  \\\n",
       "326             Plot  Area  Ready To Move        nynappanahalli  3 Bedroom   \n",
       "454   Super built-up  Area         18-Mar  Rajarajeshwari Nagar      3 BHK   \n",
       "489   Super built-up  Area  Ready To Move          Shanthinagar      2 BHK   \n",
       "1163  Super built-up  Area  Ready To Move    near ullas theater      4 BHK   \n",
       "1257  Super built-up  Area  Ready To Move                #NAME?      3 BHK   \n",
       "\n",
       "     society total_sqft  bath  balcony  lat  long ward  \n",
       "326      NaN       3600   3.0      1.0  NaN   NaN  NaN  \n",
       "454      NaN       1410   2.0      2.0  NaN   NaN  NaN  \n",
       "489      NaN       1080   2.0      2.0  NaN   NaN  NaN  \n",
       "1163     NaN       2600   3.0      3.0  NaN   NaN  NaN  \n",
       "1257     NaN       1600   2.0      1.0  NaN   NaN  NaN  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dataframes on the 'location' column\n",
    "ts3 = pd.merge(ts2, locations, on='location', how='left')\n",
    "ts3[ts3['ward'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f27b0c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>missing</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability location   size society total_sqft  \\\n",
       "1257  Super built-up  Area  Ready To Move  missing  3 BHK     NaN       1600   \n",
       "\n",
       "      bath  balcony  lat  long ward  \n",
       "1257   2.0      1.0  NaN   NaN  NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2.loc[ts2['location'] == 'Rajarajeshwari Nagar','location'] = 'Rajarajeshwari Nagara'\n",
    "ts2.loc[ts2['location'] == 'Shanthinagar', 'location'] = 'Shanti Nagar'\n",
    "ts2.loc[ts2['location'] == 'near ullas theater', 'location'] = 'Near ullas theater'\n",
    "ts2.loc[ts2['location'] == 'nynappanahalli', 'location'] = 'BTM 4th Stage'\n",
    "ts2.loc[ts2['location'] == '#NAME?', 'location'] = 'missing'\n",
    "\n",
    "ts3 = pd.merge(ts2, locations, on='location', how='left')\n",
    "\n",
    "ts3[ts3['ward'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b5c2577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>Doddanekkundi</td>\n",
       "      <td>5270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>Begur</td>\n",
       "      <td>4216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>Bilekahalli</td>\n",
       "      <td>11721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>Anjanapura</td>\n",
       "      <td>3997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>7049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>Puttenahalli</td>\n",
       "      <td>17137.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968   \n",
       "...       ...        ...   ...      ...        ...        ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508   \n",
       "\n",
       "                 ward  density  \n",
       "0       Doddanekkundi   5270.0  \n",
       "1               Begur   4216.0  \n",
       "2          HBR Layout  12717.0  \n",
       "3         Bilekahalli  11721.0  \n",
       "4          Anjanapura   3997.0  \n",
       "...               ...      ...  \n",
       "1475  Outside of town  27566.0  \n",
       "1476        Gottigere   7049.0  \n",
       "1477        Hagadooru   4003.0  \n",
       "1478  Outside of town  27566.0  \n",
       "1479     Puttenahalli  17137.0  \n",
       "\n",
       "[1480 rows x 12 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts3b = pd.merge(ts3, ward_density, on='ward', how='left')\n",
    "ts3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f3897d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>Doddanekkundi</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>Begur</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>Bilekahalli</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>Anjanapura</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>Puttenahalli</td>\n",
       "      <td>17137.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968   \n",
       "...       ...        ...   ...      ...        ...        ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508   \n",
       "\n",
       "                 ward  density  parks_per_ward  \n",
       "0       Doddanekkundi   5270.0             7.0  \n",
       "1               Begur   4216.0             0.0  \n",
       "2          HBR Layout  12717.0             5.0  \n",
       "3         Bilekahalli  11721.0             5.0  \n",
       "4          Anjanapura   3997.0             5.0  \n",
       "...               ...      ...             ...  \n",
       "1475  Outside of town  27566.0             NaN  \n",
       "1476        Gottigere   7049.0             2.0  \n",
       "1477        Hagadooru   4003.0             1.0  \n",
       "1478  Outside of town  27566.0             NaN  \n",
       "1479     Puttenahalli  17137.0             2.0  \n",
       "\n",
       "[1480 rows x 13 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts3c = pd.merge(ts3b, ward_parks, on='ward', how='left')\n",
    "ts3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7743ac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [area_type, availability, location, size, society, total_sqft, bath, balcony, lat, long, ward, density, parks_per_ward]\n",
       "Index: []"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts3c['ward'] = ts3c['ward'].fillna('missing')\n",
    "ts3c['lat'] = ts3c['lat'].fillna(ts3c['lat'].mean())\n",
    "ts3c['long'] = ts3c['long'].fillna(ts3c['long'].mean())\n",
    "ts3c['parks_per_ward'] = ts3c['parks_per_ward'].fillna(ts3c['parks_per_ward'].mean())\n",
    "ts3c['density'] = ts3c['density'].fillna(ts3c['density'].mean())\n",
    "\n",
    "ts3c[ts3c['long'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "22df8e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>Doddanekkundi</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.051436</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>Begur</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.144852</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>Bilekahalli</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.243176</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>Anjanapura</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.569574</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.217266</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.069071</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.865235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>Puttenahalli</td>\n",
       "      <td>17137.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.821156</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968   \n",
       "...       ...        ...   ...      ...        ...        ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508   \n",
       "\n",
       "                 ward  density  parks_per_ward  nearest_high_school  \\\n",
       "0       Doddanekkundi   5270.0        7.000000             1.051436   \n",
       "1               Begur   4216.0        0.000000             2.144852   \n",
       "2          HBR Layout  12717.0        5.000000             1.220832   \n",
       "3         Bilekahalli  11721.0        5.000000             1.243176   \n",
       "4          Anjanapura   3997.0        5.000000             0.289757   \n",
       "...               ...      ...             ...                  ...   \n",
       "1475  Outside of town  27566.0        4.122466             1.569574   \n",
       "1476        Gottigere   7049.0        2.000000             0.217266   \n",
       "1477        Hagadooru   4003.0        1.000000             1.069071   \n",
       "1478  Outside of town  27566.0        4.122466             1.865235   \n",
       "1479     Puttenahalli  17137.0        2.000000             0.821156   \n",
       "\n",
       "      high_schools_3km  \n",
       "0                    9  \n",
       "1                    4  \n",
       "2                   12  \n",
       "3                    9  \n",
       "4                   15  \n",
       "...                ...  \n",
       "1475                 2  \n",
       "1476                 4  \n",
       "1477                 6  \n",
       "1478                 1  \n",
       "1479                21  \n",
       "\n",
       "[1480 rows x 15 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts4 = find_nearest_places(ts3c, high_schools, \"high_schools_3km\", \"nearest_high_school\", 3)\n",
    "\n",
    "ts4\n",
    "\n",
    "#df4[df4[\"high_schools_3km\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cef8cabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>Doddanekkundi</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.051436</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>Begur</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.144852</td>\n",
       "      <td>4</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>Bilekahalli</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.243176</td>\n",
       "      <td>9</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>Anjanapura</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>15</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.569574</td>\n",
       "      <td>2</td>\n",
       "      <td>1.772065</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.217266</td>\n",
       "      <td>4</td>\n",
       "      <td>1.511123</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.069071</td>\n",
       "      <td>6</td>\n",
       "      <td>1.120029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.865235</td>\n",
       "      <td>1</td>\n",
       "      <td>4.195692</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>Puttenahalli</td>\n",
       "      <td>17137.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.821156</td>\n",
       "      <td>21</td>\n",
       "      <td>0.747050</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968   \n",
       "...       ...        ...   ...      ...        ...        ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508   \n",
       "\n",
       "                 ward  density  parks_per_ward  nearest_high_school  \\\n",
       "0       Doddanekkundi   5270.0        7.000000             1.051436   \n",
       "1               Begur   4216.0        0.000000             2.144852   \n",
       "2          HBR Layout  12717.0        5.000000             1.220832   \n",
       "3         Bilekahalli  11721.0        5.000000             1.243176   \n",
       "4          Anjanapura   3997.0        5.000000             0.289757   \n",
       "...               ...      ...             ...                  ...   \n",
       "1475  Outside of town  27566.0        4.122466             1.569574   \n",
       "1476        Gottigere   7049.0        2.000000             0.217266   \n",
       "1477        Hagadooru   4003.0        1.000000             1.069071   \n",
       "1478  Outside of town  27566.0        4.122466             1.865235   \n",
       "1479     Puttenahalli  17137.0        2.000000             0.821156   \n",
       "\n",
       "      high_schools_3km  nearest_hospital  hospitals_5km  \n",
       "0                    9          0.235652             53  \n",
       "1                    4          1.271498             41  \n",
       "2                   12          0.954018            118  \n",
       "3                    9          0.621746            157  \n",
       "4                   15          0.527077             83  \n",
       "...                ...               ...            ...  \n",
       "1475                 2          1.772065             26  \n",
       "1476                 4          1.511123             26  \n",
       "1477                 6          1.120029             24  \n",
       "1478                 1          4.195692              3  \n",
       "1479                21          0.747050            168  \n",
       "\n",
       "[1480 rows x 17 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts5 = find_nearest_places(ts4, hospitals, \"hospitals_5km\", \"nearest_hospital\", 5)\n",
    "\n",
    "ts5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "94bade2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>Doddanekkundi</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.051436</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>53</td>\n",
       "      <td>8.950588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>Begur</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.144852</td>\n",
       "      <td>4</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>41</td>\n",
       "      <td>2.747318</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>118</td>\n",
       "      <td>3.939355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>Bilekahalli</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.243176</td>\n",
       "      <td>9</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>157</td>\n",
       "      <td>3.049196</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>Anjanapura</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>15</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>83</td>\n",
       "      <td>4.879432</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.569574</td>\n",
       "      <td>2</td>\n",
       "      <td>1.772065</td>\n",
       "      <td>26</td>\n",
       "      <td>1.953872</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.217266</td>\n",
       "      <td>4</td>\n",
       "      <td>1.511123</td>\n",
       "      <td>26</td>\n",
       "      <td>5.981703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.069071</td>\n",
       "      <td>6</td>\n",
       "      <td>1.120029</td>\n",
       "      <td>24</td>\n",
       "      <td>13.478028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.865235</td>\n",
       "      <td>1</td>\n",
       "      <td>4.195692</td>\n",
       "      <td>3</td>\n",
       "      <td>9.554815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>Puttenahalli</td>\n",
       "      <td>17137.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.821156</td>\n",
       "      <td>21</td>\n",
       "      <td>0.747050</td>\n",
       "      <td>168</td>\n",
       "      <td>2.389793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968   \n",
       "...       ...        ...   ...      ...        ...        ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508   \n",
       "\n",
       "                 ward  density  parks_per_ward  nearest_high_school  \\\n",
       "0       Doddanekkundi   5270.0        7.000000             1.051436   \n",
       "1               Begur   4216.0        0.000000             2.144852   \n",
       "2          HBR Layout  12717.0        5.000000             1.220832   \n",
       "3         Bilekahalli  11721.0        5.000000             1.243176   \n",
       "4          Anjanapura   3997.0        5.000000             0.289757   \n",
       "...               ...      ...             ...                  ...   \n",
       "1475  Outside of town  27566.0        4.122466             1.569574   \n",
       "1476        Gottigere   7049.0        2.000000             0.217266   \n",
       "1477        Hagadooru   4003.0        1.000000             1.069071   \n",
       "1478  Outside of town  27566.0        4.122466             1.865235   \n",
       "1479     Puttenahalli  17137.0        2.000000             0.821156   \n",
       "\n",
       "      high_schools_3km  nearest_hospital  hospitals_5km  nearest_university  \\\n",
       "0                    9          0.235652             53            8.950588   \n",
       "1                    4          1.271498             41            2.747318   \n",
       "2                   12          0.954018            118            3.939355   \n",
       "3                    9          0.621746            157            3.049196   \n",
       "4                   15          0.527077             83            4.879432   \n",
       "...                ...               ...            ...                 ...   \n",
       "1475                 2          1.772065             26            1.953872   \n",
       "1476                 4          1.511123             26            5.981703   \n",
       "1477                 6          1.120029             24           13.478028   \n",
       "1478                 1          4.195692              3            9.554815   \n",
       "1479                21          0.747050            168            2.389793   \n",
       "\n",
       "      universities_5km  \n",
       "0                    0  \n",
       "1                    2  \n",
       "2                    1  \n",
       "3                    4  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1475                 2  \n",
       "1476                 0  \n",
       "1477                 0  \n",
       "1478                 0  \n",
       "1479                 1  \n",
       "\n",
       "[1480 rows x 19 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts6 = find_nearest_places(ts5, universities, \"universities_5km\", \"nearest_university\", 5)\n",
    "\n",
    "ts6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "441e5a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>...</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.051436</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>53</td>\n",
       "      <td>8.950588</td>\n",
       "      <td>0</td>\n",
       "      <td>3.134721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>...</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.144852</td>\n",
       "      <td>4</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>41</td>\n",
       "      <td>2.747318</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>...</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>118</td>\n",
       "      <td>3.939355</td>\n",
       "      <td>1</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>...</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.243176</td>\n",
       "      <td>9</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>157</td>\n",
       "      <td>3.049196</td>\n",
       "      <td>4</td>\n",
       "      <td>1.305272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>...</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>15</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>83</td>\n",
       "      <td>4.879432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>...</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.569574</td>\n",
       "      <td>2</td>\n",
       "      <td>1.772065</td>\n",
       "      <td>26</td>\n",
       "      <td>1.953872</td>\n",
       "      <td>2</td>\n",
       "      <td>2.866206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>...</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.217266</td>\n",
       "      <td>4</td>\n",
       "      <td>1.511123</td>\n",
       "      <td>26</td>\n",
       "      <td>5.981703</td>\n",
       "      <td>0</td>\n",
       "      <td>2.564197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>...</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.069071</td>\n",
       "      <td>6</td>\n",
       "      <td>1.120029</td>\n",
       "      <td>24</td>\n",
       "      <td>13.478028</td>\n",
       "      <td>0</td>\n",
       "      <td>1.228699</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>...</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>1.865235</td>\n",
       "      <td>1</td>\n",
       "      <td>4.195692</td>\n",
       "      <td>3</td>\n",
       "      <td>9.554815</td>\n",
       "      <td>0</td>\n",
       "      <td>3.789765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>...</td>\n",
       "      <td>17137.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.821156</td>\n",
       "      <td>21</td>\n",
       "      <td>0.747050</td>\n",
       "      <td>168</td>\n",
       "      <td>2.389793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578089</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  ...  density  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464  ...   5270.0   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684  ...   4216.0   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650  ...  12717.0   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037  ...  11721.0   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968  ...   3997.0   \n",
       "...       ...        ...   ...      ...        ...        ...  ...      ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520  ...  27566.0   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845  ...   7049.0   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624  ...   4003.0   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550  ...  27566.0   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508  ...  17137.0   \n",
       "\n",
       "      parks_per_ward  nearest_high_school  high_schools_3km  nearest_hospital  \\\n",
       "0           7.000000             1.051436                 9          0.235652   \n",
       "1           0.000000             2.144852                 4          1.271498   \n",
       "2           5.000000             1.220832                12          0.954018   \n",
       "3           5.000000             1.243176                 9          0.621746   \n",
       "4           5.000000             0.289757                15          0.527077   \n",
       "...              ...                  ...               ...               ...   \n",
       "1475        4.122466             1.569574                 2          1.772065   \n",
       "1476        2.000000             0.217266                 4          1.511123   \n",
       "1477        1.000000             1.069071                 6          1.120029   \n",
       "1478        4.122466             1.865235                 1          4.195692   \n",
       "1479        2.000000             0.821156                21          0.747050   \n",
       "\n",
       "      hospitals_5km  nearest_university  universities_5km  \\\n",
       "0                53            8.950588                 0   \n",
       "1                41            2.747318                 2   \n",
       "2               118            3.939355                 1   \n",
       "3               157            3.049196                 4   \n",
       "4                83            4.879432                 1   \n",
       "...             ...                 ...               ...   \n",
       "1475             26            1.953872                 2   \n",
       "1476             26            5.981703                 0   \n",
       "1477             24           13.478028                 0   \n",
       "1478              3            9.554815                 0   \n",
       "1479            168            2.389793                 1   \n",
       "\n",
       "      nearest_police_station  police_stations_3km  \n",
       "0                   3.134721                    0  \n",
       "1                   1.427325                    2  \n",
       "2                   1.773094                    5  \n",
       "3                   1.305272                    5  \n",
       "4                   0.197445                    3  \n",
       "...                      ...                  ...  \n",
       "1475                2.866206                    1  \n",
       "1476                2.564197                    1  \n",
       "1477                1.228699                    2  \n",
       "1478                3.789765                    0  \n",
       "1479                0.578089                    5  \n",
       "\n",
       "[1480 rows x 21 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts7 = find_nearest_places(ts6, police_stations, \"police_stations_3km\", \"nearest_police_station\", 3)\n",
    "\n",
    "ts7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5a485d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051436</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>53</td>\n",
       "      <td>8.950588</td>\n",
       "      <td>0</td>\n",
       "      <td>3.134721</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543893</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>...</td>\n",
       "      <td>2.144852</td>\n",
       "      <td>4</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>41</td>\n",
       "      <td>2.747318</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427325</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975165</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>...</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>118</td>\n",
       "      <td>3.939355</td>\n",
       "      <td>1</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>5</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.243176</td>\n",
       "      <td>9</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>157</td>\n",
       "      <td>3.049196</td>\n",
       "      <td>4</td>\n",
       "      <td>1.305272</td>\n",
       "      <td>5</td>\n",
       "      <td>0.330802</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>15</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>83</td>\n",
       "      <td>4.879432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197445</td>\n",
       "      <td>3</td>\n",
       "      <td>0.867344</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.569574</td>\n",
       "      <td>2</td>\n",
       "      <td>1.772065</td>\n",
       "      <td>26</td>\n",
       "      <td>1.953872</td>\n",
       "      <td>2</td>\n",
       "      <td>2.866206</td>\n",
       "      <td>1</td>\n",
       "      <td>2.484172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217266</td>\n",
       "      <td>4</td>\n",
       "      <td>1.511123</td>\n",
       "      <td>26</td>\n",
       "      <td>5.981703</td>\n",
       "      <td>0</td>\n",
       "      <td>2.564197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.069071</td>\n",
       "      <td>6</td>\n",
       "      <td>1.120029</td>\n",
       "      <td>24</td>\n",
       "      <td>13.478028</td>\n",
       "      <td>0</td>\n",
       "      <td>1.228699</td>\n",
       "      <td>2</td>\n",
       "      <td>1.241454</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>...</td>\n",
       "      <td>1.865235</td>\n",
       "      <td>1</td>\n",
       "      <td>4.195692</td>\n",
       "      <td>3</td>\n",
       "      <td>9.554815</td>\n",
       "      <td>0</td>\n",
       "      <td>3.789765</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000183</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821156</td>\n",
       "      <td>21</td>\n",
       "      <td>0.747050</td>\n",
       "      <td>168</td>\n",
       "      <td>2.389793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578089</td>\n",
       "      <td>5</td>\n",
       "      <td>0.487060</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  ...  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464  ...   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684  ...   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650  ...   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037  ...   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968  ...   \n",
       "...       ...        ...   ...      ...        ...        ...  ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520  ...   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845  ...   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624  ...   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550  ...   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508  ...   \n",
       "\n",
       "     nearest_high_school  high_schools_3km  nearest_hospital  hospitals_5km  \\\n",
       "0               1.051436                 9          0.235652             53   \n",
       "1               2.144852                 4          1.271498             41   \n",
       "2               1.220832                12          0.954018            118   \n",
       "3               1.243176                 9          0.621746            157   \n",
       "4               0.289757                15          0.527077             83   \n",
       "...                  ...               ...               ...            ...   \n",
       "1475            1.569574                 2          1.772065             26   \n",
       "1476            0.217266                 4          1.511123             26   \n",
       "1477            1.069071                 6          1.120029             24   \n",
       "1478            1.865235                 1          4.195692              3   \n",
       "1479            0.821156                21          0.747050            168   \n",
       "\n",
       "      nearest_university  universities_5km  nearest_police_station  \\\n",
       "0               8.950588                 0                3.134721   \n",
       "1               2.747318                 2                1.427325   \n",
       "2               3.939355                 1                1.773094   \n",
       "3               3.049196                 4                1.305272   \n",
       "4               4.879432                 1                0.197445   \n",
       "...                  ...               ...                     ...   \n",
       "1475            1.953872                 2                2.866206   \n",
       "1476            5.981703                 0                2.564197   \n",
       "1477           13.478028                 0                1.228699   \n",
       "1478            9.554815                 0                3.789765   \n",
       "1479            2.389793                 1                0.578089   \n",
       "\n",
       "      police_stations_3km  nearest_park  parks_3km  \n",
       "0                       0      0.543893         10  \n",
       "1                       2      0.975165         18  \n",
       "2                       5      0.108980         43  \n",
       "3                       5      0.330802        106  \n",
       "4                       3      0.867344         28  \n",
       "...                   ...           ...        ...  \n",
       "1475                    1      2.484172          1  \n",
       "1476                    1      0.000000          6  \n",
       "1477                    2      1.241454          2  \n",
       "1478                    0      2.000183          2  \n",
       "1479                    5      0.487060         85  \n",
       "\n",
       "[1480 rows x 23 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts7b = find_nearest_places(ts7, parks, \"parks_3km\", \"nearest_park\", 3)\n",
    "\n",
    "ts7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ce9d7b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>53</td>\n",
       "      <td>8.950588</td>\n",
       "      <td>0</td>\n",
       "      <td>3.134721</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543893</td>\n",
       "      <td>10</td>\n",
       "      <td>0.470666</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>...</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>41</td>\n",
       "      <td>2.747318</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427325</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975165</td>\n",
       "      <td>18</td>\n",
       "      <td>0.947945</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>118</td>\n",
       "      <td>3.939355</td>\n",
       "      <td>1</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>5</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>157</td>\n",
       "      <td>3.049196</td>\n",
       "      <td>4</td>\n",
       "      <td>1.305272</td>\n",
       "      <td>5</td>\n",
       "      <td>0.330802</td>\n",
       "      <td>106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>83</td>\n",
       "      <td>4.879432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197445</td>\n",
       "      <td>3</td>\n",
       "      <td>0.867344</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Vittasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Prlla C</td>\n",
       "      <td>1246</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.772065</td>\n",
       "      <td>26</td>\n",
       "      <td>1.953872</td>\n",
       "      <td>2</td>\n",
       "      <td>2.866206</td>\n",
       "      <td>1</td>\n",
       "      <td>2.484172</td>\n",
       "      <td>1</td>\n",
       "      <td>1.139354</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Gottigere</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511123</td>\n",
       "      <td>26</td>\n",
       "      <td>5.981703</td>\n",
       "      <td>0</td>\n",
       "      <td>2.564197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Channasandra</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Unm 2El</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120029</td>\n",
       "      <td>24</td>\n",
       "      <td>13.478028</td>\n",
       "      <td>0</td>\n",
       "      <td>1.228699</td>\n",
       "      <td>2</td>\n",
       "      <td>1.241454</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>18-Feb</td>\n",
       "      <td>Tumkur Road</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Sahtsva</td>\n",
       "      <td>996</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>...</td>\n",
       "      <td>4.195692</td>\n",
       "      <td>3</td>\n",
       "      <td>9.554815</td>\n",
       "      <td>0</td>\n",
       "      <td>3.789765</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000183</td>\n",
       "      <td>2</td>\n",
       "      <td>0.657619</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>7th Phase JP Nagar</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>MaicaRS</td>\n",
       "      <td>1150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747050</td>\n",
       "      <td>168</td>\n",
       "      <td>2.389793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578089</td>\n",
       "      <td>5</td>\n",
       "      <td>0.487060</td>\n",
       "      <td>85</td>\n",
       "      <td>0.568469</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 area_type   availability            location       size  \\\n",
       "0     Super built-up  Area  Ready To Move         Brookefield      2 BHK   \n",
       "1               Plot  Area  Ready To Move       Akshaya Nagar  9 Bedroom   \n",
       "2               Plot  Area         18-Apr         Hennur Road  4 Bedroom   \n",
       "3     Super built-up  Area  Ready To Move   Kodichikkanahalli      3 BHK   \n",
       "4     Super built-up  Area  Ready To Move         Konanakunte      2 BHK   \n",
       "...                    ...            ...                 ...        ...   \n",
       "1475  Super built-up  Area  Ready To Move         Vittasandra      2 BHK   \n",
       "1476  Super built-up  Area  Ready To Move           Gottigere      3 BHK   \n",
       "1477  Super built-up  Area  Ready To Move        Channasandra      2 BHK   \n",
       "1478        Built-up  Area         18-Feb         Tumkur Road      2 BHK   \n",
       "1479        Built-up  Area  Ready To Move  7th Phase JP Nagar      2 BHK   \n",
       "\n",
       "      society total_sqft  bath  balcony        lat       long  ...  \\\n",
       "0     Roeekbl       1225   2.0      2.0  12.965480  77.718464  ...   \n",
       "1         NaN       2400   9.0      2.0  12.867799  77.616684  ...   \n",
       "2     Saandtt       1650   5.0      2.0  13.013906  77.626650  ...   \n",
       "3     Winerri       1322   3.0      1.0  12.895345  77.615037  ...   \n",
       "4     AmageSa       1161   2.0      1.0  12.882219  77.565968  ...   \n",
       "...       ...        ...   ...      ...        ...        ...  ...   \n",
       "1475  Prlla C       1246   2.0      1.0  12.855352  77.636520  ...   \n",
       "1476      NaN       1660   3.0      2.0  12.856443  77.588845  ...   \n",
       "1477  Unm 2El       1216   2.0      2.0  12.979699  77.761624  ...   \n",
       "1478  Sahtsva        996   2.0      1.0  13.058265  77.468550  ...   \n",
       "1479  MaicaRS       1150   2.0      2.0  12.897862  77.584508  ...   \n",
       "\n",
       "     nearest_hospital  hospitals_5km  nearest_university  universities_5km  \\\n",
       "0            0.235652             53            8.950588                 0   \n",
       "1            1.271498             41            2.747318                 2   \n",
       "2            0.954018            118            3.939355                 1   \n",
       "3            0.621746            157            3.049196                 4   \n",
       "4            0.527077             83            4.879432                 1   \n",
       "...               ...            ...                 ...               ...   \n",
       "1475         1.772065             26            1.953872                 2   \n",
       "1476         1.511123             26            5.981703                 0   \n",
       "1477         1.120029             24           13.478028                 0   \n",
       "1478         4.195692              3            9.554815                 0   \n",
       "1479         0.747050            168            2.389793                 1   \n",
       "\n",
       "      nearest_police_station  police_stations_3km  nearest_park  parks_3km  \\\n",
       "0                   3.134721                    0      0.543893         10   \n",
       "1                   1.427325                    2      0.975165         18   \n",
       "2                   1.773094                    5      0.108980         43   \n",
       "3                   1.305272                    5      0.330802        106   \n",
       "4                   0.197445                    3      0.867344         28   \n",
       "...                      ...                  ...           ...        ...   \n",
       "1475                2.866206                    1      2.484172          1   \n",
       "1476                2.564197                    1      0.000000          6   \n",
       "1477                1.228699                    2      1.241454          2   \n",
       "1478                3.789765                    0      2.000183          2   \n",
       "1479                0.578089                    5      0.487060         85   \n",
       "\n",
       "      nearest_primary_school  primary_schools_2km  \n",
       "0                   0.470666                    9  \n",
       "1                   0.947945                    5  \n",
       "2                   0.000000                   37  \n",
       "3                   0.000000                   12  \n",
       "4                   0.000000                   10  \n",
       "...                      ...                  ...  \n",
       "1475                1.139354                    7  \n",
       "1476                0.000000                    7  \n",
       "1477                0.000000                   14  \n",
       "1478                0.657619                    6  \n",
       "1479                0.568469                   12  \n",
       "\n",
       "[1480 rows x 25 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts7c = find_nearest_places(ts7b, primary_schools, \"primary_schools_2km\", \"nearest_primary_school\", 2)\n",
    "\n",
    "ts7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5a7d63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts7c.to_csv('new_test_set2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "68e422ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>location</th>\n",
       "      <th>size</th>\n",
       "      <th>society</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_university</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Brookefield</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>Roeekbl</td>\n",
       "      <td>1225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>53</td>\n",
       "      <td>8.950588</td>\n",
       "      <td>0</td>\n",
       "      <td>3.134721</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543893</td>\n",
       "      <td>10</td>\n",
       "      <td>0.470666</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Akshaya Nagar</td>\n",
       "      <td>9 Bedroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>...</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>41</td>\n",
       "      <td>2.747318</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427325</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975165</td>\n",
       "      <td>18</td>\n",
       "      <td>0.947945</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plot  Area</td>\n",
       "      <td>18-Apr</td>\n",
       "      <td>Hennur Road</td>\n",
       "      <td>4 Bedroom</td>\n",
       "      <td>Saandtt</td>\n",
       "      <td>1650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>118</td>\n",
       "      <td>3.939355</td>\n",
       "      <td>1</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>5</td>\n",
       "      <td>0.108980</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Kodichikkanahalli</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>Winerri</td>\n",
       "      <td>1322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>157</td>\n",
       "      <td>3.049196</td>\n",
       "      <td>4</td>\n",
       "      <td>1.305272</td>\n",
       "      <td>5</td>\n",
       "      <td>0.330802</td>\n",
       "      <td>106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super built-up  Area</td>\n",
       "      <td>Ready To Move</td>\n",
       "      <td>Konanakunte</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>AmageSa</td>\n",
       "      <td>1161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>83</td>\n",
       "      <td>4.879432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197445</td>\n",
       "      <td>3</td>\n",
       "      <td>0.867344</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              area_type   availability           location       size  society  \\\n",
       "0  Super built-up  Area  Ready To Move        Brookefield      2 BHK  Roeekbl   \n",
       "1            Plot  Area  Ready To Move      Akshaya Nagar  9 Bedroom      NaN   \n",
       "2            Plot  Area         18-Apr        Hennur Road  4 Bedroom  Saandtt   \n",
       "3  Super built-up  Area  Ready To Move  Kodichikkanahalli      3 BHK  Winerri   \n",
       "4  Super built-up  Area  Ready To Move        Konanakunte      2 BHK  AmageSa   \n",
       "\n",
       "  total_sqft  bath  balcony        lat       long  ... nearest_hospital  \\\n",
       "0       1225   2.0      2.0  12.965480  77.718464  ...         0.235652   \n",
       "1       2400   9.0      2.0  12.867799  77.616684  ...         1.271498   \n",
       "2       1650   5.0      2.0  13.013906  77.626650  ...         0.954018   \n",
       "3       1322   3.0      1.0  12.895345  77.615037  ...         0.621746   \n",
       "4       1161   2.0      1.0  12.882219  77.565968  ...         0.527077   \n",
       "\n",
       "   hospitals_5km  nearest_university  universities_5km  \\\n",
       "0             53            8.950588                 0   \n",
       "1             41            2.747318                 2   \n",
       "2            118            3.939355                 1   \n",
       "3            157            3.049196                 4   \n",
       "4             83            4.879432                 1   \n",
       "\n",
       "   nearest_police_station  police_stations_3km  nearest_park  parks_3km  \\\n",
       "0                3.134721                    0      0.543893         10   \n",
       "1                1.427325                    2      0.975165         18   \n",
       "2                1.773094                    5      0.108980         43   \n",
       "3                1.305272                    5      0.330802        106   \n",
       "4                0.197445                    3      0.867344         28   \n",
       "\n",
       "   nearest_primary_school  primary_schools_2km  \n",
       "0                0.470666                    9  \n",
       "1                0.947945                    5  \n",
       "2                0.000000                   37  \n",
       "3                0.000000                   12  \n",
       "4                0.000000                   10  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts8 = ts7c.reset_index(drop=True)\n",
    "\n",
    "ts8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c52ddfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts9 = ts8.copy()\n",
    "ts9['ready_to_move'] = ts9['availability'].apply(lambda x: 1 if x == 'Ready To Move' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4edd3cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location                   object\n",
       "size                       object\n",
       "total_sqft                 object\n",
       "bath                      float64\n",
       "lat                       float64\n",
       "long                      float64\n",
       "ward                       object\n",
       "density                   float64\n",
       "parks_per_ward            float64\n",
       "nearest_high_school       float64\n",
       "high_schools_3km            int32\n",
       "nearest_hospital          float64\n",
       "hospitals_5km               int32\n",
       "nearest_university        float64\n",
       "universities_5km            int32\n",
       "nearest_police_station    float64\n",
       "police_stations_3km         int32\n",
       "nearest_park              float64\n",
       "parks_3km                   int32\n",
       "nearest_primary_school    float64\n",
       "primary_schools_2km         int32\n",
       "ready_to_move               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts10 = ts9.copy()\n",
    "ts10.drop(columns=['availability','area_type', 'society', 'balcony'],inplace = True)\n",
    "ts10.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a88a8760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location                  0\n",
       "size                      2\n",
       "total_sqft                0\n",
       "bath                      7\n",
       "lat                       0\n",
       "long                      0\n",
       "ward                      0\n",
       "density                   0\n",
       "parks_per_ward            0\n",
       "nearest_high_school       0\n",
       "high_schools_3km          0\n",
       "nearest_hospital          0\n",
       "hospitals_5km             0\n",
       "nearest_university        0\n",
       "universities_5km          0\n",
       "nearest_police_station    0\n",
       "police_stations_3km       0\n",
       "nearest_park              0\n",
       "parks_3km                 0\n",
       "nearest_primary_school    0\n",
       "primary_schools_2km       0\n",
       "ready_to_move             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts10.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f4fb336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           2 BHK\n",
       "1       9 Bedroom\n",
       "2       4 Bedroom\n",
       "3           3 BHK\n",
       "4           2 BHK\n",
       "          ...    \n",
       "1475        2 BHK\n",
       "1476        3 BHK\n",
       "1477        2 BHK\n",
       "1478        2 BHK\n",
       "1479        2 BHK\n",
       "Name: size, Length: 1480, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts10['size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525b1fb",
   "metadata": {},
   "source": [
    "#### Convert object type columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a80c8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts11 = ts10.copy()\n",
    "# extract the number of bedrooms from the 'size' column\n",
    "ts11['bedrooms'] = ts11['size'].str.split().str[0]\n",
    "\n",
    "# replace empty strings with NaN values\n",
    "ts11['bedrooms'] = ts11['bedrooms'].replace('', pd.NA)\n",
    "\n",
    "# drop rows with NaN values in the 'bedrooms' column\n",
    "ts11['bedrooms'] = ts11['bedrooms'].astype(float)\n",
    "ts11['bedrooms'] = ts11['bedrooms'].fillna(ts11['bedrooms'].notnull().mean())\n",
    "ts11['bedrooms'] = ts11['bedrooms'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "86b9db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts12 = ts11.copy()\n",
    "ts12['bath'] = ts12['bath'].fillna(ts12['bath'].notnull().mean())\n",
    "ts12['bath'] = ts12['bath'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ea7ddab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           2 BHK\n",
       "1       9 Bedroom\n",
       "2       4 Bedroom\n",
       "3           3 BHK\n",
       "4           2 BHK\n",
       "          ...    \n",
       "1475        2 BHK\n",
       "1476        3 BHK\n",
       "1477        2 BHK\n",
       "1478        2 BHK\n",
       "1479        2 BHK\n",
       "Name: size, Length: 1480, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts12['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e1328649",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts13 = ts12.copy()\n",
    "ts13['studio'] = ts13['size'].apply(lambda x: 0 if pd.isna(x) or x.split()[1] == 'BHK' else 1)\n",
    "ts13.drop(columns=['size'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e72a3c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>...</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Sarjapur  Road</td>\n",
       "      <td>1691 - 2170</td>\n",
       "      <td>3</td>\n",
       "      <td>12.910933</td>\n",
       "      <td>77.684154</td>\n",
       "      <td>Bellandur</td>\n",
       "      <td>3041.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994897</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.967393</td>\n",
       "      <td>1</td>\n",
       "      <td>1.514300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Chikkaballapur</td>\n",
       "      <td>1200 - 2000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.435498</td>\n",
       "      <td>77.731534</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>22.522747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.367405</td>\n",
       "      <td>0</td>\n",
       "      <td>25.237682</td>\n",
       "      <td>0</td>\n",
       "      <td>7.074786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Yelahanka</td>\n",
       "      <td>1892 - 2798</td>\n",
       "      <td>3</td>\n",
       "      <td>13.115466</td>\n",
       "      <td>77.606998</td>\n",
       "      <td>Kempegowda Ward</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Whitefield</td>\n",
       "      <td>524 - 894</td>\n",
       "      <td>1</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>77.749972</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629064</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293975</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069651</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>534 - 763</td>\n",
       "      <td>1</td>\n",
       "      <td>13.035324</td>\n",
       "      <td>77.628470</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.499601</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.088208</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.591125</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Whitefield</td>\n",
       "      <td>1498 - 1523</td>\n",
       "      <td>3</td>\n",
       "      <td>12.969820</td>\n",
       "      <td>77.749972</td>\n",
       "      <td>Hagadooru</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714559</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629064</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293975</td>\n",
       "      <td>2</td>\n",
       "      <td>0.069651</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Doddaballapur</td>\n",
       "      <td>5Acres</td>\n",
       "      <td>1</td>\n",
       "      <td>13.295714</td>\n",
       "      <td>77.536391</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>2.525515</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.217723</td>\n",
       "      <td>0</td>\n",
       "      <td>1.176381</td>\n",
       "      <td>1</td>\n",
       "      <td>4.394392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Rachenahalli</td>\n",
       "      <td>660 - 690</td>\n",
       "      <td>1</td>\n",
       "      <td>13.061519</td>\n",
       "      <td>77.616380</td>\n",
       "      <td>Thanisandra</td>\n",
       "      <td>7161.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.006576</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.498794</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Old Madras Road</td>\n",
       "      <td>1165 - 1225</td>\n",
       "      <td>2</td>\n",
       "      <td>13.051515</td>\n",
       "      <td>77.758360</td>\n",
       "      <td>Outside of town</td>\n",
       "      <td>27566.0</td>\n",
       "      <td>4.122466</td>\n",
       "      <td>2.237596</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.685993</td>\n",
       "      <td>0</td>\n",
       "      <td>6.388555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Binny Pete</td>\n",
       "      <td>2695 - 2940</td>\n",
       "      <td>0</td>\n",
       "      <td>12.967566</td>\n",
       "      <td>77.558359</td>\n",
       "      <td>Binnipete</td>\n",
       "      <td>48081.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.269355</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.672573</td>\n",
       "      <td>28</td>\n",
       "      <td>0.760943</td>\n",
       "      <td>48</td>\n",
       "      <td>0.413497</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            location   total_sqft  bath        lat       long  \\\n",
       "42    Sarjapur  Road  1691 - 2170     3  12.910933  77.684154   \n",
       "151   Chikkaballapur  1200 - 2000     0  13.435498  77.731534   \n",
       "174        Yelahanka  1892 - 2798     3  13.115466  77.606998   \n",
       "180       Whitefield    524 - 894     1  12.969820  77.749972   \n",
       "215       HBR Layout    534 - 763     1  13.035324  77.628470   \n",
       "260       Whitefield  1498 - 1523     3  12.969820  77.749972   \n",
       "325    Doddaballapur       5Acres     1  13.295714  77.536391   \n",
       "351     Rachenahalli    660 - 690     1  13.061519  77.616380   \n",
       "382  Old Madras Road  1165 - 1225     2  13.051515  77.758360   \n",
       "387       Binny Pete  2695 - 2940     0  12.967566  77.558359   \n",
       "\n",
       "                ward  density  parks_per_ward  nearest_high_school  \\\n",
       "42         Bellandur   3041.0        1.000000             0.994897   \n",
       "151  Outside of town  27566.0        4.122466            22.522747   \n",
       "174  Kempegowda Ward   3182.0        0.000000             0.000000   \n",
       "180        Hagadooru   4003.0        1.000000             0.714559   \n",
       "215       HBR Layout  12717.0        5.000000             0.499601   \n",
       "260        Hagadooru   4003.0        1.000000             0.714559   \n",
       "325  Outside of town  27566.0        4.122466             2.525515   \n",
       "351      Thanisandra   7161.0        1.000000             0.505800   \n",
       "382  Outside of town  27566.0        4.122466             2.237596   \n",
       "387        Binnipete  48081.0        2.000000             1.269355   \n",
       "\n",
       "     high_schools_3km  ...  universities_5km  nearest_police_station  \\\n",
       "42                 10  ...                 0                1.967393   \n",
       "151                 0  ...                 0               21.367405   \n",
       "174                10  ...                 0                0.000000   \n",
       "180                 6  ...                 0                0.629064   \n",
       "215                 8  ...                 0                1.088208   \n",
       "260                 6  ...                 0                0.629064   \n",
       "325                 1  ...                 0               17.217723   \n",
       "351                 9  ...                 1                2.006576   \n",
       "382                 1  ...                 0                5.685993   \n",
       "387                13  ...                 6                0.672573   \n",
       "\n",
       "     police_stations_3km  nearest_park  parks_3km  nearest_primary_school  \\\n",
       "42                     1      1.514300          2                0.000000   \n",
       "151                    0     25.237682          0                7.074786   \n",
       "174                    1      0.000000         14                0.000000   \n",
       "180                    2      0.293975          2                0.069651   \n",
       "215                    3      0.000000         24                0.591125   \n",
       "260                    2      0.293975          2                0.069651   \n",
       "325                    0      1.176381          1                4.394392   \n",
       "351                    2      0.000000         19                0.498794   \n",
       "382                    0      6.388555          0                0.000000   \n",
       "387                   28      0.760943         48                0.413497   \n",
       "\n",
       "     primary_schools_2km  ready_to_move  bedrooms  studio  \n",
       "42                     8              1         3       0  \n",
       "151                    0              0         0       0  \n",
       "174                   99              0         3       0  \n",
       "180                   15              0         1       0  \n",
       "215                   16              0         1       0  \n",
       "260                   15              0         3       0  \n",
       "325                    0              0         1       1  \n",
       "351                   11              0         1       0  \n",
       "382                    2              0         2       0  \n",
       "387                   47              0         4       0  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts13[~ts13[\"total_sqft\"].apply(is_float)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fe6c7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of maximum value: 325\n",
      "location                    Doddaballapur\n",
      "total_sqft                         217800\n",
      "bath                                    1\n",
      "lat                             13.295714\n",
      "long                            77.536391\n",
      "ward                      Outside of town\n",
      "density                           27566.0\n",
      "parks_per_ward                   4.122466\n",
      "nearest_high_school              2.525515\n",
      "high_schools_3km                        1\n",
      "nearest_hospital                 4.279988\n",
      "hospitals_5km                           1\n",
      "nearest_university              14.125354\n",
      "universities_5km                        0\n",
      "nearest_police_station          17.217723\n",
      "police_stations_3km                     0\n",
      "nearest_park                     1.176381\n",
      "parks_3km                               1\n",
      "nearest_primary_school           4.394392\n",
      "primary_schools_2km                     0\n",
      "ready_to_move                           0\n",
      "bedrooms                                1\n",
      "studio                                  1\n",
      "Name: 325, dtype: object\n",
      "location                    Doddaballapur\n",
      "total_sqft                         5Acres\n",
      "bath                                    1\n",
      "lat                             13.295714\n",
      "long                            77.536391\n",
      "ward                      Outside of town\n",
      "density                           27566.0\n",
      "parks_per_ward                   4.122466\n",
      "nearest_high_school              2.525515\n",
      "high_schools_3km                        1\n",
      "nearest_hospital                 4.279988\n",
      "hospitals_5km                           1\n",
      "nearest_university              14.125354\n",
      "universities_5km                        0\n",
      "nearest_police_station          17.217723\n",
      "police_stations_3km                     0\n",
      "nearest_park                     1.176381\n",
      "parks_3km                               1\n",
      "nearest_primary_school           4.394392\n",
      "primary_schools_2km                     0\n",
      "ready_to_move                           0\n",
      "bedrooms                                1\n",
      "studio                                  1\n",
      "Name: 325, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ts14 = ts13.copy()\n",
    "ts14['total_sqft'] = ts14['total_sqft'].apply(convert_to_sqft)\n",
    "max_id = ts14['total_sqft'].idxmax()\n",
    "\n",
    "print('ID of maximum value:', max_id)\n",
    "print(ts14.loc[max_id])\n",
    "print(ts13.loc[max_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9ba7c032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>...</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [location, total_sqft, bath, lat, long, ward, density, parks_per_ward, nearest_high_school, high_schools_3km, nearest_hospital, hospitals_5km, nearest_university, universities_5km, nearest_police_station, police_stations_3km, nearest_park, parks_3km, nearest_primary_school, primary_schools_2km, ready_to_move, bedrooms, studio]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts14[~ts14[\"total_sqft\"].apply(is_float)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ac0c34bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>...</th>\n",
       "      <th>universities_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>nearest_park</th>\n",
       "      <th>parks_3km</th>\n",
       "      <th>nearest_primary_school</th>\n",
       "      <th>primary_schools_2km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [location, total_sqft, bath, lat, long, ward, density, parks_per_ward, nearest_high_school, high_schools_3km, nearest_hospital, hospitals_5km, nearest_university, universities_5km, nearest_police_station, police_stations_3km, nearest_park, parks_3km, nearest_primary_school, primary_schools_2km, ready_to_move, bedrooms, studio]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts14[ts14[\"total_sqft\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "620beefd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1225\n",
       "1       2400\n",
       "2       1650\n",
       "3       1322\n",
       "4       1161\n",
       "        ... \n",
       "1475    1246\n",
       "1476    1660\n",
       "1477    1216\n",
       "1478     996\n",
       "1479    1150\n",
       "Name: total_sqft, Length: 1480, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts14[\"total_sqft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f055b444",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location                   object\n",
       "total_sqft                  int64\n",
       "bath                        int32\n",
       "lat                       float64\n",
       "long                      float64\n",
       "ward                       object\n",
       "density                   float64\n",
       "parks_per_ward            float64\n",
       "nearest_high_school       float64\n",
       "high_schools_3km            int32\n",
       "nearest_hospital          float64\n",
       "hospitals_5km               int32\n",
       "nearest_university        float64\n",
       "universities_5km            int32\n",
       "nearest_police_station    float64\n",
       "police_stations_3km         int32\n",
       "nearest_park              float64\n",
       "parks_3km                   int32\n",
       "nearest_primary_school    float64\n",
       "primary_schools_2km         int32\n",
       "ready_to_move               int64\n",
       "bedrooms                    int32\n",
       "studio                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts14.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9b0eaa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df21['location'].unique()\n",
    "\n",
    "test_one_hot = pd.get_dummies(ts14['location'])\n",
    "\n",
    "for category in categories:\n",
    "    if category not in test_one_hot.columns:\n",
    "        test_one_hot[category] = 0\n",
    "\n",
    "# align the columns of the test set with the training set\n",
    "test_one_hot = test_one_hot[dummies.columns]\n",
    "test_one_hot = test_one_hot.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "509346db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ward</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vijayanagar</th>\n",
       "      <th>Vittasandra</th>\n",
       "      <th>Whitefield</th>\n",
       "      <th>Yelahanka</th>\n",
       "      <th>Yelahanka New Town</th>\n",
       "      <th>Yeshwanthpur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1225</td>\n",
       "      <td>2</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>Doddanekkundi</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.051436</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2400</td>\n",
       "      <td>9</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>Begur</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.144852</td>\n",
       "      <td>4</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1650</td>\n",
       "      <td>5</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>HBR Layout</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>3</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>Bilekahalli</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.243176</td>\n",
       "      <td>9</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1161</td>\n",
       "      <td>2</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>Anjanapura</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>15</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_sqft  bath        lat       long           ward  density  \\\n",
       "0        1225     2  12.965480  77.718464  Doddanekkundi   5270.0   \n",
       "1        2400     9  12.867799  77.616684          Begur   4216.0   \n",
       "2        1650     5  13.013906  77.626650     HBR Layout  12717.0   \n",
       "3        1322     3  12.895345  77.615037    Bilekahalli  11721.0   \n",
       "4        1161     2  12.882219  77.565968     Anjanapura   3997.0   \n",
       "\n",
       "   parks_per_ward  nearest_high_school  high_schools_3km  nearest_hospital  \\\n",
       "0             7.0             1.051436                 9          0.235652   \n",
       "1             0.0             2.144852                 4          1.271498   \n",
       "2             5.0             1.220832                12          0.954018   \n",
       "3             5.0             1.243176                 9          0.621746   \n",
       "4             5.0             0.289757                15          0.527077   \n",
       "\n",
       "   ...  Uttarahalli  Varthur  Vasanthapura  Vidyaranyapura  Vijayanagar  \\\n",
       "0  ...            0        0             0               0            0   \n",
       "1  ...            0        0             0               0            0   \n",
       "2  ...            0        0             0               0            0   \n",
       "3  ...            0        0             0               0            0   \n",
       "4  ...            0        0             0               0            0   \n",
       "\n",
       "   Vittasandra  Whitefield  Yelahanka  Yelahanka New Town  Yeshwanthpur  \n",
       "0            0           0          0                   0             0  \n",
       "1            0           0          0                   0             0  \n",
       "2            0           0          0                   0             0  \n",
       "3            0           0          0                   0             0  \n",
       "4            0           0          0                   0             0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts15 = ts14.copy()\n",
    "\n",
    "ts15 = pd.concat([ts15,test_one_hot],axis='columns')\n",
    "\n",
    "## removing 'location' as we have already created the dummies\n",
    "ts15 = ts15.drop('location',axis = 1)\n",
    "\n",
    "ts15.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ac976fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories1 = df21['ward'].unique()\n",
    "\n",
    "test_one_hot1 = pd.get_dummies(ts15['ward'])\n",
    "\n",
    "for category in categories1:\n",
    "    if category not in test_one_hot1.columns:\n",
    "        test_one_hot1[category] = 0\n",
    "\n",
    "# align the columns of the test set with the training set\n",
    "test_one_hot1 = test_one_hot1[dummies1.columns]\n",
    "test_one_hot1 = test_one_hot1.astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "83f268a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>density</th>\n",
       "      <th>parks_per_ward</th>\n",
       "      <th>nearest_high_school</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>nearest_hospital</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>...</th>\n",
       "      <th>Singasandra</th>\n",
       "      <th>Thanisandra</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vasanthnagar</th>\n",
       "      <th>Vidyapeetha</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vignananagar</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1225</td>\n",
       "      <td>2</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.051436</td>\n",
       "      <td>9</td>\n",
       "      <td>0.235652</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2400</td>\n",
       "      <td>9</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.144852</td>\n",
       "      <td>4</td>\n",
       "      <td>1.271498</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1650</td>\n",
       "      <td>5</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.220832</td>\n",
       "      <td>12</td>\n",
       "      <td>0.954018</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>3</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.243176</td>\n",
       "      <td>9</td>\n",
       "      <td>0.621746</td>\n",
       "      <td>157</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1161</td>\n",
       "      <td>2</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.289757</td>\n",
       "      <td>15</td>\n",
       "      <td>0.527077</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_sqft  bath        lat       long  density  parks_per_ward  \\\n",
       "0        1225     2  12.965480  77.718464   5270.0             7.0   \n",
       "1        2400     9  12.867799  77.616684   4216.0             0.0   \n",
       "2        1650     5  13.013906  77.626650  12717.0             5.0   \n",
       "3        1322     3  12.895345  77.615037  11721.0             5.0   \n",
       "4        1161     2  12.882219  77.565968   3997.0             5.0   \n",
       "\n",
       "   nearest_high_school  high_schools_3km  nearest_hospital  hospitals_5km  \\\n",
       "0             1.051436                 9          0.235652             53   \n",
       "1             2.144852                 4          1.271498             41   \n",
       "2             1.220832                12          0.954018            118   \n",
       "3             1.243176                 9          0.621746            157   \n",
       "4             0.289757                15          0.527077             83   \n",
       "\n",
       "   ...  Singasandra  Thanisandra  Uttarahalli  Varthur  Vasanthapura  \\\n",
       "0  ...            0            0            0        0             0   \n",
       "1  ...            0            0            0        0             0   \n",
       "2  ...            0            0            0        0             0   \n",
       "3  ...            0            0            0        0             0   \n",
       "4  ...            0            0            0        0             0   \n",
       "\n",
       "   Vasanthnagar  Vidyapeetha  Vidyaranyapura  Vignananagar  Yelachenahalli  \n",
       "0             0            0               0             0               0  \n",
       "1             0            0               0             0               0  \n",
       "2             0            0               0             0               0  \n",
       "3             0            0               0             0               0  \n",
       "4             0            0               0             0               0  \n",
       "\n",
       "[5 rows x 278 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts16 = ts15.copy()\n",
    "\n",
    "ts16 = pd.concat([ts16,test_one_hot1],axis='columns')\n",
    "\n",
    "## removing 'location' as we have already created the dummies\n",
    "ts16 = ts16.drop('ward',axis = 1)\n",
    "\n",
    "ts16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0f30f2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_sqft                       int64\n",
       "bath                             int32\n",
       "lat                            float64\n",
       "long                           float64\n",
       "density                          int64\n",
       "parks_per_ward                 float64\n",
       "nearest_high_school            float64\n",
       "high_schools_3km                 int32\n",
       "nearest_hospital               float64\n",
       "hospitals_5km                    int32\n",
       "nearest_university             float64\n",
       "universities_5km                 int32\n",
       "nearest_police_station         float64\n",
       "police_stations_3km              int32\n",
       "nearest_park                   float64\n",
       "parks_3km                        int32\n",
       "nearest_primary_school         float64\n",
       "primary_schools_2km              int32\n",
       "ready_to_move                    int64\n",
       "bedrooms                         int32\n",
       "studio                           int64\n",
       "1st Phase JP Nagar               uint8\n",
       "2nd Stage Nagarbhavi             uint8\n",
       "5th Phase JP Nagar               uint8\n",
       "6th Phase JP Nagar               uint8\n",
       "7th Phase JP Nagar               uint8\n",
       "8th Phase JP Nagar               uint8\n",
       "9th Phase JP Nagar               uint8\n",
       "Abbigere                         uint8\n",
       "Akshaya Nagar                    uint8\n",
       "Ambalipura                       uint8\n",
       "Ambedkar Nagar                   uint8\n",
       "Amruthahalli                     uint8\n",
       "Anandapura                       uint8\n",
       "Ananth Nagar                     uint8\n",
       "Anekal                           uint8\n",
       "Ardendale                        uint8\n",
       "Attibele                         uint8\n",
       "BEML Layout                      uint8\n",
       "BTM 2nd Stage                    uint8\n",
       "BTM Layout                       uint8\n",
       "Babusapalaya                     uint8\n",
       "Balagere                         uint8\n",
       "Banashankari                     uint8\n",
       "Banashankari Stage II            uint8\n",
       "Banashankari Stage III           uint8\n",
       "Banashankari Stage V             uint8\n",
       "Banaswadi                        uint8\n",
       "Bannerghatta                     uint8\n",
       "Bannerghatta Road                uint8\n",
       "Basavangudi                      uint8\n",
       "Battarahalli                     uint8\n",
       "Begur                            uint8\n",
       "Begur Road                       uint8\n",
       "Bellandur                        uint8\n",
       "Benson Town                      uint8\n",
       "Bhoganhalli                      uint8\n",
       "Billekahalli                     uint8\n",
       "Binny Pete                       uint8\n",
       "Bisuvanahalli                    uint8\n",
       "Bommanahalli                     uint8\n",
       "Bommasandra                      uint8\n",
       "Bommasandra Industrial Area      uint8\n",
       "Brookefield                      uint8\n",
       "Budigere                         uint8\n",
       "CV Raman Nagar                   uint8\n",
       "Chandapura                       uint8\n",
       "Channasandra                     uint8\n",
       "Chikka Tirupathi                 uint8\n",
       "Chikkalasandra                   uint8\n",
       "Choodasandra                     uint8\n",
       "Cunningham Road                  uint8\n",
       "Devanahalli                      uint8\n",
       "Devarachikkanahalli              uint8\n",
       "Dodda Nekkundi                   uint8\n",
       "Doddathoguru                     uint8\n",
       "Domlur                           uint8\n",
       "Dommasandra                      uint8\n",
       "EPIP Zone                        uint8\n",
       "Electronic City                  uint8\n",
       "Electronic City Phase II         uint8\n",
       "Electronics City Phase 1         uint8\n",
       "Frazer Town                      uint8\n",
       "Garudachar Palya                 uint8\n",
       "Gottigere                        uint8\n",
       "Green Glen Layout                uint8\n",
       "Gubbalala                        uint8\n",
       "Gunjur                           uint8\n",
       "HBR Layout                       uint8\n",
       "HRBR Layout                      uint8\n",
       "HSR Layout                       uint8\n",
       "Haralur Road                     uint8\n",
       "Harlur                           uint8\n",
       "Hebbal                           uint8\n",
       "Hebbal Kempapura                 uint8\n",
       "Hegde Nagar                      uint8\n",
       "Hennur                           uint8\n",
       "Hennur Road                      uint8\n",
       "Hoodi                            uint8\n",
       "Horamavu Agara                   uint8\n",
       "Horamavu Banaswadi               uint8\n",
       "Hormavu                          uint8\n",
       "Hosa Road                        uint8\n",
       "Hosakerehalli                    uint8\n",
       "Hoskote                          uint8\n",
       "Hosur Road                       uint8\n",
       "Hulimavu                         uint8\n",
       "Iblur Village                    uint8\n",
       "Indira Nagar                     uint8\n",
       "JP Nagar                         uint8\n",
       "Jakkur                           uint8\n",
       "Jalahalli                        uint8\n",
       "Jalahalli East                   uint8\n",
       "Jigani                           uint8\n",
       "KR Puram                         uint8\n",
       "Kadugodi                         uint8\n",
       "Kaggadasapura                    uint8\n",
       "Kaggalipura                      uint8\n",
       "Kaikondrahalli                   uint8\n",
       "Kalena Agrahara                  uint8\n",
       "Kalyan nagar                     uint8\n",
       "Kambipura                        uint8\n",
       "Kammasandra                      uint8\n",
       "Kanakapura                       uint8\n",
       "Kanakpura Road                   uint8\n",
       "Kannamangala                     uint8\n",
       "Kasavanhalli                     uint8\n",
       "Kasturi Nagar                    uint8\n",
       "Kathriguppe                      uint8\n",
       "Kaval Byrasandra                 uint8\n",
       "Kenchenahalli                    uint8\n",
       "Kengeri                          uint8\n",
       "Kengeri Satellite Town           uint8\n",
       "Kereguddadahalli                 uint8\n",
       "Kodichikkanahalli                uint8\n",
       "Kogilu                           uint8\n",
       "Koramangala                      uint8\n",
       "Kothannur                        uint8\n",
       "Kothanur                         uint8\n",
       "Kudlu                            uint8\n",
       "Kudlu Gate                       uint8\n",
       "Kumaraswami Layout               uint8\n",
       "Kundalahalli                     uint8\n",
       "Lakshminarayana Pura             uint8\n",
       "Lingadheeranahalli               uint8\n",
       "Magadi Road                      uint8\n",
       "Mahadevpura                      uint8\n",
       "Mallasandra                      uint8\n",
       "Malleshpalya                     uint8\n",
       "Malleshwaram                     uint8\n",
       "Marathahalli                     uint8\n",
       "Margondanahalli                  uint8\n",
       "Munnekollal                      uint8\n",
       "Mysore Road                      uint8\n",
       "Nagarbhavi                       uint8\n",
       "Nagavara                         uint8\n",
       "OMBR Layout                      uint8\n",
       "Old Airport Road                 uint8\n",
       "Old Madras Road                  uint8\n",
       "Padmanabhanagar                  uint8\n",
       "Pai Layout                       uint8\n",
       "Panathur                         uint8\n",
       "Parappana Agrahara               uint8\n",
       "Poorna Pragna Layout             uint8\n",
       "R.T. Nagar                       uint8\n",
       "Rachenahalli                     uint8\n",
       "Raja Rajeshwari Nagar            uint8\n",
       "Rajaji Nagar                     uint8\n",
       "Ramagondanahalli                 uint8\n",
       "Ramamurthy Nagar                 uint8\n",
       "Rayasandra                       uint8\n",
       "Sahakara Nagar                   uint8\n",
       "Sanjay nagar                     uint8\n",
       "Sarjapur                         uint8\n",
       "Sarjapur  Road                   uint8\n",
       "Sarjapura - Attibele Road        uint8\n",
       "Sector 7 HSR Layout              uint8\n",
       "Seegehalli                       uint8\n",
       "Singasandra                      uint8\n",
       "Somasundara Palya                uint8\n",
       "Sonnenahalli                     uint8\n",
       "Subramanyapura                   uint8\n",
       "TC Palaya                        uint8\n",
       "Talaghattapura                   uint8\n",
       "Thanisandra                      uint8\n",
       "Thigalarapalya                   uint8\n",
       "Thubarahalli                     uint8\n",
       "Tumkur Road                      uint8\n",
       "Ulsoor                           uint8\n",
       "Uttarahalli                      uint8\n",
       "Varthur                          uint8\n",
       "Vasanthapura                     uint8\n",
       "Vidyaranyapura                   uint8\n",
       "Vijayanagar                      uint8\n",
       "Vittasandra                      uint8\n",
       "Whitefield                       uint8\n",
       "Yelahanka                        uint8\n",
       "Yelahanka New Town               uint8\n",
       "Yeshwanthpur                     uint8\n",
       "A. Narayanapura                  uint8\n",
       "Anjanapura                       uint8\n",
       "Arakere                          uint8\n",
       "Aramanenagar                     uint8\n",
       "Attur                            uint8\n",
       "BTM Layout                       uint8\n",
       "Banaswadi                        uint8\n",
       "Basavanagudi                     uint8\n",
       "Basavanapura                     uint8\n",
       "Begur                            uint8\n",
       "Bellandur                        uint8\n",
       "Benniganahalli                   uint8\n",
       "Bilekahalli                      uint8\n",
       "Binnipete                        uint8\n",
       "Bommanahalli                     uint8\n",
       "Byatarayanapura                  uint8\n",
       "C. V. Raman Nagar                uint8\n",
       "Chikkalasandra                   uint8\n",
       "Chowdeshwari Ward                uint8\n",
       "Dodda Bidarkallu                 uint8\n",
       "Doddanekkundi                    uint8\n",
       "Domlur                           uint8\n",
       "Ganesh Mandira                   uint8\n",
       "Ganganagar                       uint8\n",
       "Garudacharpalya                  uint8\n",
       "Girinagar                        uint8\n",
       "Gottigere                        uint8\n",
       "Govindarajanagar                 uint8\n",
       "H. M. T.                         uint8\n",
       "HAL Airport                      uint8\n",
       "HBR Layout                       uint8\n",
       "HSR Layout                       uint8\n",
       "Hagadooru                        uint8\n",
       "Hebbala                          uint8\n",
       "Hemmigepura                      uint8\n",
       "Hongasandra                      uint8\n",
       "Hoodi                            uint8\n",
       "Horamavu                         uint8\n",
       "Hosathippasandra                 uint8\n",
       "Hoysalanagar                     uint8\n",
       "Jakkur                           uint8\n",
       "Jalahalli                        uint8\n",
       "Jayanagar                        uint8\n",
       "Jayanagar East                   uint8\n",
       "Kadugudi                         uint8\n",
       "Kathriguppe                      uint8\n",
       "Kavalbyrasandra                  uint8\n",
       "Kempegowda Ward                  uint8\n",
       "Kengeri                          uint8\n",
       "Koramangala                      uint8\n",
       "Kottigepalya                     uint8\n",
       "Krishnarajapuram                 uint8\n",
       "Kuvempunagar                     uint8\n",
       "Madiwala                         uint8\n",
       "Mangammanapalya                  uint8\n",
       "Marathahalli                     uint8\n",
       "Nagavara                         uint8\n",
       "Outside of town                  uint8\n",
       "Padmanabhanagar                  uint8\n",
       "Pulakeshinagar                   uint8\n",
       "Puttenahalli                     uint8\n",
       "Rajajinagar                      uint8\n",
       "Rajarajeshwarinagar              uint8\n",
       "Ramamurthynagar                  uint8\n",
       "Ramaswamypalya                   uint8\n",
       "Sanjaynagar                      uint8\n",
       "Sarakki                          uint8\n",
       "Shakambarinagar                  uint8\n",
       "Shettyhalli                      uint8\n",
       "Singasandra                      uint8\n",
       "Thanisandra                      uint8\n",
       "Uttarahalli                      uint8\n",
       "Varthur                          uint8\n",
       "Vasanthapura                     uint8\n",
       "Vasanthnagar                     uint8\n",
       "Vidyapeetha                      uint8\n",
       "Vidyaranyapura                   uint8\n",
       "Vignananagar                     uint8\n",
       "Yelachenahalli                   uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2db58fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_sqft                       int64\n",
       "bath                             int32\n",
       "lat                            float64\n",
       "long                           float64\n",
       "density                        float64\n",
       "parks_per_ward                 float64\n",
       "nearest_high_school            float64\n",
       "high_schools_3km                 int32\n",
       "nearest_hospital               float64\n",
       "hospitals_5km                    int32\n",
       "nearest_university             float64\n",
       "universities_5km                 int32\n",
       "nearest_police_station         float64\n",
       "police_stations_3km              int32\n",
       "nearest_park                   float64\n",
       "parks_3km                        int32\n",
       "nearest_primary_school         float64\n",
       "primary_schools_2km              int32\n",
       "ready_to_move                    int64\n",
       "bedrooms                         int32\n",
       "studio                           int64\n",
       "1st Phase JP Nagar               uint8\n",
       "2nd Stage Nagarbhavi             uint8\n",
       "5th Phase JP Nagar               uint8\n",
       "6th Phase JP Nagar               uint8\n",
       "7th Phase JP Nagar               uint8\n",
       "8th Phase JP Nagar               uint8\n",
       "9th Phase JP Nagar               uint8\n",
       "Abbigere                         uint8\n",
       "Akshaya Nagar                    uint8\n",
       "Ambalipura                       uint8\n",
       "Ambedkar Nagar                   uint8\n",
       "Amruthahalli                     uint8\n",
       "Anandapura                       uint8\n",
       "Ananth Nagar                     uint8\n",
       "Anekal                           uint8\n",
       "Ardendale                        uint8\n",
       "Attibele                         uint8\n",
       "BEML Layout                      uint8\n",
       "BTM 2nd Stage                    uint8\n",
       "BTM Layout                       uint8\n",
       "Babusapalaya                     uint8\n",
       "Balagere                         uint8\n",
       "Banashankari                     uint8\n",
       "Banashankari Stage II            uint8\n",
       "Banashankari Stage III           uint8\n",
       "Banashankari Stage V             uint8\n",
       "Banaswadi                        uint8\n",
       "Bannerghatta                     uint8\n",
       "Bannerghatta Road                uint8\n",
       "Basavangudi                      uint8\n",
       "Battarahalli                     uint8\n",
       "Begur                            uint8\n",
       "Begur Road                       uint8\n",
       "Bellandur                        uint8\n",
       "Benson Town                      uint8\n",
       "Bhoganhalli                      uint8\n",
       "Billekahalli                     uint8\n",
       "Binny Pete                       uint8\n",
       "Bisuvanahalli                    uint8\n",
       "Bommanahalli                     uint8\n",
       "Bommasandra                      uint8\n",
       "Bommasandra Industrial Area      uint8\n",
       "Brookefield                      uint8\n",
       "Budigere                         uint8\n",
       "CV Raman Nagar                   uint8\n",
       "Chandapura                       uint8\n",
       "Channasandra                     uint8\n",
       "Chikka Tirupathi                 uint8\n",
       "Chikkalasandra                   uint8\n",
       "Choodasandra                     uint8\n",
       "Cunningham Road                  uint8\n",
       "Devanahalli                      uint8\n",
       "Devarachikkanahalli              uint8\n",
       "Dodda Nekkundi                   uint8\n",
       "Doddathoguru                     uint8\n",
       "Domlur                           uint8\n",
       "Dommasandra                      uint8\n",
       "EPIP Zone                        uint8\n",
       "Electronic City                  uint8\n",
       "Electronic City Phase II         uint8\n",
       "Electronics City Phase 1         uint8\n",
       "Frazer Town                      uint8\n",
       "Garudachar Palya                 uint8\n",
       "Gottigere                        uint8\n",
       "Green Glen Layout                uint8\n",
       "Gubbalala                        uint8\n",
       "Gunjur                           uint8\n",
       "HBR Layout                       uint8\n",
       "HRBR Layout                      uint8\n",
       "HSR Layout                       uint8\n",
       "Haralur Road                     uint8\n",
       "Harlur                           uint8\n",
       "Hebbal                           uint8\n",
       "Hebbal Kempapura                 uint8\n",
       "Hegde Nagar                      uint8\n",
       "Hennur                           uint8\n",
       "Hennur Road                      uint8\n",
       "Hoodi                            uint8\n",
       "Horamavu Agara                   uint8\n",
       "Horamavu Banaswadi               uint8\n",
       "Hormavu                          uint8\n",
       "Hosa Road                        uint8\n",
       "Hosakerehalli                    uint8\n",
       "Hoskote                          uint8\n",
       "Hosur Road                       uint8\n",
       "Hulimavu                         uint8\n",
       "Iblur Village                    uint8\n",
       "Indira Nagar                     uint8\n",
       "JP Nagar                         uint8\n",
       "Jakkur                           uint8\n",
       "Jalahalli                        uint8\n",
       "Jalahalli East                   uint8\n",
       "Jigani                           uint8\n",
       "KR Puram                         uint8\n",
       "Kadugodi                         uint8\n",
       "Kaggadasapura                    uint8\n",
       "Kaggalipura                      uint8\n",
       "Kaikondrahalli                   uint8\n",
       "Kalena Agrahara                  uint8\n",
       "Kalyan nagar                     uint8\n",
       "Kambipura                        uint8\n",
       "Kammasandra                      uint8\n",
       "Kanakapura                       uint8\n",
       "Kanakpura Road                   uint8\n",
       "Kannamangala                     uint8\n",
       "Kasavanhalli                     uint8\n",
       "Kasturi Nagar                    uint8\n",
       "Kathriguppe                      uint8\n",
       "Kaval Byrasandra                 uint8\n",
       "Kenchenahalli                    uint8\n",
       "Kengeri                          uint8\n",
       "Kengeri Satellite Town           uint8\n",
       "Kereguddadahalli                 uint8\n",
       "Kodichikkanahalli                uint8\n",
       "Kogilu                           uint8\n",
       "Koramangala                      uint8\n",
       "Kothannur                        uint8\n",
       "Kothanur                         uint8\n",
       "Kudlu                            uint8\n",
       "Kudlu Gate                       uint8\n",
       "Kumaraswami Layout               uint8\n",
       "Kundalahalli                     uint8\n",
       "Lakshminarayana Pura             uint8\n",
       "Lingadheeranahalli               uint8\n",
       "Magadi Road                      uint8\n",
       "Mahadevpura                      uint8\n",
       "Mallasandra                      uint8\n",
       "Malleshpalya                     uint8\n",
       "Malleshwaram                     uint8\n",
       "Marathahalli                     uint8\n",
       "Margondanahalli                  uint8\n",
       "Munnekollal                      uint8\n",
       "Mysore Road                      uint8\n",
       "Nagarbhavi                       uint8\n",
       "Nagavara                         uint8\n",
       "OMBR Layout                      uint8\n",
       "Old Airport Road                 uint8\n",
       "Old Madras Road                  uint8\n",
       "Padmanabhanagar                  uint8\n",
       "Pai Layout                       uint8\n",
       "Panathur                         uint8\n",
       "Parappana Agrahara               uint8\n",
       "Poorna Pragna Layout             uint8\n",
       "R.T. Nagar                       uint8\n",
       "Rachenahalli                     uint8\n",
       "Raja Rajeshwari Nagar            uint8\n",
       "Rajaji Nagar                     uint8\n",
       "Ramagondanahalli                 uint8\n",
       "Ramamurthy Nagar                 uint8\n",
       "Rayasandra                       uint8\n",
       "Sahakara Nagar                   uint8\n",
       "Sanjay nagar                     uint8\n",
       "Sarjapur                         uint8\n",
       "Sarjapur  Road                   uint8\n",
       "Sarjapura - Attibele Road        uint8\n",
       "Sector 7 HSR Layout              uint8\n",
       "Seegehalli                       uint8\n",
       "Singasandra                      uint8\n",
       "Somasundara Palya                uint8\n",
       "Sonnenahalli                     uint8\n",
       "Subramanyapura                   uint8\n",
       "TC Palaya                        uint8\n",
       "Talaghattapura                   uint8\n",
       "Thanisandra                      uint8\n",
       "Thigalarapalya                   uint8\n",
       "Thubarahalli                     uint8\n",
       "Tumkur Road                      uint8\n",
       "Ulsoor                           uint8\n",
       "Uttarahalli                      uint8\n",
       "Varthur                          uint8\n",
       "Vasanthapura                     uint8\n",
       "Vidyaranyapura                   uint8\n",
       "Vijayanagar                      uint8\n",
       "Vittasandra                      uint8\n",
       "Whitefield                       uint8\n",
       "Yelahanka                        uint8\n",
       "Yelahanka New Town               uint8\n",
       "Yeshwanthpur                     uint8\n",
       "A. Narayanapura                  uint8\n",
       "Anjanapura                       uint8\n",
       "Arakere                          uint8\n",
       "Aramanenagar                     uint8\n",
       "Attur                            uint8\n",
       "BTM Layout                       uint8\n",
       "Banaswadi                        uint8\n",
       "Basavanagudi                     uint8\n",
       "Basavanapura                     uint8\n",
       "Begur                            uint8\n",
       "Bellandur                        uint8\n",
       "Benniganahalli                   uint8\n",
       "Bilekahalli                      uint8\n",
       "Binnipete                        uint8\n",
       "Bommanahalli                     uint8\n",
       "Byatarayanapura                  uint8\n",
       "C. V. Raman Nagar                uint8\n",
       "Chikkalasandra                   uint8\n",
       "Chowdeshwari Ward                uint8\n",
       "Dodda Bidarkallu                 uint8\n",
       "Doddanekkundi                    uint8\n",
       "Domlur                           uint8\n",
       "Ganesh Mandira                   uint8\n",
       "Ganganagar                       uint8\n",
       "Garudacharpalya                  uint8\n",
       "Girinagar                        uint8\n",
       "Gottigere                        uint8\n",
       "Govindarajanagar                 uint8\n",
       "H. M. T.                         uint8\n",
       "HAL Airport                      uint8\n",
       "HBR Layout                       uint8\n",
       "HSR Layout                       uint8\n",
       "Hagadooru                        uint8\n",
       "Hebbala                          uint8\n",
       "Hemmigepura                      uint8\n",
       "Hongasandra                      uint8\n",
       "Hoodi                            uint8\n",
       "Horamavu                         uint8\n",
       "Hosathippasandra                 uint8\n",
       "Hoysalanagar                     uint8\n",
       "Jakkur                           uint8\n",
       "Jalahalli                        uint8\n",
       "Jayanagar                        uint8\n",
       "Jayanagar East                   uint8\n",
       "Kadugudi                         uint8\n",
       "Kathriguppe                      uint8\n",
       "Kavalbyrasandra                  uint8\n",
       "Kempegowda Ward                  uint8\n",
       "Kengeri                          uint8\n",
       "Koramangala                      uint8\n",
       "Kottigepalya                     uint8\n",
       "Krishnarajapuram                 uint8\n",
       "Kuvempunagar                     uint8\n",
       "Madiwala                         uint8\n",
       "Mangammanapalya                  uint8\n",
       "Marathahalli                     uint8\n",
       "Nagavara                         uint8\n",
       "Outside of town                  uint8\n",
       "Padmanabhanagar                  uint8\n",
       "Pulakeshinagar                   uint8\n",
       "Puttenahalli                     uint8\n",
       "Rajajinagar                      uint8\n",
       "Rajarajeshwarinagar              uint8\n",
       "Ramamurthynagar                  uint8\n",
       "Ramaswamypalya                   uint8\n",
       "Sanjaynagar                      uint8\n",
       "Sarakki                          uint8\n",
       "Shakambarinagar                  uint8\n",
       "Shettyhalli                      uint8\n",
       "Singasandra                      uint8\n",
       "Thanisandra                      uint8\n",
       "Uttarahalli                      uint8\n",
       "Varthur                          uint8\n",
       "Vasanthapura                     uint8\n",
       "Vasanthnagar                     uint8\n",
       "Vidyapeetha                      uint8\n",
       "Vidyaranyapura                   uint8\n",
       "Vignananagar                     uint8\n",
       "Yelachenahalli                   uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts16.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487baa7b",
   "metadata": {},
   "source": [
    "#### Checking to see if our training dataset and test dataset after pro-processing have the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8f9ae222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two dataframes have the same columns.\n"
     ]
    }
   ],
   "source": [
    "if X.columns.equals(ts16.columns):\n",
    "    print(\"The two dataframes have the same columns.\")\n",
    "else:\n",
    "    print(\"The two dataframes do not have the same columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d0dd19cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>high_schools_3km</th>\n",
       "      <th>hospitals_5km</th>\n",
       "      <th>nearest_police_station</th>\n",
       "      <th>police_stations_3km</th>\n",
       "      <th>ready_to_move</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>Sarakki</th>\n",
       "      <th>Shakambarinagar</th>\n",
       "      <th>Thanisandra</th>\n",
       "      <th>Uttarahalli</th>\n",
       "      <th>Varthur</th>\n",
       "      <th>Vasanthapura</th>\n",
       "      <th>Vidyapeetha</th>\n",
       "      <th>Vidyaranyapura</th>\n",
       "      <th>Vignananagar</th>\n",
       "      <th>Yelachenahalli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1225</td>\n",
       "      <td>2</td>\n",
       "      <td>12.965480</td>\n",
       "      <td>77.718464</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>3.134721</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2400</td>\n",
       "      <td>9</td>\n",
       "      <td>12.867799</td>\n",
       "      <td>77.616684</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>1.427325</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1650</td>\n",
       "      <td>5</td>\n",
       "      <td>13.013906</td>\n",
       "      <td>77.626650</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>3</td>\n",
       "      <td>12.895345</td>\n",
       "      <td>77.615037</td>\n",
       "      <td>9</td>\n",
       "      <td>157</td>\n",
       "      <td>1.305272</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1161</td>\n",
       "      <td>2</td>\n",
       "      <td>12.882219</td>\n",
       "      <td>77.565968</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>0.197445</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1246</td>\n",
       "      <td>2</td>\n",
       "      <td>12.855352</td>\n",
       "      <td>77.636520</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2.866206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>1660</td>\n",
       "      <td>3</td>\n",
       "      <td>12.856443</td>\n",
       "      <td>77.588845</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2.564197</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>1216</td>\n",
       "      <td>2</td>\n",
       "      <td>12.979699</td>\n",
       "      <td>77.761624</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>1.228699</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>996</td>\n",
       "      <td>2</td>\n",
       "      <td>13.058265</td>\n",
       "      <td>77.468550</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.789765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>1150</td>\n",
       "      <td>2</td>\n",
       "      <td>12.897862</td>\n",
       "      <td>77.584508</td>\n",
       "      <td>21</td>\n",
       "      <td>168</td>\n",
       "      <td>0.578089</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_sqft  bath        lat       long  high_schools_3km  hospitals_5km  \\\n",
       "0           1225     2  12.965480  77.718464                 9             53   \n",
       "1           2400     9  12.867799  77.616684                 4             41   \n",
       "2           1650     5  13.013906  77.626650                12            118   \n",
       "3           1322     3  12.895345  77.615037                 9            157   \n",
       "4           1161     2  12.882219  77.565968                15             83   \n",
       "...          ...   ...        ...        ...               ...            ...   \n",
       "1475        1246     2  12.855352  77.636520                 2             26   \n",
       "1476        1660     3  12.856443  77.588845                 4             26   \n",
       "1477        1216     2  12.979699  77.761624                 6             24   \n",
       "1478         996     2  13.058265  77.468550                 1              3   \n",
       "1479        1150     2  12.897862  77.584508                21            168   \n",
       "\n",
       "      nearest_police_station  police_stations_3km  ready_to_move  bedrooms  \\\n",
       "0                   3.134721                    0              1         2   \n",
       "1                   1.427325                    2              1         9   \n",
       "2                   1.773094                    5              0         4   \n",
       "3                   1.305272                    5              1         3   \n",
       "4                   0.197445                    3              1         2   \n",
       "...                      ...                  ...            ...       ...   \n",
       "1475                2.866206                    1              1         2   \n",
       "1476                2.564197                    1              1         3   \n",
       "1477                1.228699                    2              1         2   \n",
       "1478                3.789765                    0              0         2   \n",
       "1479                0.578089                    5              1         2   \n",
       "\n",
       "      ...  Sarakki  Shakambarinagar  Thanisandra  Uttarahalli  Varthur  \\\n",
       "0     ...        0                0            0            0        0   \n",
       "1     ...        0                0            0            0        0   \n",
       "2     ...        0                0            0            0        0   \n",
       "3     ...        0                0            0            0        0   \n",
       "4     ...        0                0            0            0        0   \n",
       "...   ...      ...              ...          ...          ...      ...   \n",
       "1475  ...        0                0            0            0        0   \n",
       "1476  ...        0                0            0            0        0   \n",
       "1477  ...        0                0            0            0        0   \n",
       "1478  ...        0                0            0            0        0   \n",
       "1479  ...        0                0            0            0        0   \n",
       "\n",
       "      Vasanthapura  Vidyapeetha  Vidyaranyapura  Vignananagar  Yelachenahalli  \n",
       "0                0            0               0             0               0  \n",
       "1                0            0               0             0               0  \n",
       "2                0            0               0             0               0  \n",
       "3                0            0               0             0               0  \n",
       "4                0            0               0             0               0  \n",
       "...            ...          ...             ...           ...             ...  \n",
       "1475             0            0               0             0               0  \n",
       "1476             0            0               0             0               0  \n",
       "1477             0            0               0             0               0  \n",
       "1478             0            0               0             0               0  \n",
       "1479             0            0               0             0               0  \n",
       "\n",
       "[1480 rows x 192 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sfs = ts16.iloc[:, [0, 1, 2, 3, 7, 9, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 63, 64, 65, 68, 70, 72, 73, 74, 75, 78, 79, 81, 83, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 100, 102, 103, 105, 106, 107, 109, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 131, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 159, 160, 161, 163, 164, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 190, 193, 194, 195, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 226, 227, 228, 229, 232, 233, 234, 235, 236, 239, 240, 241, 242, 243, 244, 246, 248, 249, 250, 251, 253, 255, 256, 257, 260, 262, 264, 265, 266, 269, 270, 271, 272, 274, 275, 276, 277]]\n",
    "X_test_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d0e280cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two dataframes have the same columns.\n"
     ]
    }
   ],
   "source": [
    "if X_sfs.columns.equals(X_test_sfs.columns):\n",
    "    print(\"The two dataframes have the same columns.\")\n",
    "else:\n",
    "    print(\"The two dataframes do not have the same columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "61eb0fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_sqft                   0\n",
       "bath                         0\n",
       "lat                          0\n",
       "long                         0\n",
       "high_schools_3km             0\n",
       "hospitals_5km                0\n",
       "nearest_police_station       0\n",
       "police_stations_3km          0\n",
       "ready_to_move                0\n",
       "bedrooms                     0\n",
       "studio                       0\n",
       "1st Phase JP Nagar           0\n",
       "2nd Stage Nagarbhavi         0\n",
       "5th Phase JP Nagar           0\n",
       "6th Phase JP Nagar           0\n",
       "7th Phase JP Nagar           0\n",
       "8th Phase JP Nagar           0\n",
       "9th Phase JP Nagar           0\n",
       "Abbigere                     0\n",
       "Ambalipura                   0\n",
       "Ambedkar Nagar               0\n",
       "Amruthahalli                 0\n",
       "Anandapura                   0\n",
       "Ananth Nagar                 0\n",
       "Anekal                       0\n",
       "BEML Layout                  0\n",
       "BTM 2nd Stage                0\n",
       "BTM Layout                   0\n",
       "Babusapalaya                 0\n",
       "Balagere                     0\n",
       "Banashankari                 0\n",
       "Banashankari Stage V         0\n",
       "Bannerghatta                 0\n",
       "Bannerghatta Road            0\n",
       "Basavangudi                  0\n",
       "Battarahalli                 0\n",
       "Begur                        0\n",
       "Begur Road                   0\n",
       "Bellandur                    0\n",
       "Benson Town                  0\n",
       "Billekahalli                 0\n",
       "Binny Pete                   0\n",
       "Bommasandra                  0\n",
       "Brookefield                  0\n",
       "Budigere                     0\n",
       "CV Raman Nagar               0\n",
       "Chikka Tirupathi             0\n",
       "Choodasandra                 0\n",
       "Devanahalli                  0\n",
       "Devarachikkanahalli          0\n",
       "Dodda Nekkundi               0\n",
       "Doddathoguru                 0\n",
       "EPIP Zone                    0\n",
       "Electronic City              0\n",
       "Electronics City Phase 1     0\n",
       "Garudachar Palya             0\n",
       "Gubbalala                    0\n",
       "Gunjur                       0\n",
       "HRBR Layout                  0\n",
       "HSR Layout                   0\n",
       "Haralur Road                 0\n",
       "Harlur                       0\n",
       "Hebbal Kempapura             0\n",
       "Hegde Nagar                  0\n",
       "Hennur                       0\n",
       "Hennur Road                  0\n",
       "Hoodi                        0\n",
       "Horamavu Banaswadi           0\n",
       "Hosa Road                    0\n",
       "Hosakerehalli                0\n",
       "Hosur Road                   0\n",
       "Hulimavu                     0\n",
       "Iblur Village                0\n",
       "JP Nagar                     0\n",
       "Jalahalli                    0\n",
       "Jalahalli East               0\n",
       "Jigani                       0\n",
       "Kaggalipura                  0\n",
       "Kaikondrahalli               0\n",
       "Kalena Agrahara              0\n",
       "Kalyan nagar                 0\n",
       "Kambipura                    0\n",
       "Kammasandra                  0\n",
       "Kanakapura                   0\n",
       "Kasavanhalli                 0\n",
       "Kasturi Nagar                0\n",
       "Kathriguppe                  0\n",
       "Kaval Byrasandra             0\n",
       "Kengeri                      0\n",
       "Koramangala                  0\n",
       "Kothannur                    0\n",
       "Kudlu                        0\n",
       "Kudlu Gate                   0\n",
       "Kundalahalli                 0\n",
       "Lakshminarayana Pura         0\n",
       "Lingadheeranahalli           0\n",
       "Magadi Road                  0\n",
       "Mahadevpura                  0\n",
       "Mallasandra                  0\n",
       "Malleshpalya                 0\n",
       "Malleshwaram                 0\n",
       "Marathahalli                 0\n",
       "Mysore Road                  0\n",
       "Padmanabhanagar              0\n",
       "Pai Layout                   0\n",
       "Panathur                     0\n",
       "Poorna Pragna Layout         0\n",
       "R.T. Nagar                   0\n",
       "Raja Rajeshwari Nagar        0\n",
       "Rajaji Nagar                 0\n",
       "Ramagondanahalli             0\n",
       "Ramamurthy Nagar             0\n",
       "Rayasandra                   0\n",
       "Sanjay nagar                 0\n",
       "Sarjapur                     0\n",
       "Sarjapur  Road               0\n",
       "Sarjapura - Attibele Road    0\n",
       "Sector 7 HSR Layout          0\n",
       "Seegehalli                   0\n",
       "Singasandra                  0\n",
       "Somasundara Palya            0\n",
       "Sonnenahalli                 0\n",
       "Subramanyapura               0\n",
       "TC Palaya                    0\n",
       "Talaghattapura               0\n",
       "Thanisandra                  0\n",
       "Thigalarapalya               0\n",
       "Tumkur Road                  0\n",
       "Ulsoor                       0\n",
       "Varthur                      0\n",
       "Vijayanagar                  0\n",
       "Vittasandra                  0\n",
       "Whitefield                   0\n",
       "A. Narayanapura              0\n",
       "Anjanapura                   0\n",
       "Arakere                      0\n",
       "Attur                        0\n",
       "BTM Layout                   0\n",
       "Banaswadi                    0\n",
       "Basavanagudi                 0\n",
       "Basavanapura                 0\n",
       "Begur                        0\n",
       "Bellandur                    0\n",
       "Benniganahalli               0\n",
       "Bilekahalli                  0\n",
       "Binnipete                    0\n",
       "Bommanahalli                 0\n",
       "Byatarayanapura              0\n",
       "C. V. Raman Nagar            0\n",
       "Chikkalasandra               0\n",
       "Doddanekkundi                0\n",
       "Domlur                       0\n",
       "Ganesh Mandira               0\n",
       "Ganganagar                   0\n",
       "Girinagar                    0\n",
       "Govindarajanagar             0\n",
       "H. M. T.                     0\n",
       "HAL Airport                  0\n",
       "HBR Layout                   0\n",
       "Hebbala                      0\n",
       "Hemmigepura                  0\n",
       "Hongasandra                  0\n",
       "Hoodi                        0\n",
       "Horamavu                     0\n",
       "Jakkur                       0\n",
       "Jalahalli                    0\n",
       "Jayanagar                    0\n",
       "Jayanagar East               0\n",
       "Kadugudi                     0\n",
       "Kathriguppe                  0\n",
       "Kempegowda Ward              0\n",
       "Koramangala                  0\n",
       "Kottigepalya                 0\n",
       "Krishnarajapuram             0\n",
       "Kuvempunagar                 0\n",
       "Mangammanapalya              0\n",
       "Nagavara                     0\n",
       "Outside of town              0\n",
       "Padmanabhanagar              0\n",
       "Rajajinagar                  0\n",
       "Ramamurthynagar              0\n",
       "Sanjaynagar                  0\n",
       "Sarakki                      0\n",
       "Shakambarinagar              0\n",
       "Thanisandra                  0\n",
       "Uttarahalli                  0\n",
       "Varthur                      0\n",
       "Vasanthapura                 0\n",
       "Vidyapeetha                  0\n",
       "Vidyaranyapura               0\n",
       "Vignananagar                 0\n",
       "Yelachenahalli               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sfs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ecf76",
   "metadata": {},
   "source": [
    "### Predicting house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8ccad3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output of the X_test dataset\n",
    "y_pred = algorithm.predict(X_test_sfs)\n",
    "np.savetxt('best_algo.csv', y_pred, delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6524736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = bagging_regr.predict(X_test_sfs)\n",
    "np.savetxt('algo1.csv', y_pred1, delimiter='\\n')\n",
    "y_pred2 = extra_trees_regr.predict(X_test_sfs)\n",
    "np.savetxt('algo2.csv', y_pred2, delimiter='\\n')\n",
    "y_pred3 = grad_boost_regr.predict(X_test_sfs)\n",
    "np.savetxt('algo3.csv', y_pred3, delimiter='\\n')\n",
    "y_pred4 = hist_grad_boost_regr.predict(X_test_sfs)\n",
    "np.savetxt('algo4.csv', y_pred4, delimiter='\\n')\n",
    "y_pred5 = random_forest_regr.predict(X_test_sfs)\n",
    "np.savetxt('algo5.csv', y_pred5, delimiter='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
